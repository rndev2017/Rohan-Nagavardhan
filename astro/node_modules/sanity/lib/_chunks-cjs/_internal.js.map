{"version":3,"file":"_internal.js","sources":["../../src/_internal/cli/commands/backup/backupGroup.ts","../../src/_internal/cli/actions/backup/parseApiErr.ts","../../src/_internal/cli/debug.ts","../../src/_internal/cli/actions/dataset/validateDatasetName.ts","../../src/_internal/cli/actions/dataset/datasetNamePrompt.ts","../../src/_internal/cli/actions/dataset/chooseDatasetPrompt.ts","../../src/_internal/cli/actions/backup/resolveApiClient.ts","../../src/_internal/cli/commands/backup/disableBackupCommand.ts","../../src/_internal/cli/actions/backup/debug.ts","../../src/_internal/cli/actions/backup/archiveDir.ts","../../src/_internal/cli/actions/backup/chooseBackupIdPrompt.ts","../../src/_internal/cli/actions/backup/cleanupTmpDir.ts","../../src/_internal/cli/actions/backup/withRetry.ts","../../src/_internal/cli/actions/backup/downloadAsset.ts","../../src/_internal/cli/actions/backup/downloadDocument.ts","../../src/_internal/cli/actions/backup/fetchNextBackupPage.ts","../../src/_internal/cli/actions/backup/progressSpinner.ts","../../src/_internal/cli/util/humanFileSize.ts","../../src/_internal/cli/util/isPathDirName.ts","../../src/_internal/cli/commands/backup/downloadBackupCommand.ts","../../src/_internal/cli/commands/backup/enableBackupCommand.ts","../../src/_internal/cli/commands/backup/listBackupCommand.ts","../../src/_internal/cli/commands/build/buildCommand.ts","../../src/_internal/cli/commands/check/checkCommand.ts","../../src/_internal/cli/commands/config/configCheckCommand.ts","../../src/_internal/cli/actions/cors/addCorsOrigin.ts","../../src/_internal/cli/commands/cors/addCorsOriginCommand.ts","../../src/_internal/cli/commands/cors/corsGroup.ts","../../src/_internal/cli/commands/cors/deleteCorsOriginCommand.ts","../../src/_internal/cli/commands/cors/listCorsOriginsCommand.ts","../../src/_internal/cli/actions/dataset/alias/validateDatasetAliasName.ts","../../src/_internal/cli/actions/dataset/alias/promptForDatasetAliasName.ts","../../src/_internal/cli/commands/dataset/alias/datasetAliasesClient.ts","../../src/_internal/cli/commands/dataset/alias/createAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/deleteAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/linkAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/unlinkAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/aliasCommands.ts","../../src/_internal/cli/actions/dataset/listDatasetCopyJobs.ts","../../src/_internal/cli/util/getClientUrl.ts","../../src/_internal/cli/commands/dataset/copyDatasetCommand.ts","../../src/_internal/cli/commands/dataset/createDatasetCommand.ts","../../src/_internal/cli/commands/dataset/datasetGroup.ts","../../src/_internal/cli/commands/dataset/datasetVisibilityCommand.ts","../../src/_internal/cli/commands/dataset/deleteDatasetCommand.ts","../../src/_internal/cli/commands/dataset/exportDatasetCommand.ts","../../src/_internal/cli/commands/dataset/importDatasetCommand.ts","../../src/_internal/cli/commands/dataset/alias/listAliasesHandler.ts","../../src/_internal/cli/commands/dataset/listDatasetsCommand.ts","../../src/_internal/cli/commands/deploy/deployCommand.ts","../../src/_internal/cli/commands/deploy/undeployCommand.ts","../../src/_internal/cli/commands/dev/devCommand.ts","../../src/_internal/cli/commands/documents/createDocumentsCommand.ts","../../src/_internal/cli/commands/documents/deleteDocumentsCommand.ts","../../src/_internal/cli/commands/documents/documentsGroup.ts","../../src/_internal/cli/util/colorizeJson.ts","../../src/_internal/cli/commands/documents/getDocumentsCommand.ts","../../src/_internal/cli/commands/documents/queryDocumentsCommand.ts","../../src/_internal/cli/commands/documents/validateDocumentsCommand.ts","../../src/_internal/cli/commands/exec/execCommand.ts","../../src/_internal/cli/commands/graphql/deleteGraphQLAPICommand.ts","../../src/_internal/cli/commands/graphql/deployGraphQLAPICommand.ts","../../src/_internal/cli/commands/graphql/graphqlGroup.ts","../../src/_internal/cli/commands/graphql/listGraphQLAPIsCommand.ts","../../src/_internal/cli/commands/hook/createHookCommand.ts","../../src/_internal/cli/commands/hook/deleteHookCommand.ts","../../src/_internal/cli/commands/hook/hookGroup.ts","../../src/_internal/cli/commands/hook/printHookAttemptCommand.ts","../../src/_internal/cli/commands/hook/listHookLogsCommand.ts","../../src/_internal/cli/commands/hook/listHooksCommand.ts","../../src/_internal/cli/commands/migration/constants.ts","../../src/_internal/cli/commands/migration/templates/minimalAdvanced.ts","../../src/_internal/cli/commands/migration/templates/minimalSimple.ts","../../src/_internal/cli/commands/migration/templates/renameField.ts","../../src/_internal/cli/commands/migration/templates/renameType.ts","../../src/_internal/cli/commands/migration/templates/stringToPTE.ts","../../src/_internal/cli/commands/migration/createMigrationCommand.ts","../../src/_internal/cli/commands/migration/utils/resolveMigrationScript.ts","../../src/_internal/cli/commands/migration/listMigrationsCommand.ts","../../src/_internal/cli/commands/migration/migrationGroup.ts","../../src/_internal/cli/util/tree.ts","../../src/_internal/cli/commands/migration/prettyMutationFormatter.ts","../../src/_internal/cli/commands/migration/runMigrationCommand.ts","../../src/_internal/cli/commands/preview/previewCommand.ts","../../src/_internal/cli/commands/schema/extractSchemaCommand.ts","../../src/_internal/cli/commands/schema/schemaGroup.ts","../../src/_internal/cli/commands/schema/validateSchemaCommand.ts","../../src/_internal/cli/util/isInteractive.ts","../../src/_internal/cli/commands/start/startCommand.ts","../../src/_internal/cli/commands/uninstall/uninstallCommand.ts","../../src/_internal/cli/util/prettifyQuotaError.ts","../../src/_internal/cli/commands/users/inviteUserCommand.ts","../../src/_internal/cli/commands/users/listUsersCommand.ts","../../src/_internal/cli/commands/users/usersGroup.ts","../../src/_internal/cli/commands/index.ts"],"sourcesContent":["import {type CliCommandGroupDefinition} from '@sanity/cli'\n\n// defaultApiVersion is the backend API version used for dataset backup.\nexport const defaultApiVersion = 'v2024-02-21'\n\nconst datasetBackupGroup: CliCommandGroupDefinition = {\n  name: 'backup',\n  signature: '[COMMAND]',\n  description: 'Manage backups.',\n  isGroupRoot: true,\n}\n\nexport default datasetBackupGroup\n","// apiErr is a type that represents an error returned by the API\ninterface ApiErr {\n  statusCode: number\n  message: string\n}\n\n// parseApiErr is a function that attempts with the best effort to parse\n// an error returned by the API since different API endpoint may end up\n// returning different error structures.\n// eslint-disable-next-line @typescript-eslint/no-explicit-any,@typescript-eslint/explicit-module-boundary-types\nfunction parseApiErr(err: any): ApiErr {\n  const apiErr = {} as ApiErr\n  if (err.code) {\n    apiErr.statusCode = err.code\n  } else if (err.statusCode) {\n    apiErr.statusCode = err.statusCode\n  }\n\n  if (err.message) {\n    apiErr.message = err.message\n  } else if (err.statusMessage) {\n    apiErr.message = err.statusMessage\n  } else if (err?.response?.body?.message) {\n    apiErr.message = err.response.body.message\n  } else if (err?.response?.data?.message) {\n    apiErr.message = err.response.data.message\n  } else {\n    // If no message can be extracted, print the whole error.\n    apiErr.message = JSON.stringify(err)\n  }\n\n  return apiErr\n}\n\nexport default parseApiErr\n","import debugIt from 'debug'\n\nexport const debug = debugIt('sanity:core')\n","const MAX_DATASET_NAME_LENGTH = 64\n\nexport function validateDatasetName(datasetName: string): false | string {\n  if (!datasetName) {\n    return 'Dataset name is missing'\n  }\n\n  const name = `${datasetName}`\n\n  if (name.toLowerCase() !== name) {\n    return 'Dataset name must be all lowercase characters'\n  }\n\n  if (name.length < 2) {\n    return 'Dataset name must be at least two characters long'\n  }\n\n  if (name.length > MAX_DATASET_NAME_LENGTH) {\n    return `Dataset name must be at most ${MAX_DATASET_NAME_LENGTH} characters`\n  }\n\n  if (!/^[a-z0-9]/.test(name)) {\n    return 'Dataset name must start with a letter or a number'\n  }\n\n  if (!/^[a-z0-9][-_a-z0-9]+$/.test(name)) {\n    return 'Dataset name must only contain letters, numbers, dashes and underscores'\n  }\n\n  if (/[-_]$/.test(name)) {\n    return 'Dataset name must not end with a dash or an underscore'\n  }\n\n  return false\n}\n","import {type CliPrompter} from '@sanity/cli'\n\nimport {validateDatasetName} from './validateDatasetName'\n\nexport function promptForDatasetName(\n  prompt: CliPrompter,\n  options: {message?: string; default?: string} = {},\n): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Dataset name:',\n    validate: (name) => {\n      const err = validateDatasetName(name)\n      if (err) {\n        return err\n      }\n\n      return true\n    },\n    ...options,\n  })\n}\n","import {type CliCommandContext} from '@sanity/cli'\n\nimport {debug} from '../../debug'\nimport {promptForDatasetName} from './datasetNamePrompt'\n\nexport async function chooseDatasetPrompt(\n  context: CliCommandContext,\n  options: {message?: string; allowCreation?: boolean} = {},\n): Promise<string> {\n  const {apiClient, prompt} = context\n  const {message, allowCreation} = options\n  const client = apiClient()\n\n  const datasets = await client.datasets.list()\n  const hasProduction = datasets.find((dataset) => dataset.name === 'production')\n  const datasetChoices = datasets.map((dataset) => ({value: dataset.name}))\n  const selected = await prompt.single({\n    message: message || 'Select dataset to use',\n    type: 'list',\n    choices: allowCreation\n      ? [{value: 'new', name: 'Create new dataset'}, new prompt.Separator(), ...datasetChoices]\n      : datasetChoices,\n  })\n\n  if (selected === 'new') {\n    debug('User wants to create a new dataset, prompting for name')\n    const newDatasetName = await promptForDatasetName(prompt, {\n      message: 'Name your dataset:',\n      default: hasProduction ? undefined : 'production',\n    })\n    await client.datasets.create(newDatasetName)\n    return newDatasetName\n  }\n\n  return selected\n}\n","import {type CliCommandContext} from '@sanity/cli'\nimport {type SanityClient} from '@sanity/client'\n\nimport {chooseDatasetPrompt} from '../dataset/chooseDatasetPrompt'\n\ntype ResolvedApiClient = {\n  projectId: string\n  datasetName: string\n  token?: string\n  client: SanityClient\n}\n\nasync function resolveApiClient(\n  context: CliCommandContext,\n  datasetName: string,\n  apiVersion: string,\n): Promise<ResolvedApiClient> {\n  const {apiClient} = context\n\n  let client = apiClient()\n  const {projectId, token} = client.config()\n\n  if (!projectId) {\n    throw new Error('Project ID not defined')\n  }\n\n  // If no dataset provided, explicitly ask for dataset instead of using dataset\n  // configured in Sanity config. Aligns with `sanity dataset export` behavior.\n  let selectedDataset: string = datasetName\n  if (!selectedDataset) {\n    selectedDataset = await chooseDatasetPrompt(context, {\n      message: 'Select the dataset name:',\n    })\n  }\n\n  client = client.withConfig({dataset: datasetName, apiVersion})\n\n  return {\n    projectId,\n    datasetName: selectedDataset,\n    token,\n    client,\n  }\n}\n\nexport default resolveApiClient\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport {defaultApiVersion} from './backupGroup'\n\nconst helpText = `\nExamples\n  sanity backup disable DATASET_NAME\n`\n\nconst disableDatasetBackupCommand: CliCommandDefinition = {\n  name: 'disable',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'Disable backup for a dataset.',\n  helpText,\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const [dataset] = args.argsWithoutOptions\n    const {projectId, datasetName, token, client} = await resolveApiClient(\n      context,\n      dataset,\n      defaultApiVersion,\n    )\n\n    try {\n      await client.request({\n        method: 'PUT',\n        headers: {Authorization: `Bearer ${token}`},\n        uri: `/projects/${projectId}/datasets/${datasetName}/settings/backups`,\n        body: {\n          enabled: false,\n        },\n      })\n      output.print(`${chalk.green(`Disabled daily backups for dataset ${datasetName}\\n`)}`)\n    } catch (error) {\n      const {message} = parseApiErr(error)\n      output.print(`${chalk.red(`Disabling dataset backup failed: ${message}`)}\\n`)\n    }\n  },\n}\n\nexport default disableDatasetBackupCommand\n","export default require('debug')('sanity:backup')\n","import {createWriteStream} from 'node:fs'\nimport zlib from 'node:zlib'\n\nimport {type ProgressData} from 'archiver'\n\nimport debug from './debug'\n\nconst archiver = require('archiver')\n\n// ProgressCb is a callback that is called with the number of bytes processed so far.\ntype ProgressCb = (processedBytes: number) => void\n\n// archiveDir creates a tarball of the given directory and writes it to the given file path.\nfunction archiveDir(tmpOutDir: string, outFilePath: string, progressCb: ProgressCb): Promise<void> {\n  return new Promise((resolve, reject) => {\n    const archiveDestination = createWriteStream(outFilePath)\n    archiveDestination.on('error', (err: Error) => {\n      reject(err)\n    })\n\n    archiveDestination.on('close', () => {\n      resolve()\n    })\n\n    const archive = archiver('tar', {\n      gzip: true,\n      gzipOptions: {level: zlib.constants.Z_DEFAULT_COMPRESSION},\n    })\n\n    archive.on('error', (err: Error) => {\n      debug('Archiving errored!\\n%s', err.stack)\n      reject(err)\n    })\n\n    // Catch warnings for non-blocking errors (stat failures and others)\n    archive.on('warning', (err: Error) => {\n      debug('Archive warning: %s', err.message)\n    })\n\n    archive.on('progress', (progress: ProgressData) => {\n      progressCb(progress.fs.processedBytes)\n    })\n\n    // Pipe archive data to the file\n    archive.pipe(archiveDestination)\n    archive.directory(tmpOutDir, false)\n    archive.finalize()\n  })\n}\n\nexport default archiveDir\n","import {type CliCommandContext} from '@sanity/cli'\n\nimport {defaultApiVersion} from '../../commands/backup/backupGroup'\nimport resolveApiClient from './resolveApiClient'\n\n// maxBackupIdsShown is the maximum number of backup IDs to show in the prompt.\n// Higher numbers will cause the prompt to be slow.\nconst maxBackupIdsShown = 100\n\nasync function chooseBackupIdPrompt(\n  context: CliCommandContext,\n  datasetName: string,\n): Promise<string> {\n  const {prompt} = context\n\n  const {projectId, token, client} = await resolveApiClient(context, datasetName, defaultApiVersion)\n\n  try {\n    // Fetch last $maxBackupIdsShown backups for this dataset.\n    // We expect here that API returns backups sorted by creation date in descending order.\n    const response = await client.request({\n      headers: {Authorization: `Bearer ${token}`},\n      uri: `/projects/${projectId}/datasets/${datasetName}/backups`,\n      query: {limit: maxBackupIdsShown.toString()},\n    })\n\n    if (response?.backups?.length > 0) {\n      const backupIdChoices = response.backups.map((backup: {id: string}) => ({\n        value: backup.id,\n      }))\n      const selected = await prompt.single({\n        message: `Select backup ID to use (only last ${maxBackupIdsShown} shown)`,\n        type: 'list',\n        choices: backupIdChoices,\n      })\n\n      return selected\n    }\n  } catch (err) {\n    throw new Error(`Failed to fetch backups for dataset ${datasetName}: ${err.message}`)\n  }\n\n  throw new Error('No backups found')\n}\n\nexport default chooseBackupIdPrompt\n","import rimraf from 'rimraf'\n\nimport debug from './debug'\n\nfunction cleanupTmpDir(tmpDir: string): void {\n  rimraf(tmpDir, (err) => {\n    if (err) {\n      debug(`Error cleaning up temporary files: ${err.message}`)\n    }\n  })\n}\n\nexport default cleanupTmpDir\n","import debug from './debug'\n\nconst MAX_RETRIES = 5\nconst BACKOFF_DELAY_BASE = 200\n\nconst exponentialBackoff = (retryCount: number) => Math.pow(2, retryCount) * BACKOFF_DELAY_BASE\n\nasync function withRetry<T>(\n  operation: () => Promise<T>,\n  maxRetries: number = MAX_RETRIES,\n): Promise<T> {\n  for (let retryCount = 0; retryCount < maxRetries; retryCount++) {\n    try {\n      return await operation()\n    } catch (err) {\n      // Immediately rethrow if the error is not server-related.\n      if (err.response && err.response.statusCode && err.response.statusCode < 500) {\n        throw err\n      }\n\n      const retryDelay = exponentialBackoff(retryCount)\n      debug(`Error encountered, retrying after ${retryDelay}ms: %s`, err.message)\n      await new Promise((resolve) => setTimeout(resolve, retryDelay))\n    }\n  }\n\n  throw new Error('Operation failed after all retries')\n}\n\nexport default withRetry\n","import {createWriteStream} from 'node:fs'\nimport path from 'node:path'\nimport {pipeline} from 'node:stream/promises'\n\nimport {getIt} from 'get-it'\n// eslint-disable-next-line import/extensions\nimport {keepAlive, promise} from 'get-it/middleware'\n\nimport debug from './debug'\nimport withRetry from './withRetry'\n\nconst CONNECTION_TIMEOUT = 15 * 1000 // 15 seconds\nconst READ_TIMEOUT = 3 * 60 * 1000 // 3 minutes\n\nconst request = getIt([keepAlive(), promise()])\n\nasync function downloadAsset(\n  url: string,\n  fileName: string,\n  fileType: string,\n  outDir: string,\n): Promise<void> {\n  // File names that contain a path to file (e.g. sanity-storage/assets/file-name.tar.gz) fail when archive is\n  // created due to missing parent dir (e.g. sanity-storage/assets), so we want to handle them by taking\n  // the base name as file name.\n  const normalizedFileName = path.basename(fileName)\n\n  const assetFilePath = getAssetFilePath(normalizedFileName, fileType, outDir)\n  await withRetry(async () => {\n    const response = await request({\n      url: url,\n      maxRedirects: 5,\n      timeout: {connect: CONNECTION_TIMEOUT, socket: READ_TIMEOUT},\n      stream: true,\n    })\n\n    debug('Received asset %s with status code %d', normalizedFileName, response?.statusCode)\n\n    await pipeline(response.body, createWriteStream(assetFilePath))\n  })\n}\n\nfunction getAssetFilePath(fileName: string, fileType: string, outDir: string): string {\n  // Set assetFilePath if we are downloading an asset file.\n  // If it's a JSON document, assetFilePath will be an empty string.\n  let assetFilePath = ''\n  if (fileType === 'image') {\n    assetFilePath = path.join(outDir, 'images', fileName)\n  } else if (fileType === 'file') {\n    assetFilePath = path.join(outDir, 'files', fileName)\n  }\n\n  return assetFilePath\n}\n\nexport default downloadAsset\n","import {getIt, type MiddlewareResponse} from 'get-it'\n// eslint-disable-next-line import/extensions\nimport {keepAlive, promise} from 'get-it/middleware'\n\nimport debug from './debug'\nimport withRetry from './withRetry'\n\nconst CONNECTION_TIMEOUT = 15 * 1000 // 15 seconds\nconst READ_TIMEOUT = 3 * 60 * 1000 // 3 minutes\n\nconst request = getIt([keepAlive(), promise()])\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nasync function downloadDocument(url: string): Promise<any> {\n  const response = await withRetry<MiddlewareResponse>(() =>\n    request({\n      url,\n      maxRedirects: 5,\n      timeout: {connect: CONNECTION_TIMEOUT, socket: READ_TIMEOUT},\n    }),\n  )\n\n  debug('Received document from %s with status code %d', url, response?.statusCode)\n\n  return response.body\n}\n\nexport default downloadDocument\n","import {Readable} from 'node:stream'\n\nimport {type QueryParams, type SanityClient} from '@sanity/client'\n\ntype File = {\n  name: string\n  url: string\n  type: string\n}\n\ntype GetBackupResponse = {\n  createdAt: string\n  totalFiles: number\n  files: File[]\n  nextCursor?: string\n}\n\nclass PaginatedGetBackupStream extends Readable {\n  private cursor = ''\n  private readonly client: SanityClient\n  private readonly projectId: string\n  private readonly datasetName: string\n  private readonly backupId: string\n  private readonly token: string\n  public totalFiles = 0\n\n  constructor(\n    client: SanityClient,\n    projectId: string,\n    datasetName: string,\n    backupId: string,\n    token: string,\n  ) {\n    super({objectMode: true})\n    this.client = client\n    this.projectId = projectId\n    this.datasetName = datasetName\n    this.backupId = backupId\n    this.token = token\n  }\n\n  async _read(): Promise<void> {\n    try {\n      const data = await this.fetchNextBackupPage()\n\n      // Set totalFiles when it's fetched for the first time\n      if (this.totalFiles === 0) {\n        this.totalFiles = data.totalFiles\n      }\n\n      data.files.forEach((file: File) => this.push(file))\n\n      if (typeof data.nextCursor === 'string' && data.nextCursor !== '') {\n        this.cursor = data.nextCursor\n      } else {\n        // No more pages left to fetch.\n        this.push(null)\n      }\n    } catch (err) {\n      this.destroy(err as Error)\n    }\n  }\n\n  // fetchNextBackupPage fetches the next page of backed up files from the backup API.\n  async fetchNextBackupPage(): Promise<GetBackupResponse> {\n    const query: QueryParams = this.cursor === '' ? {} : {nextCursor: this.cursor}\n\n    try {\n      return await this.client.request({\n        headers: {Authorization: `Bearer ${this.token}`},\n        uri: `/projects/${this.projectId}/datasets/${this.datasetName}/backups/${this.backupId}`,\n        query,\n      })\n    } catch (error) {\n      // It can be clearer to pull this logic out in a  common error handling function for re-usability.\n      let msg = error.statusCode ? error.response.body.message : error.message\n\n      // If no message can be extracted, print the whole error.\n      if (msg === undefined) {\n        msg = String(error)\n      }\n      throw new Error(`Downloading dataset backup failed: ${msg}`)\n    }\n  }\n}\n\nexport {PaginatedGetBackupStream}\nexport type {File, GetBackupResponse}\n","import {type CliOutputter} from '@sanity/cli'\nimport prettyMs from 'pretty-ms'\n\ntype ProgressEvent = {\n  step: string\n  update?: boolean\n  current?: number\n  total?: number\n}\n\ninterface ProgressSpinner {\n  set: (progress: ProgressEvent) => void\n  update: (progress: ProgressEvent) => void\n  succeed: () => void\n  fail: () => void\n}\n\nconst newProgress = (output: CliOutputter, startStep: string): ProgressSpinner => {\n  let spinner = output.spinner(startStep).start()\n  let lastProgress: ProgressEvent = {step: startStep}\n  let start = Date.now()\n\n  const print = (progress: ProgressEvent) => {\n    const elapsed = prettyMs(Date.now() - start)\n    if (progress.current && progress.current > 0 && progress.total && progress.total > 0) {\n      spinner.text = `${progress.step} (${progress.current}/${progress.total}) [${elapsed}]`\n    } else {\n      spinner.text = `${progress.step} [${elapsed}]`\n    }\n  }\n\n  return {\n    set: (progress: ProgressEvent) => {\n      if (progress.step !== lastProgress.step) {\n        print(lastProgress) // Print the last progress before moving on\n        spinner.succeed()\n        spinner = output.spinner(progress.step).start()\n        start = Date.now()\n      } else if (progress.step === lastProgress.step && progress.update) {\n        print(progress)\n      }\n      lastProgress = progress\n    },\n    update: (progress: ProgressEvent) => {\n      print(progress)\n      lastProgress = progress\n    },\n    succeed: () => {\n      spinner.succeed()\n      start = Date.now()\n    },\n    fail: () => {\n      spinner.fail()\n      start = Date.now()\n    },\n  }\n}\n\nexport default newProgress\n","function humanFileSize(size: number): string {\n  const i = size == 0 ? 0 : Math.floor(Math.log(size) / Math.log(1024))\n  return `${(size / Math.pow(1024, i)).toFixed(2)} ${['B', 'kB', 'MB', 'GB', 'TB'][i]}`\n}\n\nexport default humanFileSize\n","function isPathDirName(filepath: string): boolean {\n  // Check if the path has an extension, commonly indicating a file\n  return !/\\.\\w+$/.test(filepath)\n}\n\nexport default isPathDirName\n","import {createWriteStream, existsSync, mkdirSync} from 'node:fs'\nimport {mkdtemp} from 'node:fs/promises'\nimport {tmpdir} from 'node:os'\nimport path from 'node:path'\nimport {finished} from 'node:stream/promises'\n\nimport {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n  type SanityClient,\n} from '@sanity/cli'\nimport {absolutify} from '@sanity/util/fs'\nimport {Mutex} from 'async-mutex'\nimport createDebug from 'debug'\nimport {isString} from 'lodash'\nimport prettyMs from 'pretty-ms'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport archiveDir from '../../actions/backup/archiveDir'\nimport chooseBackupIdPrompt from '../../actions/backup/chooseBackupIdPrompt'\nimport cleanupTmpDir from '../../actions/backup/cleanupTmpDir'\nimport downloadAsset from '../../actions/backup/downloadAsset'\nimport downloadDocument from '../../actions/backup/downloadDocument'\nimport {type File, PaginatedGetBackupStream} from '../../actions/backup/fetchNextBackupPage'\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport newProgress from '../../actions/backup/progressSpinner'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport humanFileSize from '../../util/humanFileSize'\nimport isPathDirName from '../../util/isPathDirName'\nimport {defaultApiVersion} from './backupGroup'\n\nconst debug = createDebug('sanity:backup')\n\nconst DEFAULT_DOWNLOAD_CONCURRENCY = 10\nconst MAX_DOWNLOAD_CONCURRENCY = 24\n\ninterface DownloadBackupOptions {\n  projectId: string\n  datasetName: string\n  token: string\n  backupId: string\n  outDir: string\n  outFileName: string\n  overwrite: boolean\n  concurrency: number\n}\n\nconst helpText = `\nOptions\n  --backup-id <string> The backup ID to download. (required)\n  --out <string>       The file or directory path the backup should download to.\n  --overwrite          Allows overwriting of existing backup file.\n  --concurrency <num>  Concurrent number of backup item downloads. (max: 24)\n\nExamples\n  sanity backup download DATASET_NAME --backup-id 2024-01-01-backup-1\n  sanity backup download DATASET_NAME --backup-id 2024-01-01-backup-2 --out /path/to/file\n  sanity backup download DATASET_NAME --backup-id 2024-01-01-backup-3 --out /path/to/file --overwrite\n`\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .options('backup-id', {type: 'string'})\n    .options('out', {type: 'string'})\n    .options('concurrency', {type: 'number', default: DEFAULT_DOWNLOAD_CONCURRENCY})\n    .options('overwrite', {type: 'boolean', default: false}).argv\n}\n\nconst downloadBackupCommand: CliCommandDefinition = {\n  name: 'download',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'Download a dataset backup to a local file.',\n  helpText,\n  // eslint-disable-next-line max-statements\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const [client, opts] = await prepareBackupOptions(context, args)\n    const {projectId, datasetName, backupId, outDir, outFileName} = opts\n\n    // If any of the output path or file name is empty, cancel the operation.\n    if (outDir === '' || outFileName === '') {\n      output.print('Operation cancelled.')\n      return\n    }\n    const outFilePath = path.join(outDir, outFileName)\n\n    output.print('╭───────────────────────────────────────────────────────────╮')\n    output.print('│                                                           │')\n    output.print('│ Downloading backup for:                                   │')\n    output.print(`│ ${chalk.bold('projectId')}: ${chalk.cyan(projectId).padEnd(56)} │`)\n    output.print(`│ ${chalk.bold('dataset')}: ${chalk.cyan(datasetName).padEnd(58)} │`)\n    output.print(`│ ${chalk.bold('backupId')}: ${chalk.cyan(backupId).padEnd(56)} │`)\n    output.print('│                                                           │')\n    output.print('╰───────────────────────────────────────────────────────────╯')\n    output.print('')\n    output.print(`Downloading backup to \"${chalk.cyan(outFilePath)}\"`)\n\n    const start = Date.now()\n    const progressSpinner = newProgress(output, 'Setting up backup environment...')\n\n    // Create a unique temporary directory to store files before bundling them into the archive at outputPath.\n    // Temporary directories are normally deleted at the end of backup process, any unexpected exit may leave them\n    // behind, hence it is important to create a unique directory for each attempt.\n    const tmpOutDir = await mkdtemp(path.join(tmpdir(), `sanity-backup-`))\n\n    // Create required directories if they don't exist.\n    for (const dir of [outDir, path.join(tmpOutDir, 'images'), path.join(tmpOutDir, 'files')]) {\n      mkdirSync(dir, {recursive: true})\n    }\n\n    debug('Writing to temporary directory %s', tmpOutDir)\n    const tmpOutDocumentsFile = path.join(tmpOutDir, 'data.ndjson')\n\n    // Handle concurrent writes to the same file using mutex.\n    const docOutStream = createWriteStream(tmpOutDocumentsFile)\n    const docWriteMutex = new Mutex()\n\n    try {\n      const backupFileStream = new PaginatedGetBackupStream(\n        client,\n        opts.projectId,\n        opts.datasetName,\n        opts.backupId,\n        opts.token,\n      )\n\n      const files: File[] = []\n      let i = 0\n      for await (const file of backupFileStream) {\n        files.push(file)\n        i++\n        progressSpinner.set({\n          step: `Reading backup files...`,\n          update: true,\n          current: i,\n          total: backupFileStream.totalFiles,\n        })\n      }\n\n      let totalItemsDownloaded = 0\n      // This is dynamically imported because this module is ESM only and this file gets compiled to CJS at this time.\n      const {default: pMap} = await import('p-map')\n      await pMap(\n        files,\n        async (file: File) => {\n          if (file.type === 'file' || file.type === 'image') {\n            await downloadAsset(file.url, file.name, file.type, tmpOutDir)\n          } else {\n            const doc = await downloadDocument(file.url)\n            await docWriteMutex.runExclusive(() => {\n              docOutStream.write(`${doc}\\n`)\n            })\n          }\n\n          totalItemsDownloaded += 1\n          progressSpinner.set({\n            step: `Downloading documents and assets...`,\n            update: true,\n            current: totalItemsDownloaded,\n            total: backupFileStream.totalFiles,\n          })\n        },\n        {concurrency: opts.concurrency},\n      )\n    } catch (error) {\n      progressSpinner.fail()\n      const {message} = parseApiErr(error)\n      throw new Error(`Downloading dataset backup failed: ${message}`)\n    }\n\n    docOutStream.end()\n    await finished(docOutStream)\n\n    progressSpinner.set({step: `Archiving files into a tarball...`, update: true})\n    try {\n      await archiveDir(tmpOutDir, outFilePath, (processedBytes: number) => {\n        progressSpinner.update({\n          step: `Archiving files into a tarball, ${humanFileSize(processedBytes)} bytes written...`,\n        })\n      })\n    } catch (err) {\n      progressSpinner.fail()\n      throw new Error(`Archiving backup failed: ${err.message}`)\n    }\n\n    progressSpinner.set({\n      step: `Cleaning up temporary files at ${chalk.cyan(`${tmpOutDir}`)}`,\n    })\n    cleanupTmpDir(tmpOutDir)\n\n    progressSpinner.set({\n      step: `Backup download complete [${prettyMs(Date.now() - start)}]`,\n    })\n    progressSpinner.succeed()\n  },\n}\n\n// prepareBackupOptions validates backup options from CLI and prepares Client and DownloadBackupOptions.\nasync function prepareBackupOptions(\n  context: CliCommandContext,\n  args: CliCommandArguments,\n): Promise<[SanityClient, DownloadBackupOptions]> {\n  const flags = await parseCliFlags(args)\n  const [dataset] = args.argsWithoutOptions\n  const {prompt, workDir} = context\n  const {projectId, datasetName, client} = await resolveApiClient(\n    context,\n    dataset,\n    defaultApiVersion,\n  )\n\n  const {token} = client.config()\n  if (!isString(token) || token.length < 1) {\n    throw new Error(`token is missing`)\n  }\n\n  if (!isString(datasetName) || datasetName.length < 1) {\n    throw new Error(`dataset ${datasetName} must be a valid dataset name`)\n  }\n\n  const backupId = String(flags['backup-id'] || (await chooseBackupIdPrompt(context, datasetName)))\n  if (backupId.length < 1) {\n    throw new Error(`backup-id ${flags['backup-id']} should be a valid string`)\n  }\n\n  if ('concurrency' in flags) {\n    if (flags.concurrency < 1 || flags.concurrency > MAX_DOWNLOAD_CONCURRENCY) {\n      throw new Error(`concurrency should be in 1 to ${MAX_DOWNLOAD_CONCURRENCY} range`)\n    }\n  }\n\n  const defaultOutFileName = `${datasetName}-backup-${backupId}.tar.gz`\n  let out = await (async (): Promise<string> => {\n    if (flags.out !== undefined) {\n      // Rewrite the output path to an absolute path, if it is not already.\n      return absolutify(flags.out)\n    }\n\n    const input = await prompt.single({\n      type: 'input',\n      message: 'Output path:',\n      default: path.join(workDir, defaultOutFileName),\n      filter: absolutify,\n    })\n    return input\n  })()\n\n  // If path is a directory name, then add a default file name to the path.\n  if (isPathDirName(out)) {\n    out = path.join(out, defaultOutFileName)\n  }\n\n  // If the file already exists, ask for confirmation if it should be overwritten.\n  if (!flags.overwrite && existsSync(out)) {\n    const shouldOverwrite = await prompt.single({\n      type: 'confirm',\n      message: `File \"${out}\" already exists, would you like to overwrite it?`,\n      default: false,\n    })\n\n    // If the user does not want to overwrite the file, set the output path to an empty string.\n    // This should be handled by the caller of this function as cancel operation.\n    if (!shouldOverwrite) {\n      out = ''\n    }\n  }\n\n  return [\n    client,\n    {\n      projectId,\n      datasetName,\n      backupId,\n      token,\n      outDir: path.dirname(out),\n      outFileName: path.basename(out),\n      overwrite: flags.overwrite,\n      concurrency: flags.concurrency || DEFAULT_DOWNLOAD_CONCURRENCY,\n    },\n  ]\n}\n\nexport default downloadBackupCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport {defaultApiVersion} from './backupGroup'\n\nconst helpText = `\nExamples\n  sanity backup enable DATASET_NAME\n`\n\nconst enableDatasetBackupCommand: CliCommandDefinition = {\n  name: 'enable',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'Enable backup for a dataset.',\n  helpText,\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const [dataset] = args.argsWithoutOptions\n    const {projectId, datasetName, token, client} = await resolveApiClient(\n      context,\n      dataset,\n      defaultApiVersion,\n    )\n\n    try {\n      await client.request({\n        method: 'PUT',\n        headers: {Authorization: `Bearer ${token}`},\n        uri: `/projects/${projectId}/datasets/${datasetName}/settings/backups`,\n        body: {\n          enabled: true,\n        },\n      })\n\n      output.print(\n        `${chalk.green(\n          `Enabled backups for dataset ${datasetName}.\\nPlease note that it may take up to 24 hours before the first backup is created.\\n`,\n        )}`,\n      )\n\n      output.print(\n        `${chalk.bold(`Retention policies may apply depending on your plan and agreement.\\n`)}`,\n      )\n    } catch (error) {\n      const {message} = parseApiErr(error)\n      output.print(`${chalk.red(`Enabling dataset backup failed: ${message}`)}\\n`)\n    }\n  },\n}\nexport default enableDatasetBackupCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport {Table} from 'console-table-printer'\nimport {isAfter, isValid, lightFormat, parse} from 'date-fns'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport {defaultApiVersion} from './backupGroup'\n\nconst DEFAULT_LIST_BACKUP_LIMIT = 30\n\ninterface ListDatasetBackupFlags {\n  before?: string\n  after?: string\n  limit?: string\n}\n\ntype ListBackupRequestQueryParams = {\n  before?: string\n  after?: string\n  limit: string\n}\n\ntype ListBackupResponse = {\n  backups: ListBackupResponseItem[]\n}\n\ntype ListBackupResponseItem = {\n  id: string\n  createdAt: string\n}\n\nconst helpText = `\nOptions\n  --limit <int>     Maximum number of backups returned. Default 30.\n  --after <string>  Only return backups after this date (inclusive)\n  --before <string> Only return backups before this date (exclusive). Cannot be younger than <after> if specified.\n\nExamples\n  sanity backup list DATASET_NAME\n  sanity backup list DATASET_NAME --limit 50\n  sanity backup list DATASET_NAME --after 2024-01-31 --limit 10\n  sanity backup list DATASET_NAME --after 2024-01-31 --before 2024-01-10\n`\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .options('after', {type: 'string'})\n    .options('before', {type: 'string'})\n    .options('limit', {type: 'number', default: DEFAULT_LIST_BACKUP_LIMIT, alias: 'l'}).argv\n}\n\nconst listDatasetBackupCommand: CliCommandDefinition<ListDatasetBackupFlags> = {\n  name: 'list',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'List available backups for a dataset.',\n  helpText,\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const flags = await parseCliFlags(args)\n    const [dataset] = args.argsWithoutOptions\n\n    const {projectId, datasetName, token, client} = await resolveApiClient(\n      context,\n      dataset,\n      defaultApiVersion,\n    )\n\n    const query: ListBackupRequestQueryParams = {limit: DEFAULT_LIST_BACKUP_LIMIT.toString()}\n    if (flags.limit) {\n      // We allow limit up to Number.MAX_SAFE_INTEGER to leave it for server-side validation,\n      //  while still sending sensible value in limit string.\n      if (flags.limit < 1 || flags.limit > Number.MAX_SAFE_INTEGER) {\n        throw new Error(\n          `Parsing --limit: must be an integer between 1 and ${Number.MAX_SAFE_INTEGER}`,\n        )\n      }\n      query.limit = flags.limit.toString()\n    }\n\n    if (flags.before || flags.after) {\n      try {\n        const parsedBefore = processDateFlags(flags.before)\n        const parsedAfter = processDateFlags(flags.after)\n\n        if (parsedAfter && parsedBefore && isAfter(parsedAfter, parsedBefore)) {\n          throw new Error('--after date must be before --before')\n        }\n\n        query.before = flags.before\n        query.after = flags.after\n      } catch (err) {\n        throw new Error(`Parsing date flags: ${err}`)\n      }\n    }\n\n    let response\n    try {\n      response = await client.request<ListBackupResponse>({\n        headers: {Authorization: `Bearer ${token}`},\n        uri: `/projects/${projectId}/datasets/${datasetName}/backups`,\n        query: {...query},\n      })\n    } catch (error) {\n      const {message} = parseApiErr(error)\n      output.error(`${chalk.red(`List dataset backup failed: ${message}`)}\\n`)\n    }\n\n    if (response && response.backups) {\n      if (response.backups.length === 0) {\n        output.print('No backups found.')\n        return\n      }\n\n      const table = new Table({\n        columns: [\n          {name: 'resource', title: 'RESOURCE', alignment: 'left'},\n          {name: 'createdAt', title: 'CREATED AT', alignment: 'left'},\n          {name: 'backupId', title: 'BACKUP ID', alignment: 'left'},\n        ],\n      })\n\n      response.backups.forEach((backup: ListBackupResponseItem) => {\n        const {id, createdAt} = backup\n        table.addRow({\n          resource: 'Dataset',\n          createdAt: lightFormat(Date.parse(createdAt), 'yyyy-MM-dd HH:mm:ss'),\n          backupId: id,\n        })\n      })\n\n      table.printTable()\n    }\n  },\n}\n\nfunction processDateFlags(date: string | undefined): Date | undefined {\n  if (!date) return undefined\n  const parsedDate = parse(date, 'yyyy-MM-dd', new Date())\n  if (isValid(parsedDate)) {\n    return parsedDate\n  }\n\n  throw new Error(`Invalid ${date} date format. Use YYYY-MM-DD`)\n}\n\nexport default listDatasetBackupCommand\n","import type {CliCommandArguments, CliCommandContext, CliCommandDefinition} from '@sanity/cli'\nimport {BuildSanityStudioCommandFlags} from '../../actions/build/buildAction'\n\nconst helpText = `\nOptions\n  --source-maps Enable source maps for built bundles (increases size of bundle)\n  --no-minify Skip minifying built JavaScript (speeds up build, increases size of bundle)\n  -y, --yes Use unattended mode, accepting defaults and using only flags for choices\n\nExamples\n  sanity build\n  sanity build --no-minify --source-maps\n`\n\nconst buildCommand: CliCommandDefinition = {\n  name: 'build',\n  signature: '[OUTPUT_DIR]',\n  description: 'Builds the Sanity Studio configuration into a static bundle',\n  action: async (\n    args: CliCommandArguments<BuildSanityStudioCommandFlags>,\n    context: CliCommandContext,\n    overrides?: {basePath?: string},\n  ) => {\n    const buildAction = await getBuildAction()\n\n    return buildAction(args, context, overrides)\n  },\n  helpText,\n}\n\nasync function getBuildAction() {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions\n    const mod: typeof import('../../actions/build/buildAction') = require('../../actions/build/buildAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/build/buildAction')\n\n  return mod.default\n}\n\nexport default buildCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst checkCommand: CliCommandDefinition = {\n  name: 'check',\n  signature: '',\n  description: '[deprecated]',\n  helpText: '',\n  hideFromHelp: true,\n  action: (_args, context) => {\n    const {output} = context\n    output.print('`sanity check` is deprecated and no longer has any effect')\n    return Promise.resolve()\n  },\n}\n\nexport default checkCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst configCheckCommand: CliCommandDefinition = {\n  name: 'configcheck',\n  signature: '',\n  description: 'Checks if the required configuration files for plugins exists and are up to date',\n  helpText: '',\n  hideFromHelp: true,\n  action: async (args, context) => {\n    context.output.error('`sanity configcheck` is no longer required/used')\n    return Promise.resolve()\n  },\n}\n\nexport default configCheckCommand\n","import url from 'node:url'\n\nimport {type CliCommandContext, type CliPrompter} from '@sanity/cli'\nimport logSymbols from 'log-symbols'\nimport oneline from 'oneline'\n\nconst wildcardReplacement = 'a-wild-card-r3pl4c3m3n7-a'\nconst portReplacement = ':7777777'\n\ninterface AddCorsOriginFlags {\n  credentials?: boolean\n}\n\nexport async function addCorsOrigin(\n  givenOrigin: string,\n  flags: AddCorsOriginFlags,\n  context: CliCommandContext,\n): Promise<boolean> {\n  const {apiClient, prompt, output} = context\n  const origin = await (givenOrigin\n    ? filterAndValidateOrigin(givenOrigin)\n    : promptForOrigin(prompt))\n\n  const hasWildcard = origin.includes('*')\n  if (hasWildcard && !(await promptForWildcardConfirmation(origin, context))) {\n    return false\n  }\n  const allowCredentials =\n    typeof flags.credentials === 'undefined'\n      ? await promptForCredentials(hasWildcard, context)\n      : Boolean(flags.credentials)\n\n  if (givenOrigin !== origin) {\n    output.print(`Normalized origin to ${origin}`)\n  }\n\n  const client = apiClient({\n    requireUser: true,\n    requireProject: true,\n  })\n\n  await client.request({\n    method: 'POST',\n    url: '/cors',\n    body: {origin, allowCredentials},\n    maxRedirects: 0,\n  })\n\n  return true\n}\n\nfunction promptForCredentials(hasWildcard: boolean, context: CliCommandContext): Promise<string> {\n  const {prompt, output, chalk} = context\n\n  output.print('')\n  if (hasWildcard) {\n    output.print(oneline`\n      ${chalk.yellow(`${logSymbols.warning} Warning:`)}\n      We ${chalk.red(chalk.underline('HIGHLY'))} recommend NOT allowing credentials\n      on origins containing wildcards. If you are logged in to a studio, people will\n      be able to send requests ${chalk.underline('on your behalf')} to read and modify\n      data, from any matching origin. Please tread carefully!\n    `)\n  } else {\n    output.print(oneline`\n      ${chalk.yellow(`${logSymbols.warning} Warning:`)}\n      Should this origin be allowed to send requests using authentication tokens or\n      session cookies? Be aware that any script on this origin will be able to send\n      requests ${chalk.underline('on your behalf')} to read and modify data if you\n      are logged in to a Sanity studio. If this origin hosts a studio, you will need\n      this, otherwise you should probably answer \"No\" (n).\n    `)\n  }\n\n  output.print('')\n\n  return prompt.single({\n    type: 'confirm',\n    message: oneline`\n      Allow credentials to be sent from this origin? Please read the warning above.\n    `,\n    default: false,\n  })\n}\n\nfunction promptForWildcardConfirmation(\n  origin: string,\n  context: CliCommandContext,\n): Promise<boolean> {\n  const {prompt, output, chalk} = context\n\n  output.print('')\n  output.print(chalk.yellow(`${logSymbols.warning} Warning: Examples of allowed origins:`))\n\n  if (origin === '*') {\n    output.print('- http://www.some-malicious.site')\n    output.print('- https://not.what-you-were-expecting.com')\n    output.print('- https://high-traffic-site.com')\n    output.print('- http://192.168.1.1:8080')\n  } else {\n    output.print(`- ${origin.replace(/:\\*/, ':1234').replace(/\\*/g, 'foo')}`)\n    output.print(`- ${origin.replace(/:\\*/, ':3030').replace(/\\*/g, 'foo.bar')}`)\n  }\n\n  output.print('')\n\n  return prompt.single({\n    type: 'confirm',\n    message: oneline`\n      Using wildcards can be ${chalk.red('risky')}.\n      Are you ${chalk.underline('absolutely sure')} you want to allow this origin?`,\n    default: false,\n  })\n}\n\nfunction promptForOrigin(prompt: CliPrompter): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Origin (including protocol):',\n    filter: filterOrigin,\n    validate: (origin) => validateOrigin(origin, origin),\n  })\n}\n\nfunction filterOrigin(origin: string): string | null {\n  if (origin === '*' || origin === 'file:///*' || origin === 'null') {\n    return origin\n  }\n\n  try {\n    const example = origin\n      .replace(/([^:])\\*/g, `$1${wildcardReplacement}`)\n      .replace(/:\\*/, portReplacement)\n\n    const parsed = url.parse(example)\n    let host = parsed.host || ''\n    if (/^https?:$/.test(parsed.protocol || '')) {\n      host = host.replace(/:(80|443)$/, '')\n    }\n\n    host = host.replace(portReplacement, ':*').replace(new RegExp(wildcardReplacement, 'g'), '*')\n\n    return `${parsed.protocol}//${host}`\n  } catch (err) {\n    return null\n  }\n}\n\nfunction validateOrigin(origin: string | null, givenOrigin: string): true | string {\n  if (origin === '*' || origin === 'file:///*' || origin === 'null') {\n    return true\n  }\n\n  try {\n    url.parse(origin || (0 as any as string)) // Use 0 to trigger error for unset values\n    return true\n  } catch (err) {\n    // Fall-through to error\n  }\n\n  if (/^file:\\/\\//.test(givenOrigin)) {\n    return `Only a local file wildcard is currently allowed: file:///*`\n  }\n\n  return `Invalid origin \"${givenOrigin}\", must include protocol (https://some.host)`\n}\n\nfunction filterAndValidateOrigin(givenOrigin: string): string {\n  const origin = filterOrigin(givenOrigin)\n  const result = validateOrigin(origin, givenOrigin)\n  if (result !== true) {\n    throw new Error(result)\n  }\n\n  if (!origin) {\n    throw new Error('Invalid origin')\n  }\n\n  return origin\n}\n","import fs from 'node:fs'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\n\nimport {addCorsOrigin} from '../../actions/cors/addCorsOrigin'\n\nconst helpText = `\nOptions\n  --credentials Allow credentials (token/cookie) to be sent from this origin\n  --no-credentials Disallow credentials (token/cookie) to be sent from this origin\n\nExamples\n  sanity cors add\n  sanity cors add http://localhost:3000 --no-credentials\n`\n\nconst addCorsOriginCommand: CliCommandDefinition = {\n  name: 'add',\n  group: 'cors',\n  signature: '[ORIGIN]',\n  helpText,\n  description: 'Allow a new origin to use your project API through CORS',\n  action: async (args, context) => {\n    const {output} = context\n    const [origin] = args.argsWithoutOptions\n\n    if (!origin) {\n      throw new Error('No origin specified, use `sanity cors add <origin-url>`')\n    }\n\n    const flags = args.extOptions\n\n    // eslint-disable-next-line no-sync\n    const isFile = fs.existsSync(path.join(process.cwd(), origin))\n    if (isFile) {\n      output.warn(`Origin \"${origin}?\" Remember to quote values (sanity cors add \"*\")`)\n    }\n\n    const success = await addCorsOrigin(origin, flags, context)\n    if (success) {\n      output.print('CORS origin added successfully')\n    }\n  },\n}\n\nexport default addCorsOriginCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst corsGroup: CliCommandGroupDefinition = {\n  name: 'cors',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Configures CORS settings for Sanity projects',\n}\n\nexport default corsGroup\n","import {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\n\nimport {type CorsOrigin} from './types'\n\nconst helpText = `\nExamples\n  sanity cors delete\n  sanity cors delete http://localhost:3000\n`\n\nconst deleteCorsOriginCommand: CliCommandDefinition = {\n  name: 'delete',\n  group: 'cors',\n  signature: '[ORIGIN]',\n  helpText,\n  description: 'Delete an existing CORS-origin from your project',\n  action: async (args, context) => {\n    const {output, apiClient} = context\n    const [origin] = args.argsWithoutOptions\n    const client = apiClient({requireUser: true, requireProject: true})\n    const originId = await promptForOrigin(origin, context)\n    try {\n      await client.request({method: 'DELETE', uri: `/cors/${originId}`})\n      output.print('Origin deleted')\n    } catch (err) {\n      throw new Error(`Origin deletion failed:\\n${err.message}`)\n    }\n  },\n}\n\nexport default deleteCorsOriginCommand\n\nasync function promptForOrigin(specified: string | undefined, context: CliCommandContext) {\n  const specifiedOrigin = specified && specified.toLowerCase()\n  const {prompt, apiClient} = context\n  const client = apiClient({requireUser: true, requireProject: true})\n\n  const origins = await client.request<CorsOrigin[]>({url: '/cors'})\n  if (specifiedOrigin) {\n    const selected = origins.filter((origin) => origin.origin.toLowerCase() === specifiedOrigin)[0]\n    if (!selected) {\n      throw new Error(`Origin \"${specified} not found\"`)\n    }\n\n    return selected.id\n  }\n\n  const choices = origins.map((origin) => ({value: origin.id, name: origin.origin}))\n  return prompt.single({\n    message: 'Select origin to delete',\n    type: 'list',\n    choices,\n  })\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {type CorsOrigin} from './types'\n\nconst helpText = `\nExamples\n  sanity cors list\n`\n\nconst listCorsOriginsCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'cors',\n  signature: '',\n  helpText,\n  description: 'List all origins allowed to access the API for this project',\n  action: async (args, context) => {\n    const {output} = context\n    const {apiClient} = context\n    const client = apiClient({requireUser: true, requireProject: true})\n    const origins = await client.request<CorsOrigin[]>({url: '/cors'})\n    output.print(origins.map((origin) => origin.origin).join('\\n'))\n  },\n}\n\nexport default listCorsOriginsCommand\n","const MAX_DATASET_NAME_LENGTH = 64\n\nexport function validateDatasetAliasName(datasetName: string): false | string {\n  if (!datasetName) {\n    return 'Alias name is missing'\n  }\n\n  const name = `${datasetName}`\n\n  if (name.toLowerCase() !== name) {\n    return 'Alias name must be all lowercase characters'\n  }\n\n  if (name.length < 2) {\n    return 'Alias name must be at least two characters long'\n  }\n\n  if (name.length > MAX_DATASET_NAME_LENGTH) {\n    return `Alias name must be at most ${MAX_DATASET_NAME_LENGTH} characters`\n  }\n\n  if (!/^[a-z0-9~]/.test(name)) {\n    return 'Alias name must start with a letter or a number'\n  }\n\n  if (!/^[a-z0-9~][-_a-z0-9]+$/.test(name)) {\n    return 'Alias name must only contain letters, numbers, dashes and underscores'\n  }\n\n  if (/[-_]$/.test(name)) {\n    return 'Alias name must not end with a dash or an underscore'\n  }\n\n  return false\n}\n","import {type CliPrompter} from '@sanity/cli'\n\nimport {validateDatasetAliasName} from './validateDatasetAliasName'\n\nexport function promptForDatasetAliasName(\n  prompt: CliPrompter,\n  options: {message?: string; default?: string} = {},\n): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Alias name:',\n    validate: (name) => {\n      const err = validateDatasetAliasName(name)\n      if (err) {\n        return err\n      }\n\n      return true\n    },\n    ...options,\n  })\n}\n","import {type SanityClient} from '@sanity/client'\n\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport {type DatasetAliasDefinition, type DatasetModificationResponse} from './types'\n\nexport const ALIAS_PREFIX = '~'\n\nexport function listAliases(client: SanityClient): Promise<DatasetAliasDefinition[]> {\n  return client.request<DatasetAliasDefinition[]>({uri: '/aliases'})\n}\n\nexport function createAlias(\n  client: SanityClient,\n  aliasName: string,\n  datasetName: string | null,\n): Promise<DatasetModificationResponse> {\n  return modify(client, 'PUT', aliasName, datasetName ? {datasetName} : undefined)\n}\n\nexport function updateAlias(\n  client: SanityClient,\n  aliasName: string,\n  datasetName: string | null,\n): Promise<DatasetModificationResponse> {\n  return modify(client, 'PATCH', aliasName, datasetName ? {datasetName} : undefined)\n}\n\nexport function unlinkAlias(\n  client: SanityClient,\n  aliasName: string,\n): Promise<DatasetModificationResponse> {\n  validateDatasetAliasName(aliasName)\n  return modify(client, 'PATCH', `${aliasName}/unlink`, {})\n}\n\nexport function removeAlias(client: SanityClient, aliasName: string): Promise<{deleted: boolean}> {\n  return modify(client, 'DELETE', aliasName)\n}\n\nfunction modify(\n  client: SanityClient,\n  method: string,\n  aliasName: string,\n  body?: {datasetName?: string},\n) {\n  return client.request({method, uri: `/aliases/${aliasName}`, body})\n}\n","import {type CliCommandAction} from '@sanity/cli'\n\nimport {promptForDatasetAliasName} from '../../../actions/dataset/alias/promptForDatasetAliasName'\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport {promptForDatasetName} from '../../../actions/dataset/datasetNamePrompt'\nimport {validateDatasetName} from '../../../actions/dataset/validateDatasetName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nexport const createAliasHandler: CliCommandAction = async (args, context) => {\n  const {apiClient, output, prompt} = context\n  const [, alias, targetDataset] = args.argsWithoutOptions\n  const client = apiClient()\n\n  const nameError = alias && validateDatasetAliasName(alias)\n  if (nameError) {\n    throw new Error(nameError)\n  }\n\n  const [datasets, aliases, projectFeatures] = await Promise.all([\n    client.datasets.list().then((sets) => sets.map((ds) => ds.name)),\n    aliasClient.listAliases(client).then((sets) => sets.map((ds) => ds.name)),\n    client.request({uri: '/features'}),\n  ])\n\n  let aliasName = await (alias || promptForDatasetAliasName(prompt))\n  let aliasOutputName = aliasName\n\n  if (aliasName.startsWith(ALIAS_PREFIX)) {\n    aliasName = aliasName.slice(1)\n  } else {\n    aliasOutputName = `${ALIAS_PREFIX}${aliasName}`\n  }\n\n  if (aliases.includes(aliasName)) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" already exists`)\n  }\n\n  if (targetDataset) {\n    const datasetErr = validateDatasetName(targetDataset)\n    if (datasetErr) {\n      throw new Error(datasetErr)\n    }\n  }\n\n  const datasetName = await (targetDataset || promptForDatasetName(prompt))\n  if (datasetName && !datasets.includes(datasetName)) {\n    throw new Error(`Dataset \"${datasetName}\" does not exist `)\n  }\n\n  const canCreateAlias = projectFeatures.includes('advancedDatasetManagement')\n  if (!canCreateAlias) {\n    throw new Error(`This project cannot create a dataset alias`)\n  }\n\n  try {\n    await aliasClient.createAlias(client, aliasName, datasetName)\n    output.print(\n      `Dataset alias ${aliasOutputName} created ${\n        datasetName && `and linked to ${datasetName}`\n      } successfully`,\n    )\n  } catch (err) {\n    throw new Error(`Dataset alias creation failed:\\n${err.message}`)\n  }\n}\n","import {type CliCommandAction} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2)).option('force', {type: 'boolean'}).argv\n}\n\ninterface DeleteAliasFlags {\n  force?: boolean\n}\n\nexport const deleteAliasHandler: CliCommandAction<DeleteAliasFlags> = async (args, context) => {\n  const {apiClient, prompt, output} = context\n  const [, ds] = args.argsWithoutOptions\n  const {force} = await parseCliFlags(args)\n  const client = apiClient()\n  if (!ds) {\n    throw new Error('Dataset alias name must be provided')\n  }\n\n  let aliasName = `${ds}`\n  const dsError = validateDatasetAliasName(aliasName)\n  if (dsError) {\n    throw dsError\n  }\n  aliasName = aliasName.startsWith(ALIAS_PREFIX) ? aliasName.slice(1) : aliasName\n\n  const [fetchedAliases] = await Promise.all([aliasClient.listAliases(client)])\n  const linkedAlias = fetchedAliases.find((elem) => elem.name === aliasName)\n  const message =\n    linkedAlias && linkedAlias.datasetName\n      ? `This dataset alias is linked to ${linkedAlias.datasetName}. `\n      : ''\n\n  if (force) {\n    output.warn(`'--force' used: skipping confirmation, deleting alias \"${aliasName}\"`)\n  } else {\n    await prompt.single({\n      type: 'input',\n      message: `${message}Are you ABSOLUTELY sure you want to delete this dataset alias?\\n  Type the name of the dataset alias to confirm delete: `,\n      filter: (input) => `${input}`.trim(),\n      validate: (input) => {\n        return input === aliasName || 'Incorrect dataset alias name. Ctrl + C to cancel delete.'\n      },\n    })\n  }\n\n  return aliasClient.removeAlias(client, aliasName).then(() => {\n    output.print('Dataset alias deleted successfully')\n  })\n}\n","import {type CliCommandAction} from '@sanity/cli'\n\nimport {promptForDatasetAliasName} from '../../../actions/dataset/alias/promptForDatasetAliasName'\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport {promptForDatasetName} from '../../../actions/dataset/datasetNamePrompt'\nimport {validateDatasetName} from '../../../actions/dataset/validateDatasetName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nexport const linkAliasHandler: CliCommandAction = async (args, context) => {\n  const {apiClient, output, prompt} = context\n  const [, alias, targetDataset] = args.argsWithoutOptions\n  const flags = args.extOptions\n  const client = apiClient()\n\n  const nameError = alias && validateDatasetAliasName(alias)\n  if (nameError) {\n    throw new Error(nameError)\n  }\n\n  const [datasets, fetchedAliases] = await Promise.all([\n    client.datasets.list().then((sets) => sets.map((ds) => ds.name)),\n    aliasClient.listAliases(client),\n  ])\n  const aliases = fetchedAliases.map((da) => da.name)\n\n  let aliasName = await (alias || promptForDatasetAliasName(prompt))\n  let aliasOutputName = aliasName\n\n  if (aliasName.startsWith(ALIAS_PREFIX)) {\n    aliasName = aliasName.slice(1)\n  } else {\n    aliasOutputName = `${ALIAS_PREFIX}${aliasName}`\n  }\n\n  if (!aliases.includes(aliasName)) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" does not exist `)\n  }\n\n  const datasetName = await (targetDataset || promptForDatasetName(prompt))\n  const datasetErr = validateDatasetName(datasetName)\n  if (datasetErr) {\n    throw new Error(datasetErr)\n  }\n\n  if (!datasets.includes(datasetName)) {\n    throw new Error(`Dataset \"${datasetName}\" does not exist `)\n  }\n\n  const linkedAlias = fetchedAliases.find((elem) => elem.name === aliasName)\n\n  if (linkedAlias && linkedAlias.datasetName) {\n    if (linkedAlias.datasetName === datasetName) {\n      throw new Error(`Dataset alias ${aliasOutputName} already linked to ${datasetName}`)\n    }\n\n    if (!flags.force) {\n      await prompt.single({\n        type: 'input',\n        message: `This alias is linked to dataset <${linkedAlias.datasetName}>. Are you ABSOLUTELY sure you want to link this dataset alias to this dataset?\n        \\n  Type YES/NO: `,\n        filter: (input) => `${input}`.toLowerCase(),\n        validate: (input) => {\n          return input === 'yes' || 'Ctrl + C to cancel dataset alias link.'\n        },\n      })\n    }\n  }\n\n  try {\n    await aliasClient.updateAlias(client, aliasName, datasetName)\n    output.print(`Dataset alias ${aliasOutputName} linked to ${datasetName} successfully`)\n  } catch (err) {\n    throw new Error(`Dataset alias link failed:\\n${err.message}`)\n  }\n}\n","import {type CliCommandAction} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {promptForDatasetAliasName} from '../../../actions/dataset/alias/promptForDatasetAliasName'\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\ninterface UnlinkFlags {\n  force?: boolean\n}\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2)).option('force', {type: 'boolean'}).argv\n}\n\nexport const unlinkAliasHandler: CliCommandAction<UnlinkFlags> = async (args, context) => {\n  const {apiClient, output, prompt} = context\n  const [, alias] = args.argsWithoutOptions\n  const {force} = await parseCliFlags(args)\n  const client = apiClient()\n\n  const nameError = alias && validateDatasetAliasName(alias)\n  if (nameError) {\n    throw new Error(nameError)\n  }\n\n  const fetchedAliases = await aliasClient.listAliases(client)\n\n  let aliasName = await (alias || promptForDatasetAliasName(prompt))\n  let aliasOutputName = aliasName\n\n  if (aliasName.startsWith(ALIAS_PREFIX)) {\n    aliasName = aliasName.slice(1)\n  } else {\n    aliasOutputName = `${ALIAS_PREFIX}${aliasName}`\n  }\n\n  // get the current alias from the remote alias list\n  const linkedAlias = fetchedAliases.find((elem) => elem.name === aliasName)\n  if (!linkedAlias) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" does not exist`)\n  }\n\n  if (!linkedAlias.datasetName) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" is not linked to a dataset`)\n  }\n\n  if (force) {\n    output.warn(`'--force' used: skipping confirmation, unlinking alias \"${aliasOutputName}\"`)\n  } else {\n    await prompt.single({\n      type: 'input',\n      message: `Are you ABSOLUTELY sure you want to unlink this alias from the \"${linkedAlias.datasetName}\" dataset?\n        \\n  Type YES/NO: `,\n      filter: (input) => `${input}`.toLowerCase(),\n      validate: (input) => {\n        return input === 'yes' || 'Ctrl + C to cancel dataset alias unlink.'\n      },\n    })\n  }\n\n  try {\n    const result = await aliasClient.unlinkAlias(client, aliasName)\n    output.print(\n      `Dataset alias ${aliasOutputName} unlinked from ${result.datasetName} successfully`,\n    )\n  } catch (err) {\n    throw new Error(`Dataset alias unlink failed:\\n${err.message}`)\n  }\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport oneline from 'oneline'\n\nimport {createAliasHandler} from './createAliasHandler'\nimport {deleteAliasHandler} from './deleteAliasHandler'\nimport {linkAliasHandler} from './linkAliasHandler'\nimport {unlinkAliasHandler} from './unlinkAliasHandler'\n\nconst helpText = `\nBelow are examples of the alias subcommand\n\nCreate Alias\n  sanity dataset alias create\n  sanity dataset alias create <alias-name>\n  sanity dataset alias create <alias-name> <target-dataset>\n\nDelete Alias\n  Options\n    --force Skips security prompt and forces link command\n\n  Usage\n    sanity dataset alias delete <alias-name>\n    sanity dataset alias delete <alias-name> --force\n\nLink Alias\n  Options\n    --force Skips security prompt and forces link command\n\n  Usage\n    sanity dataset alias link\n    sanity dataset alias link <alias-name>\n    sanity dataset alias link <alias-name> <target-dataset>\n    sanity dataset alias link <alias-name> <target-dataset> --force\n\nUn-link Alias\n  Options\n    --force Skips security prompt and forces link command\n\n  Usage\n    sanity dataset alias unlink\n    sanity dataset alias unlink <alias-name>\n    sanity dataset alias unlink <alias-name> --force\n`\n\nconst aliasCommand: CliCommandDefinition = {\n  name: 'alias',\n  group: 'dataset',\n  signature: 'SUBCOMMAND [ALIAS_NAME, TARGET_DATASET]',\n  helpText,\n  description: 'You can manage your dataset alias using this command.',\n  action: async (args, context) => {\n    const [verb] = args.argsWithoutOptions\n    switch (verb) {\n      case 'create':\n        await createAliasHandler(args, context)\n        break\n      case 'delete':\n        await deleteAliasHandler(args, context)\n        break\n      case 'unlink':\n        await unlinkAliasHandler(args, context)\n        break\n      case 'link':\n        await linkAliasHandler(args, context)\n        break\n      default:\n        throw new Error(oneline`\n          Invalid command provided. Available commands are: create, delete, link and unlink.\n          For more guide run the help command 'sanity dataset alias --help'\n        `)\n    }\n  },\n}\n\nexport default aliasCommand\n","import {type CliCommandContext} from '@sanity/cli'\nimport {Table} from 'console-table-printer'\nimport {formatDistance, formatDistanceToNow, parseISO} from 'date-fns'\n\ninterface ListFlags {\n  offset?: number\n  limit?: number\n}\n\ntype CopyDatasetListResponse = {\n  id: string\n  state: string\n  createdAt: string\n  updatedAt: string\n  sourceDataset: string\n  targetDataset: string\n  withHistory: boolean\n}[]\n\nexport async function listDatasetCopyJobs(\n  flags: ListFlags,\n  context: CliCommandContext,\n): Promise<void> {\n  const {apiClient, output, chalk} = context\n  const client = apiClient()\n  const projectId = client.config().projectId\n  const query: {offset?: string; limit?: string} = {}\n  let response\n\n  if (flags.offset && flags.offset >= 0) {\n    query.offset = `${flags.offset}`\n  }\n  if (flags.limit && flags.limit > 0) {\n    query.limit = `${flags.limit}`\n  }\n\n  try {\n    response = await client.request<CopyDatasetListResponse>({\n      method: 'GET',\n      uri: `/projects/${projectId}/datasets/copy`,\n      query,\n    })\n  } catch (error) {\n    if (error.statusCode) {\n      output.error(`${chalk.red(`Dataset copy list failed:\\n${error.response.body.message}`)}\\n`)\n    } else {\n      output.error(`${chalk.red(`Dataset copy list failed:\\n${error.message}`)}\\n`)\n    }\n  }\n\n  if (response && response.length > 0) {\n    const table = new Table({\n      title: 'Dataset copy jobs for this project in descending order',\n      columns: [\n        {name: 'id', title: 'Job ID', alignment: 'left'},\n        {name: 'sourceDataset', title: 'Source Dataset', alignment: 'left'},\n        {name: 'targetDataset', title: 'Target Dataset', alignment: 'left'},\n        {name: 'state', title: 'State', alignment: 'left'},\n        {name: 'withHistory', title: 'With history', alignment: 'left'},\n        {name: 'timeStarted', title: 'Time started', alignment: 'left'},\n        {name: 'timeTaken', title: 'Time taken', alignment: 'left'},\n      ],\n    })\n\n    response.forEach((job) => {\n      const {id, state, createdAt, updatedAt, sourceDataset, targetDataset, withHistory} = job\n\n      let timeStarted = ''\n      if (createdAt !== '') {\n        timeStarted = formatDistanceToNow(parseISO(createdAt))\n      }\n\n      let timeTaken = ''\n      if (updatedAt !== '') {\n        timeTaken = formatDistance(parseISO(updatedAt), parseISO(createdAt))\n      }\n\n      let color\n      switch (state) {\n        case 'completed':\n          color = 'green'\n          break\n        case 'failed':\n          color = 'red'\n          break\n        case 'pending':\n          color = 'yellow'\n          break\n        default:\n          color = ''\n      }\n\n      table.addRow(\n        {\n          id,\n          state,\n          withHistory,\n          timeStarted: `${timeStarted} ago`,\n          timeTaken,\n          sourceDataset,\n          targetDataset,\n        },\n        {color},\n      )\n    })\n\n    table.printTable()\n  } else {\n    output.print(\"This project doesn't have any dataset copy jobs\")\n  }\n}\n","import {type SanityClient} from '@sanity/client'\n\nexport const getClientUrl = (client: SanityClient, uri: string, useCdn = false): string => {\n  const config = client.config()\n  const base = useCdn ? config.cdnUrl : config.url\n  return `${base}/${uri.replace(/^\\//, '')}`\n}\n","import {type CliCommandDefinition, type CliOutputter} from '@sanity/cli'\nimport {type SanityClient} from '@sanity/client'\nimport EventSource from '@sanity/eventsource'\nimport {Observable} from 'rxjs'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {promptForDatasetName} from '../../actions/dataset/datasetNamePrompt'\nimport {listDatasetCopyJobs} from '../../actions/dataset/listDatasetCopyJobs'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\nimport {debug} from '../../debug'\nimport {getClientUrl} from '../../util/getClientUrl'\n\nconst helpText = `\nOptions\n  --detach Start the copy without waiting for it to finish\n  --attach <job-id> Attach to the running copy process to show progress\n  --skip-history Don't preserve document history on copy\n  --list Lists all dataset copy jobs corresponding to a certain criteria.\n  --offset Start position in the list of jobs. Default 0. With --list.\n  --limit Maximum number of jobs returned. Default 10. Maximum 1000. With --list.\n\nExamples\n  sanity dataset copy\n  sanity dataset copy <source-dataset>\n  sanity dataset copy <source-dataset> <target-dataset>\n  sanity dataset copy --skip-history <source-dataset> <target-dataset>\n  sanity dataset copy --detach <source-dataset> <target-dataset>\n  sanity dataset copy --attach <job-id>\n  sanity dataset copy --list\n  sanity dataset copy --list --offset=2\n  sanity dataset copy --list --offset=2 --limit=10\n`\n\ninterface CopyProgressStreamEvent {\n  type: 'reconnect' | string\n  progress?: number\n}\n\ninterface CopyDatasetFlags {\n  'list'?: boolean\n  'attach'?: string\n  'detach'?: boolean\n  'offset'?: number\n  'limit'?: number\n  'skip-history'?: boolean\n}\n\ninterface CopyDatasetResponse {\n  jobId: string\n}\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .option('attach', {type: 'string'})\n    .option('list', {type: 'boolean'})\n    .option('limit', {type: 'number'})\n    .option('offset', {type: 'number'})\n    .option('skip-history', {type: 'boolean'})\n    .option('detach', {type: 'boolean'}).argv\n}\n\nconst progress = (url: string) => {\n  return new Observable<CopyProgressStreamEvent>((observer) => {\n    let progressSource = new EventSource(url)\n    let stopped = false\n\n    function onError(error: unknown) {\n      if (progressSource) {\n        progressSource.close()\n      }\n\n      debug(`Error received: ${error}`)\n      if (stopped) {\n        return\n      }\n      observer.next({type: 'reconnect'})\n      progressSource = new EventSource(url)\n    }\n\n    function onChannelError(error: MessageEvent) {\n      stopped = true\n      progressSource.close()\n      observer.error(error)\n    }\n\n    function onMessage(event: MessageEvent) {\n      const data = JSON.parse(event.data)\n      if (data.state === 'failed') {\n        debug('Job failed. Data: %o', event)\n        observer.error(event)\n      } else if (data.state === 'completed') {\n        debug('Job succeeded. Data: %o', event)\n        onComplete()\n      } else {\n        debug(`Job progressed. Data: %o`, event)\n        observer.next(data)\n      }\n    }\n\n    function onComplete() {\n      progressSource.removeEventListener('error', onError)\n      progressSource.removeEventListener('channel_error', onChannelError)\n      progressSource.removeEventListener('job', onMessage)\n      progressSource.removeEventListener('done', onComplete)\n      progressSource.close()\n      observer.complete()\n    }\n\n    progressSource.addEventListener('error', onError)\n    progressSource.addEventListener('channel_error', onChannelError)\n    progressSource.addEventListener('job', onMessage)\n    progressSource.addEventListener('done', onComplete)\n  })\n}\n\nconst followProgress = (\n  jobId: string,\n  client: SanityClient,\n  output: CliOutputter,\n): Promise<void> => {\n  let currentProgress = 0\n\n  const spinner = output.spinner({}).start()\n  const listenUrl = getClientUrl(client, `jobs/${jobId}/listen`)\n\n  debug(`Listening to ${listenUrl}`)\n\n  return new Promise((resolve, reject) => {\n    progress(listenUrl).subscribe({\n      next: (event) => {\n        if (typeof event.progress === 'number') {\n          currentProgress = event.progress\n        }\n\n        spinner.text = `Copy in progress: ${currentProgress}%`\n      },\n      error: (err) => {\n        spinner.fail()\n        reject(new Error(`${err.data}`))\n      },\n      complete: () => {\n        spinner.succeed('Copy finished.')\n        resolve()\n      },\n    })\n  })\n}\n\nconst copyDatasetCommand: CliCommandDefinition<CopyDatasetFlags> = {\n  name: 'copy',\n  group: 'dataset',\n  signature: '[SOURCE_DATASET] [TARGET_DATASET]',\n  helpText,\n  description:\n    'Manages dataset copying, including starting a new copy job, listing copy jobs and following the progress of a running copy job',\n  action: async (args, context) => {\n    const {apiClient, output, prompt, chalk} = context\n    // Reparsing CLI flags for better control of binary flags\n    const flags: CopyDatasetFlags = await parseCliFlags(args)\n    const client = apiClient()\n\n    if (flags.list) {\n      await listDatasetCopyJobs(flags, context)\n      return\n    }\n\n    if (flags.attach) {\n      const jobId = flags.attach\n\n      if (!jobId) {\n        throw new Error('Please supply a jobId')\n      }\n\n      await followProgress(jobId, client, output)\n      return\n    }\n\n    const [sourceDataset, targetDataset] = args.argsWithoutOptions\n    const shouldSkipHistory = Boolean(flags['skip-history'])\n\n    const nameError = sourceDataset && validateDatasetName(sourceDataset)\n    if (nameError) {\n      throw new Error(nameError)\n    }\n\n    const existingDatasets = await client.datasets\n      .list()\n      .then((datasets) => datasets.map((ds) => ds.name))\n\n    const sourceDatasetName = await (sourceDataset ||\n      promptForDatasetName(prompt, {message: 'Source dataset name:'}))\n    if (!existingDatasets.includes(sourceDatasetName)) {\n      throw new Error(`Source dataset \"${sourceDatasetName}\" doesn't exist`)\n    }\n\n    const targetDatasetName = await (targetDataset ||\n      promptForDatasetName(prompt, {message: 'Target dataset name:'}))\n    if (existingDatasets.includes(targetDatasetName)) {\n      throw new Error(`Target dataset \"${targetDatasetName}\" already exists`)\n    }\n\n    const err = validateDatasetName(targetDatasetName)\n    if (err) {\n      throw new Error(err)\n    }\n\n    try {\n      const response = await client.request<CopyDatasetResponse>({\n        method: 'PUT',\n        uri: `/datasets/${sourceDatasetName}/copy`,\n        body: {\n          targetDataset: targetDatasetName,\n          skipHistory: shouldSkipHistory,\n        },\n      })\n\n      output.print(\n        `Copying dataset ${chalk.green(sourceDatasetName)} to ${chalk.green(targetDatasetName)}...`,\n      )\n\n      if (!shouldSkipHistory) {\n        output.print(\n          `Note: You can run this command with flag '--skip-history'. The flag will reduce copy time in larger datasets.`,\n        )\n      }\n\n      output.print(`Job ${chalk.green(response.jobId)} started`)\n\n      if (flags.detach) {\n        return\n      }\n\n      await followProgress(response.jobId, client, output)\n      output.print(`Job ${chalk.green(response.jobId)} completed`)\n    } catch (error) {\n      if (error.statusCode) {\n        output.print(`${chalk.red(`Dataset copying failed:\\n${error.response.body.message}`)}\\n`)\n      } else {\n        output.print(`${chalk.red(`Dataset copying failed:\\n${error.message}`)}\\n`)\n      }\n    }\n  },\n}\n\nexport default copyDatasetCommand\n","import {type CliCommandDefinition, type CliOutputter, type CliPrompter} from '@sanity/cli'\n\nimport {promptForDatasetName} from '../../actions/dataset/datasetNamePrompt'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\nimport {debug} from '../../debug'\n\nconst helpText = `\nOptions\n  --visibility <mode> Set visibility for this dataset (public/private)\n\nExamples\n  sanity dataset create\n  sanity dataset create <name>\n  sanity dataset create <name> --visibility private\n`\n\nconst allowedModes = ['private', 'public', 'custom']\n\ninterface CreateFlags {\n  visibility?: 'private' | 'public' | 'custom'\n}\n\nconst createDatasetCommand: CliCommandDefinition<CreateFlags> = {\n  name: 'create',\n  group: 'dataset',\n  signature: '[NAME]',\n  helpText,\n  description: 'Create a new dataset within your project',\n  action: async (args, context) => {\n    const {apiClient, output, prompt} = context\n    const flags = args.extOptions\n    const [dataset] = args.argsWithoutOptions\n    const client = apiClient()\n\n    const nameError = dataset && validateDatasetName(dataset)\n    if (nameError) {\n      throw new Error(nameError)\n    }\n\n    const [datasets, projectFeatures] = await Promise.all([\n      client.datasets.list().then((sets) => sets.map((ds) => ds.name)),\n      client.request({uri: '/features'}),\n    ])\n\n    if (flags.visibility && !allowedModes.includes(flags.visibility)) {\n      throw new Error(`Visibility mode \"${flags.visibility}\" not allowed`)\n    }\n\n    const datasetName = await (dataset || promptForDatasetName(prompt))\n    if (datasets.includes(datasetName)) {\n      throw new Error(`Dataset \"${datasetName}\" already exists`)\n    }\n\n    const canCreatePrivate = projectFeatures.includes('privateDataset')\n    debug('%s create private datasets', canCreatePrivate ? 'Can' : 'Cannot')\n\n    const defaultAclMode = canCreatePrivate ? flags.visibility : 'public'\n    const aclMode = await (defaultAclMode || promptForDatasetVisibility(prompt, output))\n\n    try {\n      await client.datasets.create(datasetName, {aclMode})\n      output.print('Dataset created successfully')\n    } catch (err) {\n      throw new Error(`Dataset creation failed:\\n${err.message}`)\n    }\n  },\n}\n\nasync function promptForDatasetVisibility(prompt: CliPrompter, output: CliOutputter) {\n  const mode = await prompt.single<'public' | 'private'>({\n    type: 'list',\n    message: 'Dataset visibility',\n    choices: [\n      {\n        value: 'public',\n        name: 'Public (world readable)',\n      },\n      {\n        value: 'private',\n        name: 'Private (Authenticated user or token needed)',\n      },\n    ],\n  })\n\n  if (mode === 'private') {\n    output.print(\n      'Please note that while documents are private, assets (files and images) are still public\\n',\n    )\n  }\n\n  return mode\n}\n\nexport default createDatasetCommand\n","export default {\n  name: 'dataset',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages datasets, like create or delete, within projects',\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\n\nconst datasetVisibilityCommand: CliCommandDefinition = {\n  name: 'visibility',\n  group: 'dataset',\n  helpText: '',\n  signature: 'get/set [dataset] [mode]',\n  description: 'Set visibility of a dataset',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const [action, ds, aclMode] = args.argsWithoutOptions\n    const client = apiClient()\n\n    if (!client.datasets.edit) {\n      throw new Error('@sanity/cli must be upgraded first:\\n  npm install -g @sanity/cli')\n    }\n\n    if (!action) {\n      throw new Error('Action must be provided (get/set)')\n    }\n\n    if (!['set', 'get'].includes(action)) {\n      throw new Error('Invalid action (only get/set allowed)')\n    }\n\n    if (!ds) {\n      throw new Error('Dataset name must be provided')\n    }\n\n    if (action === 'set' && !aclMode) {\n      throw new Error('Please provide a visibility mode (public/private)')\n    }\n\n    const dataset = `${ds}`\n    const dsError = validateDatasetName(dataset)\n    if (dsError) {\n      throw new Error(dsError)\n    }\n\n    const current = (await client.datasets.list()).find((curr) => curr.name === dataset)\n\n    if (!current) {\n      throw new Error('Dataset not found')\n    }\n\n    if (action === 'get') {\n      output.print(current.aclMode)\n      return\n    }\n\n    if (current.aclMode === aclMode) {\n      output.print(`Dataset already in \"${aclMode}\"-mode`)\n      return\n    }\n\n    if (aclMode === 'private') {\n      output.print(\n        'Please note that while documents are private, assets (files and images) are still public\\n',\n      )\n    }\n\n    await client.datasets.edit(dataset, {aclMode: aclMode as 'public' | 'private'})\n    output.print('Dataset visibility changed')\n  },\n}\n\nexport default datasetVisibilityCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\n\nconst helpText = `\nOptions\n  --force Do not prompt for delete confirmation - forcefully delete\n\nExamples\n  sanity dataset delete\n  sanity dataset delete my-dataset\n  sanity dataset delete my-dataset --force\n`\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2)).option('force', {type: 'boolean'}).argv\n}\n\ninterface DeleteDatasetFlags {\n  force?: boolean\n}\n\nconst deleteDatasetCommand: CliCommandDefinition<DeleteDatasetFlags> = {\n  name: 'delete',\n  group: 'dataset',\n  helpText,\n  signature: '[datasetName]',\n  description: 'Delete a dataset within your project',\n  action: async (args, context) => {\n    const {apiClient, prompt, output} = context\n    const {force} = await parseCliFlags(args)\n    const [ds] = args.argsWithoutOptions\n    if (!ds) {\n      throw new Error('Dataset name must be provided')\n    }\n\n    const dataset = `${ds}`\n    const dsError = validateDatasetName(dataset)\n    if (dsError) {\n      throw dsError\n    }\n\n    if (force) {\n      output.warn(`'--force' used: skipping confirmation, deleting dataset \"${dataset}\"`)\n    } else {\n      await prompt.single({\n        type: 'input',\n        message:\n          'Are you ABSOLUTELY sure you want to delete this dataset?\\n  Type the name of the dataset to confirm delete:',\n        filter: (input) => `${input}`.trim(),\n        validate: (input) => {\n          return input === dataset || 'Incorrect dataset name. Ctrl + C to cancel delete.'\n        },\n      })\n    }\n\n    await apiClient().datasets.delete(dataset)\n    output.print('Dataset deleted successfully')\n  },\n}\n\nexport default deleteDatasetCommand\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition, type CliPrompter} from '@sanity/cli'\nimport exportDataset from '@sanity/export'\nimport {absolutify} from '@sanity/util/fs'\nimport prettyMs from 'pretty-ms'\n\nimport {chooseDatasetPrompt} from '../../actions/dataset/chooseDatasetPrompt'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\n\nconst noop = () => null\n\nconst helpText = `\nOptions\n  --raw                     Extract only documents, without rewriting asset references\n  --no-assets               Export only non-asset documents and remove references to image assets\n  --no-drafts               Export only published versions of documents\n  --no-compress             Skips compressing tarball entries (still generates a gzip file)\n  --types                   Defines which document types to export\n  --overwrite               Overwrite any file with the same name\n  --asset-concurrency <num> Concurrent number of asset downloads\n\nExamples\n  sanity dataset export moviedb localPath.tar.gz\n  sanity dataset export moviedb assetless.tar.gz --no-assets\n  sanity dataset export staging staging.tar.gz --raw\n  sanity dataset export staging staging.tar.gz --types products,shops\n`\n\ninterface ExportFlags {\n  'raw'?: boolean\n  'assets'?: boolean\n  'drafts'?: boolean\n  'compress'?: boolean\n  'overwrite'?: boolean\n  'types'?: string\n  'asset-concurrency'?: string\n}\n\ninterface ParsedExportFlags {\n  raw?: boolean\n  assets?: boolean\n  drafts?: boolean\n  compress?: boolean\n  overwrite?: boolean\n  types?: string[]\n  assetConcurrency?: number\n}\n\nfunction parseFlags(rawFlags: ExportFlags): ParsedExportFlags {\n  const flags: ParsedExportFlags = {}\n  if (rawFlags.types) {\n    flags.types = `${rawFlags.types}`.split(',')\n  }\n\n  if (rawFlags['asset-concurrency']) {\n    flags.assetConcurrency = parseInt(rawFlags['asset-concurrency'], 10)\n  }\n\n  if (typeof rawFlags.raw !== 'undefined') {\n    flags.raw = Boolean(rawFlags.raw)\n  }\n\n  if (typeof rawFlags.assets !== 'undefined') {\n    flags.assets = Boolean(rawFlags.assets)\n  }\n\n  if (typeof rawFlags.drafts !== 'undefined') {\n    flags.drafts = Boolean(rawFlags.drafts)\n  }\n\n  if (typeof rawFlags.compress !== 'undefined') {\n    flags.compress = Boolean(rawFlags.compress)\n  }\n\n  if (typeof rawFlags.overwrite !== 'undefined') {\n    flags.overwrite = Boolean(rawFlags.overwrite)\n  }\n\n  return flags\n}\n\ninterface ProgressEvent {\n  step: string\n  update?: boolean\n  current: number\n  total: number\n}\n\nconst exportDatasetCommand: CliCommandDefinition<ExportFlags> = {\n  name: 'export',\n  group: 'dataset',\n  signature: '[NAME] [DESTINATION]',\n  description: 'Export dataset to local filesystem as a gzipped tarball',\n  helpText,\n  action: async (args, context) => {\n    const {apiClient, output, chalk, workDir, prompt} = context\n    const client = apiClient()\n    const [targetDataset, targetDestination] = args.argsWithoutOptions\n    const flags = parseFlags(args.extOptions)\n\n    let dataset = targetDataset ? `${targetDataset}` : null\n    if (!dataset) {\n      dataset = await chooseDatasetPrompt(context, {message: 'Select dataset to export'})\n    }\n\n    const dsError = validateDatasetName(dataset)\n    if (dsError) {\n      throw dsError\n    }\n\n    // Verify existence of dataset before trying to export from it\n    const datasets = await client.datasets.list()\n    if (!datasets.find((set) => set.name === dataset)) {\n      throw new Error(`Dataset with name \"${dataset}\" not found`)\n    }\n\n    // Print information about what projectId and dataset it is being exported from\n    const {projectId} = client.config()\n\n    output.print('╭───────────────────────────────────────────────╮')\n    output.print('│                                               │')\n    output.print('│ Exporting from:                               │')\n    output.print(`│ ${chalk.bold('projectId')}: ${chalk.cyan(projectId).padEnd(44)} │`)\n    output.print(`│ ${chalk.bold('dataset')}: ${chalk.cyan(dataset).padEnd(46)} │`)\n    output.print('│                                               │')\n    output.print('╰───────────────────────────────────────────────╯')\n    output.print('')\n\n    let destinationPath = targetDestination\n    if (!destinationPath) {\n      destinationPath = await prompt.single({\n        type: 'input',\n        message: 'Output path:',\n        default: path.join(workDir, `${dataset}.tar.gz`),\n        filter: absolutify,\n      })\n    }\n\n    const outputPath = await getOutputPath(destinationPath, dataset, prompt, flags)\n    if (!outputPath) {\n      output.print('Cancelled')\n      return\n    }\n\n    // If we are dumping to a file, let the user know where it's at\n    if (outputPath !== '-') {\n      output.print(`Exporting dataset \"${chalk.cyan(dataset)}\" to \"${chalk.cyan(outputPath)}\"`)\n    }\n\n    let currentStep = 'Exporting documents...'\n    let spinner = output.spinner(currentStep).start()\n    const onProgress = (progress: ProgressEvent) => {\n      if (progress.step !== currentStep) {\n        spinner.succeed()\n        spinner = output.spinner(progress.step).start()\n      } else if (progress.step === currentStep && progress.update) {\n        spinner.text = `${progress.step} (${progress.current}/${progress.total})`\n      }\n\n      currentStep = progress.step\n    }\n\n    const start = Date.now()\n    try {\n      await exportDataset({\n        client,\n        dataset,\n        outputPath,\n        onProgress,\n        ...flags,\n      })\n      spinner.succeed()\n    } catch (err) {\n      spinner.fail()\n      throw err\n    }\n\n    output.print(`Export finished (${prettyMs(Date.now() - start)})`)\n  },\n}\n\n// eslint-disable-next-line complexity\nasync function getOutputPath(\n  destination: string,\n  dataset: string,\n  prompt: CliPrompter,\n  flags: ParsedExportFlags,\n) {\n  if (destination === '-') {\n    return '-'\n  }\n\n  const dstPath = path.isAbsolute(destination)\n    ? destination\n    : path.resolve(process.cwd(), destination)\n\n  let dstStats = await fs.stat(dstPath).catch(noop)\n  const looksLikeFile = dstStats ? dstStats.isFile() : path.basename(dstPath).indexOf('.') !== -1\n\n  if (!dstStats) {\n    const createPath = looksLikeFile ? path.dirname(dstPath) : dstPath\n\n    await fs.mkdir(createPath, {recursive: true})\n  }\n\n  const finalPath = looksLikeFile ? dstPath : path.join(dstPath, `${dataset}.tar.gz`)\n  dstStats = await fs.stat(finalPath).catch(noop)\n\n  if (!flags.overwrite && dstStats && dstStats.isFile()) {\n    const shouldOverwrite = await prompt.single({\n      type: 'confirm',\n      message: `File \"${finalPath}\" already exists, would you like to overwrite it?`,\n      default: false,\n    })\n\n    if (!shouldOverwrite) {\n      return false\n    }\n  }\n\n  return finalPath\n}\n\nexport default exportDatasetCommand\n","import {createReadStream} from 'node:fs'\nimport fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandContext, type CliCommandDefinition, type CliOutputter} from '@sanity/cli'\nimport sanityImport from '@sanity/import'\nimport {getIt} from 'get-it'\n// eslint-disable-next-line import/extensions\nimport {promise} from 'get-it/middleware'\nimport {padStart} from 'lodash'\nimport prettyMs from 'pretty-ms'\n\nimport {chooseDatasetPrompt} from '../../actions/dataset/chooseDatasetPrompt'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\nimport {debug} from '../../debug'\n\nconst yellow = (str: string) => `\\u001b[33m${str}\\u001b[39m`\n\nconst helpText = `\nOptions\n  --missing On duplicate document IDs, skip importing document in question\n  --replace On duplicate document IDs, replace existing document with imported document\n  --allow-failing-assets Skip assets that cannot be fetched/uploaded\n  --replace-assets Skip reuse of existing assets\n  --skip-cross-dataset-references Skips references to other datasets\n\nRarely used options (should generally not be used)\n  --allow-assets-in-different-dataset Allow asset documents to reference different project/dataset\n  --allow-system-documents Allow system documents like dataset permissions and custom retention to be imported\n\nExamples\n  # Import \"moviedb.ndjson\" from the current directory to the dataset called \"moviedb\"\n  sanity dataset import moviedb.ndjson moviedb\n\n  # Import \"moviedb.tar.gz\" from the current directory to the dataset called \"moviedb\",\n  # replacing any documents encountered that have the same document IDs\n  sanity dataset import moviedb.tar.gz moviedb --replace\n\n  # Import from a folder containing an ndjson file, such as an extracted tarball\n  # retrieved through \"sanity dataset export\".\n  sanity dataset import ~/some/folder moviedb\n\n  # Import from a remote URL. Will download and extract the tarball to a temporary\n  # location before importing it.\n  sanity dataset import https://some.url/moviedb.tar.gz moviedb --replace\n`\n\ninterface ImportFlags {\n  'allow-assets-in-different-dataset'?: boolean\n  'allow-failing-assets'?: boolean\n  'asset-concurrency'?: boolean\n  'replace-assets'?: boolean\n  'skip-cross-dataset-references'?: boolean\n  'allow-system-documents'?: boolean\n  'replace'?: boolean\n  'missing'?: boolean\n}\n\ninterface ParsedImportFlags {\n  allowAssetsInDifferentDataset?: boolean\n  allowFailingAssets?: boolean\n  assetConcurrency?: boolean\n  skipCrossDatasetReferences?: boolean\n  allowSystemDocuments?: boolean\n  replaceAssets?: boolean\n  replace?: boolean\n  missing?: boolean\n}\n\ninterface ProgressEvent {\n  step: string\n  total?: number\n  current?: number\n}\n\ninterface ImportWarning {\n  type?: string\n  url?: string\n}\n\nfunction toBoolIfSet(flag: unknown): boolean | undefined {\n  return typeof flag === 'undefined' ? undefined : Boolean(flag)\n}\n\nfunction parseFlags(rawFlags: ImportFlags): ParsedImportFlags {\n  const allowAssetsInDifferentDataset = toBoolIfSet(rawFlags['allow-assets-in-different-dataset'])\n  const allowFailingAssets = toBoolIfSet(rawFlags['allow-failing-assets'])\n  const assetConcurrency = toBoolIfSet(rawFlags['asset-concurrency'])\n  const replaceAssets = toBoolIfSet(rawFlags['replace-assets'])\n  const skipCrossDatasetReferences = toBoolIfSet(rawFlags['skip-cross-dataset-references'])\n  const allowSystemDocuments = toBoolIfSet(rawFlags['allow-system-documents'])\n  const replace = toBoolIfSet(rawFlags.replace)\n  const missing = toBoolIfSet(rawFlags.missing)\n  return {\n    allowAssetsInDifferentDataset,\n    allowFailingAssets,\n    assetConcurrency,\n    skipCrossDatasetReferences,\n    allowSystemDocuments,\n    replaceAssets,\n    replace,\n    missing,\n  }\n}\n\nconst importDatasetCommand: CliCommandDefinition = {\n  name: 'import',\n  group: 'dataset',\n  signature: '[FILE | FOLDER | URL] [TARGET_DATASET]',\n  description: 'Import documents to given dataset from either an ndjson file or a gzipped tarball',\n  helpText,\n  // eslint-disable-next-line max-statements\n  action: async (args, context) => {\n    const {apiClient, output, chalk, fromInitCommand} = context\n    const flags = parseFlags(args.extOptions)\n    const {\n      allowAssetsInDifferentDataset,\n      allowFailingAssets,\n      assetConcurrency,\n      skipCrossDatasetReferences,\n      allowSystemDocuments,\n      replaceAssets,\n    } = flags\n\n    const operation = getMutationOperation(args.extOptions)\n    const client = apiClient()\n\n    const [file, target] = args.argsWithoutOptions\n    if (!file) {\n      throw new Error(\n        `Source file name and target dataset must be specified (\"sanity dataset import ${chalk.bold(\n          '[file]',\n        )} [dataset]\")`,\n      )\n    }\n\n    const targetDataset = await determineTargetDataset(target, context)\n    debug(`Target dataset has been set to \"${targetDataset}\"`)\n\n    const isUrl = /^https?:\\/\\//i.test(file)\n    let inputStream\n    let assetsBase\n    let sourceIsFolder = false\n\n    if (isUrl) {\n      debug('Input is a URL, streaming from source URL')\n      inputStream = await getUrlStream(file)\n    } else {\n      const sourceFile = path.resolve(process.cwd(), file)\n      const fileStats = await fs.stat(sourceFile).catch(() => null)\n      if (!fileStats) {\n        throw new Error(`${sourceFile} does not exist or is not readable`)\n      }\n\n      sourceIsFolder = fileStats.isDirectory()\n      if (sourceIsFolder) {\n        inputStream = sourceFile\n      } else {\n        assetsBase = path.dirname(sourceFile)\n        inputStream = await createReadStream(sourceFile)\n      }\n    }\n\n    const importClient = client.clone().config({dataset: targetDataset})\n\n    // Print information about what projectId and dataset it is being imported to\n    const {projectId, dataset} = importClient.config()\n\n    output.print('╭───────────────────────────────────────────────╮')\n    output.print('│                                               │')\n    output.print('│ Importing to:                                 │')\n    output.print(`│ ${chalk.bold('projectId')}: ${chalk.cyan(projectId).padEnd(44)} │`)\n    output.print(`│ ${chalk.bold('dataset')}: ${chalk.cyan(dataset).padEnd(46)} │`)\n    output.print('│                                               │')\n    output.print('╰───────────────────────────────────────────────╯')\n    output.print('')\n\n    let currentStep: string | undefined\n    let currentProgress: ReturnType<CliOutputter['spinner']> | undefined\n    let stepStart: number | undefined\n    let spinInterval: ReturnType<typeof setInterval> | null = null\n    let percent: string | undefined\n\n    function onProgress(opts: ProgressEvent) {\n      const lengthComputable = opts.total\n      const sameStep = opts.step == currentStep\n      percent = getPercentage(opts)\n\n      if (lengthComputable && opts.total === opts.current) {\n        if (spinInterval) {\n          clearInterval(spinInterval)\n        }\n        spinInterval = null\n      }\n\n      if (sameStep) {\n        return\n      }\n\n      // Moved to a new step\n      const prevStep = currentStep\n      const prevStepStart = stepStart || Date.now()\n      stepStart = Date.now()\n      currentStep = opts.step\n\n      if (currentProgress && currentProgress.succeed) {\n        const timeSpent = prettyMs(Date.now() - prevStepStart, {\n          secondsDecimalDigits: 2,\n        })\n        currentProgress.text = `[100%] ${prevStep} (${timeSpent})`\n        currentProgress.succeed()\n      }\n\n      currentProgress = output.spinner(`[0%] ${opts.step} (0.00s)`).start()\n\n      if (spinInterval) {\n        clearInterval(spinInterval)\n        spinInterval = null\n      }\n\n      spinInterval = setInterval(() => {\n        const timeSpent = prettyMs(Date.now() - prevStepStart, {\n          secondsDecimalDigits: 2,\n        })\n\n        if (currentProgress) {\n          currentProgress.text = `${percent}${opts.step} (${timeSpent})`\n        }\n      }, 60)\n    }\n\n    function endTask({success}: {success: boolean}) {\n      if (spinInterval) {\n        clearInterval(spinInterval)\n      }\n\n      spinInterval = null\n\n      if (success && stepStart && currentProgress) {\n        const timeSpent = prettyMs(Date.now() - stepStart, {\n          secondsDecimalDigits: 2,\n        })\n        currentProgress.text = `[100%] ${currentStep} (${timeSpent})`\n        currentProgress.succeed()\n      } else if (currentProgress) {\n        currentProgress.fail()\n      }\n    }\n\n    // Start the import!\n    try {\n      const {numDocs, warnings} = await sanityImport(inputStream, {\n        client: importClient,\n        assetsBase,\n        operation,\n        onProgress,\n        allowFailingAssets,\n        allowAssetsInDifferentDataset,\n        skipCrossDatasetReferences,\n        allowSystemDocuments,\n        assetConcurrency,\n        replaceAssets,\n      })\n\n      endTask({success: true})\n\n      output.print('Done! Imported %d documents to dataset \"%s\"\\n', numDocs, targetDataset)\n      printWarnings(warnings, output)\n    } catch (err) {\n      endTask({success: false})\n\n      const isNonRefConflict =\n        !fromInitCommand &&\n        err.response &&\n        err.response.statusCode === 409 &&\n        err.step !== 'strengthen-references'\n\n      if (!isNonRefConflict) {\n        throw err\n      }\n\n      const message = [\n        err.message,\n        '',\n        'You probably want either:',\n        ' --replace (replace existing documents with same IDs)',\n        ' --missing (only import documents that do not already exist)',\n        '',\n      ].join('\\n')\n\n      // @todo SUBCLASS ERROR?\n      const error = new Error(message) as any\n      error.details = err.details\n      error.response = err.response\n      error.responseBody = err.responseBody\n\n      throw error\n    }\n  },\n}\n\nasync function determineTargetDataset(target: string, context: CliCommandContext) {\n  const {apiClient, output, prompt} = context\n  const client = apiClient()\n\n  if (target) {\n    const dsError = validateDatasetName(target)\n    if (dsError) {\n      throw new Error(dsError)\n    }\n  }\n\n  debug('Fetching available datasets')\n  const spinner = output.spinner('Fetching available datasets').start()\n  const datasets = await client.datasets.list()\n  spinner.succeed('[100%] Fetching available datasets')\n\n  let targetDataset = target ? `${target}` : null\n  if (!targetDataset) {\n    targetDataset = await chooseDatasetPrompt(context, {\n      message: 'Select target dataset',\n      allowCreation: true,\n    })\n  } else if (!datasets.find((dataset) => dataset.name === targetDataset)) {\n    debug('Target dataset does not exist, prompting for creation')\n    const shouldCreate = await prompt.single({\n      type: 'confirm',\n      message: `Dataset \"${targetDataset}\" does not exist, would you like to create it?`,\n      default: true,\n    })\n\n    if (!shouldCreate) {\n      throw new Error(`Dataset \"${targetDataset}\" does not exist`)\n    }\n\n    await client.datasets.create(targetDataset)\n  }\n\n  return targetDataset\n}\n\nfunction getMutationOperation(flags: ParsedImportFlags) {\n  const {replace, missing} = flags\n  if (replace && missing) {\n    throw new Error('Cannot use both --replace and --missing')\n  }\n\n  if (flags.replace) {\n    return 'createOrReplace'\n  }\n\n  if (flags.missing) {\n    return 'createIfNotExists'\n  }\n\n  return 'create'\n}\n\nfunction getPercentage(opts: ProgressEvent) {\n  if (!opts.total || typeof opts.current === 'undefined') {\n    return ''\n  }\n\n  const percent = Math.floor((opts.current / opts.total) * 100)\n  return `[${padStart(`${percent}`, 3, ' ')}%] `\n}\n\nfunction getUrlStream(url: string) {\n  const request = getIt([promise({onlyBody: true})])\n  return request({url, stream: true})\n}\n\nfunction printWarnings(warnings: ImportWarning[], output: CliOutputter) {\n  const assetFails = warnings.filter((warn) => warn.type === 'asset')\n\n  if (!assetFails.length) {\n    return\n  }\n\n  const warn = (output.warn || output.print).bind(output)\n\n  warn(yellow('⚠ Failed to import the following %s:'), assetFails.length > 1 ? 'assets' : 'asset')\n\n  warnings.forEach((warning) => {\n    warn(`  ${warning.url}`)\n  })\n}\n\nexport default importDatasetCommand\n","import {type CliCommandAction} from '@sanity/cli'\n\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nexport const listAliasesHandler: CliCommandAction = async (args, context) => {\n  const {apiClient, output} = context\n  const client = apiClient()\n\n  const aliases = await aliasClient.listAliases(client)\n  output.print(\n    aliases\n      .map((set) => `${ALIAS_PREFIX}${set.name} -> ${set.datasetName || '<unlinked>'}`)\n      .join('\\n'),\n  )\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {listAliasesHandler} from './alias/listAliasesHandler'\n\nconst listDatasetsCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'dataset',\n  helpText: '',\n  signature: '',\n  description: 'List datasets of your project',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const client = apiClient()\n    const datasets = await client.datasets.list()\n    output.print(datasets.map((set) => set.name).join('\\n'))\n\n    // Print alias list\n    await listAliasesHandler(args, context)\n  },\n}\n\nexport default listDatasetsCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type DeployStudioActionFlags} from '../../actions/deploy/deployAction'\n\nconst helpText = `\nOptions\n  --source-maps Enable source maps for built bundles (increases size of bundle)\n  --no-minify Skip minifying built JavaScript (speeds up build, increases size of bundle)\n  --no-build Don't build the studio prior to deploy, instead deploying the version currently in \\`dist/\\`\n\nExamples\n  sanity deploy\n  sanity deploy --no-minify --source-maps\n`\n\nconst deployCommand: CliCommandDefinition = {\n  name: 'deploy',\n  signature: '[SOURCE_DIR] [--no-build]  [--source-maps] [--no-minify]',\n  description: 'Builds and deploys Sanity Studio to Sanity hosting',\n  action: async (\n    args: CliCommandArguments<DeployStudioActionFlags>,\n    context: CliCommandContext,\n  ) => {\n    const mod = await import('../../actions/deploy/deployAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default deployCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nconst helpText = `\nExamples\n  sanity undeploy\n`\n\nconst undeployCommand: CliCommandDefinition = {\n  name: 'undeploy',\n  signature: '',\n  description: 'Removes the deployed Sanity Studio from Sanity hosting',\n  action: async (\n    args: CliCommandArguments<Record<string, unknown>>,\n    context: CliCommandContext,\n  ) => {\n    const mod = await import('../../actions/deploy/undeployAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default undeployCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type StartDevServerCommandFlags} from '../../actions/dev/devAction'\n\nconst helpText = `\nNotes\n  Changing the hostname or port number might require a new entry to the CORS-origins allow list.\n\nOptions\n  --port <port> TCP port to start server on. [default: 3333]\n  --host <host> The local network interface at which to listen. [default: \"127.0.0.1\"]\n\nExamples\n  sanity dev --host=0.0.0.0\n  sanity dev --port=1942\n`\n\nconst devCommand: CliCommandDefinition = {\n  name: 'dev',\n  signature: '[--port <port>] [--host <host>]',\n  description: 'Starts a local dev server for Sanity Studio with live reloading',\n  action: async (\n    args: CliCommandArguments<StartDevServerCommandFlags>,\n    context: CliCommandContext,\n  ) => {\n    const devAction = await getDevAction()\n\n    return devAction(args, context)\n  },\n  helpText,\n}\n\nexport async function getDevAction(): Promise<\n  (\n    args: CliCommandArguments<StartDevServerCommandFlags>,\n    context: CliCommandContext,\n  ) => Promise<void>\n> {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n    const mod: typeof import('../../actions/dev/devAction') = require('../../actions/dev/devAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/dev/devAction')\n\n  return mod.default\n}\n\nexport default devCommand\n","import fs from 'node:fs/promises'\nimport os from 'node:os'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {\n  type IdentifiedSanityDocumentStub,\n  type MultipleMutationResult,\n  type Mutation,\n  type SanityClient,\n} from '@sanity/client'\nimport {uuid} from '@sanity/uuid'\nimport chokidar from 'chokidar'\nimport execa from 'execa'\nimport json5 from 'json5'\nimport {isEqual, isPlainObject, noop} from 'lodash'\n\ntype MutationOperationName = 'create' | 'createOrReplace' | 'createIfNotExists'\n\ninterface CreateFlags {\n  dataset?: string\n  replace?: boolean\n  missing?: boolean\n  watch?: boolean\n  json5?: boolean\n  id?: string\n}\n\nconst helpText = `\nOptions\n  --replace On duplicate document IDs, replace existing document with specified document(s)\n  --missing On duplicate document IDs, don't modify the target document(s)\n  --watch   Write the documents whenever the target file or buffer changes\n  --json5   Use JSON5 file type to allow a \"simplified\" version of JSON\n  --id <id> Specify a document ID to use. Will fetch remote document ID and populate editor.\n  --dataset NAME to override dataset\n\nExamples\n  # Create the document specified in \"myDocument.json\".\n  sanity documents create myDocument.json\n\n  # Open configured $EDITOR and create the specified document(s)\n  sanity documents create\n\n  # Fetch document with the ID \"myDocId\" and open configured $EDITOR with the\n  # current document content (if any). Replace document with the edited version\n  # when the editor closes\n  sanity documents create --id myDocId --replace\n\n  # Open configured $EDITOR and replace the document with the given content\n  # on each save. Use JSON5 file extension and parser for simplified syntax.\n  sanity documents create --id myDocId --watch --replace --json5\n`\n\nconst createDocumentsCommand: CliCommandDefinition<CreateFlags> = {\n  name: 'create',\n  group: 'documents',\n  signature: '[FILE]',\n  helpText,\n  description: 'Create one or more documents',\n  // eslint-disable-next-line complexity\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const {replace, missing, watch, id, dataset} = args.extOptions\n    const [file] = args.argsWithoutOptions\n    const useJson5 = args.extOptions.json5\n    const client = dataset ? apiClient().clone().config({dataset}) : apiClient()\n\n    if (replace && missing) {\n      throw new Error('Cannot use both --replace and --missing')\n    }\n\n    if (id && file) {\n      throw new Error('Cannot use --id when specifying a file path')\n    }\n\n    let operation: MutationOperationName = 'create'\n    if (replace || missing) {\n      operation = replace ? 'createOrReplace' : 'createIfNotExists'\n    }\n\n    if (file) {\n      const contentPath = path.resolve(process.cwd(), file)\n      const content = json5.parse(await fs.readFile(contentPath, 'utf8'))\n      const result = await writeDocuments(content, operation, client)\n      output.print(getResultMessage(result, operation))\n      return\n    }\n\n    // Create a temporary file and use that as source, opening an editor on it\n    const docId = id || uuid()\n    const ext = useJson5 ? 'json5' : 'json'\n    const tmpFile = path.join(os.tmpdir(), 'sanity-cli', `${docId}.${ext}`)\n    const stringify = useJson5 ? json5.stringify : JSON.stringify\n    const defaultValue = (id && (await client.getDocument(id))) || {_id: docId, _type: 'specify-me'}\n    await fs.mkdir(path.join(os.tmpdir(), 'sanity-cli'), {recursive: true})\n    await fs.writeFile(tmpFile, stringify(defaultValue, null, 2), 'utf8')\n\n    const editor = getEditor()\n    if (watch) {\n      // If we're in watch mode, we want to run the creation on each change (if it validates)\n      registerUnlinkOnSigInt(tmpFile)\n      output.print(`Watch mode: ${tmpFile}`)\n      output.print('Watch mode: Will write documents on each save.')\n      output.print('Watch mode: Press Ctrl + C to cancel watch mode.')\n      chokidar.watch(tmpFile).on('change', () => {\n        output.print('')\n        return readAndPerformCreatesFromFile(tmpFile)\n      })\n      execa(editor.bin, editor.args.concat(tmpFile), {stdio: 'inherit'})\n    } else {\n      // While in normal mode, we just want to wait for the editor to close and run the thing once\n      execa.sync(editor.bin, editor.args.concat(tmpFile), {stdio: 'inherit'})\n      await readAndPerformCreatesFromFile(tmpFile)\n      await fs.unlink(tmpFile).catch(noop)\n    }\n\n    async function readAndPerformCreatesFromFile(filePath: string) {\n      let content\n      try {\n        content = json5.parse(await fs.readFile(filePath, 'utf8'))\n      } catch (err) {\n        output.error(`Failed to read input: ${err.message}`)\n        return\n      }\n\n      if (isEqual(content, defaultValue)) {\n        output.print('Value not modified, doing nothing.')\n        output.print('Modify document to trigger creation.')\n        return\n      }\n\n      try {\n        const writeResult = await writeDocuments(content, operation, client)\n        output.print(getResultMessage(writeResult, operation))\n      } catch (err) {\n        output.error(`Failed to write documents: ${err.message}`)\n        if (err.message.includes('already exists')) {\n          output.error('Perhaps you want to use `--replace` or `--missing`?')\n        }\n      }\n    }\n  },\n}\n\nfunction registerUnlinkOnSigInt(tmpFile: string) {\n  process.on('SIGINT', async () => {\n    await fs.unlink(tmpFile).catch(noop)\n    // eslint-disable-next-line no-process-exit\n    process.exit(130)\n  })\n}\n\nfunction writeDocuments(\n  documents: {_id?: string; _type: string} | {_id?: string; _type: string}[],\n  operation: MutationOperationName,\n  client: SanityClient,\n) {\n  const docs = Array.isArray(documents) ? documents : [documents]\n  if (docs.length === 0) {\n    throw new Error('No documents provided')\n  }\n\n  const mutations = docs.map((doc, index): Mutation => {\n    validateDocument(doc, index, docs)\n    if (operation === 'create') {\n      return {create: doc}\n    }\n\n    if (operation === 'createIfNotExists') {\n      if (isIdentifiedSanityDocument(doc)) {\n        return {createIfNotExists: doc}\n      }\n\n      throw new Error(`Missing required _id attribute for ${operation}`)\n    }\n\n    if (operation === 'createOrReplace') {\n      if (isIdentifiedSanityDocument(doc)) {\n        return {createOrReplace: doc}\n      }\n\n      throw new Error(`Missing required _id attribute for ${operation}`)\n    }\n\n    throw new Error(`Unsupported operation ${operation}`)\n  })\n\n  return client.transaction(mutations).commit()\n}\n\nfunction validateDocument(doc: unknown, index: number, arr: unknown[]) {\n  const isSingle = arr.length === 1\n\n  if (!isPlainObject(doc)) {\n    throw new Error(getErrorMessage('must be an object', index, isSingle))\n  }\n\n  if (!isSanityDocumentish(doc)) {\n    throw new Error(getErrorMessage('must have a `_type` property of type string', index, isSingle))\n  }\n}\n\nfunction isSanityDocumentish(doc: unknown): doc is {_type: string} {\n  return (\n    doc !== null &&\n    typeof doc === 'object' &&\n    '_type' in doc &&\n    typeof (doc as any)._type === 'string'\n  )\n}\n\nfunction isIdentifiedSanityDocument(doc: unknown): doc is IdentifiedSanityDocumentStub {\n  return isSanityDocumentish(doc) && '_id' in doc\n}\n\nfunction getErrorMessage(message: string, index: number, isSingle: boolean): string {\n  return isSingle ? `Document ${message}` : `Document at index ${index} ${message}`\n}\n\nfunction getResultMessage(\n  result: MultipleMutationResult,\n  operation: MutationOperationName,\n): string {\n  const joiner = '\\n  - '\n  if (operation === 'createOrReplace') {\n    return `Upserted:\\n  - ${result.results.map((res) => res.id).join(joiner)}`\n  }\n\n  if (operation === 'create') {\n    return `Created:\\n  - ${result.results.map((res) => res.id).join(joiner)}`\n  }\n\n  // \"Missing\" (createIfNotExists)\n  const created: string[] = []\n  const skipped: string[] = []\n  for (const res of result.results) {\n    if (res.operation === 'update') {\n      skipped.push(res.id)\n    } else {\n      created.push(res.id)\n    }\n  }\n\n  if (created.length > 0 && skipped.length > 0) {\n    return [\n      `Created:\\n  - ${created.join(joiner)}`,\n      `Skipped (already exists):${joiner}${skipped.join(joiner)}`,\n    ].join('\\n\\n')\n  } else if (created.length > 0) {\n    return `Created:\\n  - ${created.join(joiner)}`\n  }\n\n  return `Skipped (already exists):\\n  - ${skipped.join(joiner)}`\n}\n\nfunction getEditor() {\n  const defaultEditor = /^win/.test(process.platform) ? 'notepad' : 'vim'\n  // eslint-disable-next-line no-process-env\n  const editor = process.env.VISUAL || process.env.EDITOR || defaultEditor\n  const args = editor.split(/\\s+/)\n  const bin = args.shift() || ''\n  return {bin, args}\n}\n\nexport default createDocumentsCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport pluralize from 'pluralize-esm'\n\nconst helpText = `\nDelete a document from the projects configured dataset\n\nOptions\n  --dataset NAME to override dataset\n\nExample\n  # Delete the document with the ID \"myDocId\"\n  sanity documents delete myDocId\n\n  # ID wrapped in double or single quote works equally well\n  sanity documents delete 'myDocId'\n\n  # Delete document with ID \"someDocId\" from dataset \"blog\"\n  sanity documents delete --dataset=blog someDocId\n\n  # Delete the document with ID \"doc1\" and \"doc2\"\n  sanity documents delete doc1 doc2\n`\n\ninterface DeleteFlags {\n  dataset?: string\n}\n\nconst deleteDocumentsCommand: CliCommandDefinition<DeleteFlags> = {\n  name: 'delete',\n  group: 'documents',\n  signature: '[ID] [...IDS]',\n  helpText,\n  description: 'Delete a document by ID',\n  action: async (args, context) => {\n    const {apiClient, output, chalk} = context\n    const {dataset} = args.extOptions\n    const ids = args.argsWithoutOptions.map((str) => `${str}`)\n\n    if (!ids.length) {\n      throw new Error('Document ID must be specified')\n    }\n\n    const client = dataset ? apiClient().clone().config({dataset}) : apiClient()\n\n    const transaction = ids.reduce((trx, id) => trx.delete(id), client.transaction())\n    try {\n      const {results} = await transaction.commit()\n      const deleted = results.filter((res) => res.operation === 'delete').map((res) => res.id)\n      const notFound = ids.filter((id) => !deleted.includes(id))\n      if (deleted.length > 0) {\n        output.print(`Deleted ${deleted.length} ${pluralize('document', deleted.length)}`)\n      }\n\n      if (notFound.length > 0) {\n        output.error(\n          chalk.red(`${pluralize('Document', notFound.length)} not found: ${notFound.join(', ')}`),\n        )\n      }\n    } catch (err) {\n      throw new Error(`Failed to delete ${pluralize('document', ids.length)}:\\n${err.message}`)\n    }\n  },\n}\n\nexport default deleteDocumentsCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst documentsGroup: CliCommandGroupDefinition = {\n  name: 'documents',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages documents in your Sanity Content Lake datasets',\n}\n\nexport default documentsGroup\n","import {type CliCommandContext} from '@sanity/cli'\nimport tokenize, {type LexerToken} from 'json-lexer'\n\ninterface KeyToken {\n  type: 'key'\n  value: string\n  raw: string\n}\n\ntype ExtendedLexerToken = LexerToken | KeyToken\n\nconst identity = (inp: string): string => inp\n\nexport function colorizeJson(input: unknown, chalk: CliCommandContext['chalk']): string {\n  const formatters: Record<ExtendedLexerToken['type'], (str: string) => string> = {\n    punctuator: chalk.white,\n    key: chalk.white,\n    string: chalk.green,\n    number: chalk.yellow,\n    literal: chalk.bold,\n    whitespace: identity,\n  }\n\n  const json = JSON.stringify(input, null, 2)\n\n  return tokenize(json)\n    .map((token, i, arr): ExtendedLexerToken => {\n      // Note how the following only works because we pretty-print the JSON\n      const prevToken = i === 0 ? token : arr[i - 1]\n      if (\n        token.type === 'string' &&\n        prevToken.type === 'whitespace' &&\n        /^\\n\\s+$/.test(prevToken.value)\n      ) {\n        return {...token, type: 'key'}\n      }\n\n      return token\n    })\n    .map((token) => {\n      const formatter = formatters[token.type] || identity\n      return formatter(token.raw)\n    })\n    .join('')\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {colorizeJson} from '../../util/colorizeJson'\n\nconst helpText = `\nGet and print a document from the projects configured dataset\n\nOptions\n  --pretty colorized JSON output\n  --dataset NAME to override dataset\n\nExamples\n  # Get the document with the ID \"myDocId\"\n  sanity documents get myDocId\n\n  # ID wrapped in double or single quote works equally well\n  sanity documents get 'myDocId'\n`\n\ninterface GetDocumentFlags {\n  pretty?: boolean\n  dataset?: string\n}\n\nconst getDocumentsCommand: CliCommandDefinition<GetDocumentFlags> = {\n  name: 'get',\n  group: 'documents',\n  signature: '[DOCUMENT_ID]',\n  helpText,\n  description: 'Get and print a document by ID',\n  action: async (args, context) => {\n    const {apiClient, output, chalk} = context\n    const {pretty, dataset} = args.extOptions\n    const [docId] = args.argsWithoutOptions.map((str) => `${str}`)\n\n    if (!docId) {\n      throw new Error('Document ID must be specified')\n    }\n\n    const client = dataset ? apiClient().clone().config({dataset}) : apiClient()\n\n    try {\n      const doc = await client.getDocument(docId)\n      if (!doc) {\n        throw new Error(`Document ${docId} not found`)\n      }\n\n      output.print(pretty ? colorizeJson(doc, chalk) : JSON.stringify(doc, null, 2))\n    } catch (err) {\n      throw new Error(`Failed to fetch document:\\n${err.message}`)\n    }\n  },\n}\n\nexport default getDocumentsCommand\n","import {type CliCommandArguments, type CliCommandContext} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {colorizeJson} from '../../util/colorizeJson'\n\nconst defaultApiVersion = 'v2022-06-01'\n\nconst helpText = `\nRun a query against the projects configured dataset\n\nOptions\n  --pretty colorized JSON output\n  --dataset NAME to override dataset\n  --project PROJECT to override project ID\n  --anonymous Send the query without any authorization token\n  --api-version API version to use (defaults to \\`${defaultApiVersion}\\`)\n\nEnvironment variables\n  \\`SANITY_CLI_QUERY_API_VERSION\\` - will use the defined API version,\n  unless \\`--api-version\\` is specified.\n\nExamples\n  # Fetch 5 documents of type \"movie\"\n  sanity documents query '*[_type == \"movie\"][0..4]'\n\n  # Fetch title of the oldest movie in the dataset named \"staging\"\n  sanity documents query '*[_type == \"movie\"]|order(releaseDate asc)[0]{title}' --dataset staging\n\n  # Use API version v2021-06-07 and do a query\n  sanity documents query --api-version v2021-06-07 '*[_id == \"header\"] { \"headerText\": pt::text(body) }'\n`\n\ninterface CliQueryCommandFlags {\n  pretty?: boolean\n  anonymous?: boolean\n  dataset?: string\n  project?: string\n  apiVersion?: string\n}\n\nexport default {\n  name: 'query',\n  group: 'documents',\n  signature: '[QUERY]',\n  helpText,\n  description: 'Query for documents',\n  action: async (\n    args: CliCommandArguments<CliQueryCommandFlags>,\n    context: CliCommandContext,\n  ): Promise<void> => {\n    // Reparsing arguments for improved control of flags\n    const {\n      pretty,\n      dataset,\n      project,\n      anonymous,\n      'api-version': apiVersion,\n    } = await parseCliFlags(args)\n    const {apiClient, output, chalk, cliConfig} = context\n    const [query] = args.argsWithoutOptions\n\n    if (!query) {\n      throw new Error('Query must be specified')\n    }\n\n    if (!apiVersion) {\n      output.warn(chalk.yellow(`--api-version not specified, using \\`${defaultApiVersion}\\``))\n    }\n\n    const requireDataset = !dataset\n    const requireProject = !project\n    const requireUser = !anonymous\n\n    if (requireProject && !cliConfig?.api?.projectId) {\n      throw new Error(\n        'No project configured in CLI config - either configure one, or use `--project` flag',\n      )\n    }\n\n    if (requireDataset && !cliConfig?.api?.dataset) {\n      throw new Error(\n        'No dataset configured in CLI config - either configure one, or use `--dataset` flag',\n      )\n    }\n\n    const baseClient = apiClient({requireProject, requireUser}).clone()\n    const {dataset: originalDataset, projectId: originalProjectId} = baseClient.config()\n\n    const client = baseClient.config({\n      projectId: project || originalProjectId,\n      dataset: dataset || originalDataset,\n      apiVersion: apiVersion || defaultApiVersion,\n    })\n\n    try {\n      const docs = await client.fetch(query)\n      if (!docs) {\n        throw new Error('Query returned no results')\n      }\n\n      output.print(pretty ? colorizeJson(docs, chalk) : JSON.stringify(docs, null, 2))\n    } catch (err) {\n      throw new Error(`Failed to run query:\\n${err.message}`)\n    }\n  },\n}\n\nfunction parseCliFlags(args: CliCommandArguments<CliQueryCommandFlags>) {\n  // eslint-disable-next-line no-process-env\n  const fallbackApiVersion = process.env.SANITY_CLI_QUERY_API_VERSION\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .option('pretty', {type: 'boolean', default: false})\n    .option('dataset', {type: 'string'})\n    .option('project', {type: 'string'})\n    .option('anonymous', {type: 'boolean', default: false})\n    .option('api-version', {type: 'string', default: fallbackApiVersion}).argv\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = `Downloads and validates all document specified in a workspace`\n\nconst helpText = `\nOptions\n  -y, --yes Skips the first confirmation prompt.\n  --workspace <name> The name of the workspace to use when downloading and validating all documents.\n  --dataset <name> Override the dataset used. By default, this is derived from the given workspace.\n  --file <filepath> Provide a path to either an .ndjson file or a tarball containing an .ndjson file.\n  --format <pretty|ndjson|json> The output format used to print the found validation markers and report progress.\n  --level <error|warning|info> The minimum level reported out. Defaults to warning.\n  --max-custom-validation-concurrency <number> Specify how many custom validators can run concurrently. Defaults to 5.\n\nExamples\n  # Validates all documents in a Sanity project with more than one workspace\n  sanity documents validate --workspace default\n\n  # Override the dataset specified in the workspace\n  sanity documents validate --workspace default --dataset staging\n\n  # Save the results of the report into a file\n  sanity documents validate > report.txt\n\n  # Report out info level validation markers too\n  sanity documents validate --level info\n`\n\nconst validateDocumentsCommand: CliCommandDefinition = {\n  name: 'validate',\n  group: 'documents',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/validation/validateAction')\n\n    return mod.default(args, context)\n  },\n} satisfies CliCommandDefinition\n\nexport default validateDocumentsCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst helpText = `\nOptions\n  --with-user-token Prime access token from CLI config into getCliClient()\n  --mock-browser-env Mocks a browser-like environment using jsdom\n\nExamples\n  # Run the script at some/script.js in Sanity context\n  sanity exec some/script.js\n\n  # Run the script at migrations/fullname.ts and configure \\`getCliClient()\\`\n  # from \\`sanity/cli\\`to include the current user's token\n  sanity exec migrations/fullname.ts --with-user-token\n\n  # Run the script at scripts/browserScript.js in a mock browser environment\n  sanity exec scripts/browserScript.js --mock-browser-env\n\n  # Pass arbitrary arguments to scripts by separating them with a \\`--\\`.\n  # Arguments are available in \\`process.argv\\` as they would in regular node scripts\n  # eg the following command would yield a \\`process.argv\\` of:\n  # ['/path/to/node', '/path/to/myscript.js', '--dry-run', 'positional-argument']\n  sanity exec --mock-browser-env myscript.js -- --dry-run positional-argument\n`\n\nexport const execCommand: CliCommandDefinition = {\n  name: 'exec',\n  signature: 'SCRIPT',\n  description: 'Executes a script within the Sanity Studio context',\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/exec/execScript')\n\n    return mod.default(args, context)\n  },\n}\n\nexport default execCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type DeleteGraphQLApiFlags} from '../../actions/graphql/deleteApiAction'\n\nconst helpText = `\nOptions\n  --api <api-id> Undeploy API with this ID (project, dataset and tag flags takes preference)\n  --project <projectId> Project ID to delete GraphQL API for\n  --dataset <dataset> Delete GraphQL API for the given dataset\n  --tag <tag> Delete GraphQL API for the given tag (defaults to 'default')\n  --force Skip confirmation prompt, forcefully undeploying the GraphQL API\n\nExamples\n  sanity graphql undeploy\n  sanity graphql undeploy --api ios\n  sanity graphql undeploy --dataset staging\n  sanity graphql undeploy --dataset staging --tag next\n`\n\nconst deleteGraphQLAPICommand: CliCommandDefinition = {\n  name: 'undeploy',\n  group: 'graphql',\n  signature: '',\n  description: 'Remove a deployed GraphQL API',\n  action: async (args: CliCommandArguments<DeleteGraphQLApiFlags>, context: CliCommandContext) => {\n    const mod = await import('../../actions/graphql/deleteApiAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default deleteGraphQLAPICommand\n","import {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\n\nconst helpText = `\nOptions\n  --dry-run Validate defined APIs, exiting with an error on breaking changes\n  --force Deploy API without confirming breaking changes\n  --api <api-id> Only deploy API with this ID. Can be specified multiple times.\n\nThe following options will override any setting from the CLI configuration file\n(sanity.cli.js/sanity.cli.ts) - and applies to ALL defined APIs defined in that\nconfiguration file. Tread with caution!\n\n  --tag Deploy API(s) to given tag (defaults to 'default')\n  --dataset <name> Deploy API for the given dataset\n  --generation <gen1|gen2|gen3> API generation to deploy (defaults to 'gen3')\n  --non-null-document-fields Use non-null document fields (_id, _type etc)\n  --playground Enable GraphQL playground for easier debugging\n  --no-playground Disable GraphQL playground\n  --with-union-cache *Experimental:* Enable union cache that optimizes schema generation for schemas with many self referencing types\n\nExamples\n  # Deploy all defined GraphQL APIs\n  sanity graphql deploy\n\n  # Validate defined GraphQL APIs, check for breaking changes, skip deploy\n  sanity graphql deploy --dry-run\n\n  # Deploy only the GraphQL APIs with the IDs \"staging\" and \"ios\"\n  sanity graphql deploy --api staging --api ios\n\n  # Deploy all defined GraphQL APIs, overriding any playground setting\n  sanity graphql deploy --playground\n`\n\nconst deployGraphQLAPICommand: CliCommandDefinition = {\n  name: 'deploy',\n  signature: '',\n  group: 'graphql',\n  description: 'Deploy a GraphQL API from the current Sanity schema',\n  action: async (args: {argv?: string[]}, context: CliCommandContext) => {\n    const mod = await import('../../actions/graphql/deployApiAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default deployGraphQLAPICommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst graphqlGroup: CliCommandGroupDefinition = {\n  name: 'graphql',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: \"Deploys changes to your project's GraphQL API(s)\",\n}\n\nexport default graphqlGroup\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nconst helpText = `\nExamples\n  sanity graphql list\n`\n\nconst listGraphQLAPIsCommand: CliCommandDefinition = {\n  name: 'list',\n  signature: '',\n  group: 'graphql',\n  description: 'Lists all the GraphQL endpoints deployed for this project',\n  action: async (\n    args: CliCommandArguments<Record<string, unknown>>,\n    context: CliCommandContext,\n  ) => {\n    const mod = await import('../../actions/graphql/listApisAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default listGraphQLAPIsCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport open from 'open'\n\nconst createHookCommand: CliCommandDefinition = {\n  name: 'create',\n  group: 'hook',\n  signature: '',\n  helpText: '',\n  description: 'Create a new hook for the given dataset',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const client = apiClient()\n\n    const {projectId} = client.config()\n    if (!projectId) {\n      throw new Error('No project ID found')\n    }\n\n    const projectInfo = (await client.projects.getById(projectId)) || {}\n    const organizationId = projectInfo.organizationId || 'personal'\n    const manageUrl = `https://www.sanity.io/organizations/${organizationId}/project/${projectId}/api/webhooks/new`\n\n    output.print(`Opening ${manageUrl}`)\n    open(manageUrl)\n  },\n}\n\nexport default createHookCommand\n","import {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\n\nimport {type Hook} from './types'\n\nconst deleteHookCommand: CliCommandDefinition = {\n  name: 'delete',\n  group: 'hook',\n  signature: '[NAME]',\n  helpText: '',\n  description: 'Delete a hook within your project',\n  action: async (args, context) => {\n    const {apiClient} = context\n    const [name] = args.argsWithoutOptions\n    const client = apiClient()\n\n    const hookId = await promptForHook(name, context)\n    try {\n      await client\n        .clone()\n        .config({apiVersion: '2021-10-04'})\n        .request({method: 'DELETE', uri: `/hooks/${hookId}`})\n    } catch (err) {\n      throw new Error(`Hook deletion failed:\\n${err.message}`)\n    }\n  },\n}\n\nasync function promptForHook(specified: string | undefined, context: CliCommandContext) {\n  const specifiedName = specified && specified.toLowerCase()\n  const {prompt, apiClient} = context\n  const client = apiClient()\n\n  const hooks = await client\n    .clone()\n    .config({apiVersion: '2021-10-04'})\n    .request<Hook[]>({uri: '/hooks', json: true})\n\n  if (specifiedName) {\n    const selected = hooks.filter((hook) => hook.name.toLowerCase() === specifiedName)[0]\n    if (!selected) {\n      throw new Error(`Hook with name \"${specified} not found\"`)\n    }\n\n    return selected.id\n  }\n\n  const choices = hooks.map((hook) => ({value: hook.id, name: hook.name}))\n  return prompt.single({\n    message: 'Select hook to delete',\n    type: 'list',\n    choices,\n  })\n}\n\nexport default deleteHookCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst hookGroup: CliCommandGroupDefinition = {\n  name: 'hook',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Sets up and manages webhooks within your Sanity project',\n}\n\nexport default hookGroup\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {type DeliveryAttempt} from './types'\n\nconst printHookAttemptCommand: CliCommandDefinition = {\n  name: 'attempt',\n  group: 'hook',\n  signature: 'ATTEMPT_ID',\n  helpText: '',\n  description: 'Print details of a given webhook delivery attempt',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const [attemptId] = args.argsWithoutOptions\n    const client = apiClient()\n\n    let attempt\n    try {\n      attempt = await client.request<DeliveryAttempt>({uri: `/hooks/attempts/${attemptId}`})\n    } catch (err) {\n      throw new Error(`Hook attempt retrieval failed:\\n${err.message}`)\n    }\n\n    const {createdAt, resultCode, resultBody, failureReason, inProgress} = attempt\n\n    output.print(`Date: ${createdAt}`)\n    output.print(`Status: ${getStatus(attempt)}`)\n    output.print(`Status code: ${resultCode}`)\n\n    if (attempt.isFailure) {\n      output.print(`Failure: ${formatFailure(attempt)}`)\n    }\n\n    if (!inProgress && (!failureReason || failureReason === 'http')) {\n      const body = resultBody ? `\\n---\\n${resultBody}\\n---\\n` : '<empty>'\n      output.print(`Response body: ${body}`)\n    }\n  },\n}\n\nexport default printHookAttemptCommand\n\nexport function formatFailure(\n  attempt: DeliveryAttempt,\n  options: {includeHelp?: boolean} = {},\n): string {\n  const {includeHelp} = options\n  const {id, failureReason, resultCode} = attempt\n  const help = includeHelp ? `(run \\`sanity hook attempt ${id}\\` for details)` : ''\n  switch (failureReason) {\n    case 'http':\n      return `HTTP ${resultCode} ${help}`\n    case 'timeout':\n      return 'Request timed out'\n    case 'network':\n      return 'Network error'\n    case 'other':\n    default:\n  }\n\n  return 'Unknown error'\n}\n\nexport function getStatus(attempt: DeliveryAttempt): string {\n  if (attempt.isFailure) {\n    return 'Failed'\n  }\n\n  if (attempt.inProgress) {\n    return 'In progress'\n  }\n\n  return 'Delivered'\n}\n","import {inspect} from 'node:util'\n\nimport {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\nimport {groupBy} from 'lodash'\n\nimport {formatFailure} from './printHookAttemptCommand'\nimport {type DeliveryAttempt, type Hook, type HookMessage} from './types'\n\ninterface ListHookFlags {\n  detailed?: boolean\n}\n\nconst listHookLogsCommand: CliCommandDefinition<ListHookFlags> = {\n  name: 'logs',\n  group: 'hook',\n  signature: '[NAME]',\n  helpText: '',\n  description: 'List latest log entries for a given hook',\n  action: async (args, context) => {\n    const {apiClient} = context\n    const flags = args.extOptions\n    const [name] = args.argsWithoutOptions\n    const client = apiClient()\n\n    const hookId = await promptForHook(name, context)\n    let messages\n    let attempts\n    try {\n      messages = await client.request<HookMessage[]>({uri: `/hooks/${hookId}/messages`})\n      attempts = await client.request<DeliveryAttempt[]>({uri: `/hooks/${hookId}/attempts`})\n    } catch (err) {\n      throw new Error(`Hook logs retrieval failed:\\n${err.message}`)\n    }\n\n    const groupedAttempts = groupBy(attempts, 'messageId')\n    const populated = messages.map((msg): HookMessage & {attempts: DeliveryAttempt[]} => ({\n      ...msg,\n      attempts: groupedAttempts[msg.id],\n    }))\n\n    const totalMessages = messages.length - 1\n    populated.forEach((message, i) => {\n      printMessage(message, context, {detailed: flags.detailed})\n      printSeparator(context, totalMessages === i)\n    })\n  },\n}\n\nexport default listHookLogsCommand\n\nasync function promptForHook(specified: string | undefined, context: CliCommandContext) {\n  const specifiedName = specified && specified.toLowerCase()\n  const {prompt, apiClient} = context\n  const client = apiClient()\n\n  const hooks = await client\n    .clone()\n    .config({apiVersion: '2021-10-04'})\n    .request<Hook[]>({uri: '/hooks', json: true})\n\n  if (specifiedName) {\n    const selected = hooks.filter((hook) => hook.name.toLowerCase() === specifiedName)[0]\n    if (!selected) {\n      throw new Error(`Hook with name \"${specified} not found\"`)\n    }\n\n    return selected.id\n  }\n\n  if (hooks.length === 0) {\n    throw new Error('No hooks currently registered')\n  }\n\n  if (hooks.length === 1) {\n    return hooks[0].id\n  }\n\n  const choices = hooks.map((hook) => ({value: hook.id, name: hook.name}))\n  return prompt.single({\n    message: 'Select hook to list logs for',\n    type: 'list',\n    choices,\n  })\n}\n\nfunction printSeparator(context: CliCommandContext, skip: boolean) {\n  if (!skip) {\n    context.output.print('---\\n')\n  }\n}\n\nfunction printMessage(\n  message: HookMessage & {attempts: DeliveryAttempt[]},\n  context: CliCommandContext,\n  options: {detailed?: boolean},\n) {\n  const {detailed} = options\n  const {output, chalk} = context\n\n  output.print(`Date: ${message.createdAt}`)\n  output.print(`Status: ${message.status}`)\n  output.print(`Result code: ${message.resultCode}`)\n\n  if (message.failureCount > 0) {\n    output.print(`Failures: ${message.failureCount}`)\n  }\n\n  if (detailed) {\n    output.print('Payload:')\n    output.print(inspect(JSON.parse(message.payload), {colors: true}))\n  }\n\n  if (detailed && message.attempts) {\n    output.print('Attempts:')\n    message.attempts.forEach((attempt) => {\n      const date = attempt.createdAt.replace(/\\.\\d+Z$/, 'Z')\n      const prefix = `  [${date}]`\n\n      if (attempt.inProgress) {\n        output.print(`${prefix} ${chalk.yellow('Pending')}`)\n      } else if (attempt.isFailure) {\n        const failure = formatFailure(attempt, {includeHelp: true})\n        output.print(`${prefix} ${chalk.yellow(`Failure: ${failure}`)}`)\n      } else {\n        output.print(`${prefix} Success: HTTP ${attempt.resultCode} (${attempt.duration}ms)`)\n      }\n    })\n  }\n\n  // Leave some empty space between messages\n  output.print('')\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {type Hook} from './types'\n\nconst listHooksCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'hook',\n  signature: '',\n  helpText: '',\n  description: 'List hooks for a given project',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const client = apiClient()\n\n    let hooks\n    try {\n      hooks = await client\n        .clone()\n        .config({apiVersion: '2021-10-04'})\n        .request<Hook[]>({uri: '/hooks'})\n    } catch (err) {\n      throw new Error(`Hook list retrieval failed:\\n${err.message}`)\n    }\n\n    hooks.forEach((hook) => {\n      output.print(`Name: ${hook.name}`)\n      output.print(`Dataset: ${hook.dataset}`)\n      output.print(`URL: ${hook.url}`)\n\n      if (hook.type === 'document') {\n        output.print(`HTTP method: ${hook.httpMethod}`)\n\n        if (hook.description) {\n          output.print(`Description: ${hook.description}`)\n        }\n      }\n\n      output.print('')\n    })\n  },\n}\n\nexport default listHooksCommand\n","export const MIGRATIONS_DIRECTORY = 'migrations'\nexport const MIGRATION_SCRIPT_EXTENSIONS = ['mjs', 'js', 'ts', 'cjs']\n","export const minimalAdvanced = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {defineMigration, patch, at, setIfMissing} from 'sanity/migrate'\n\n/**\n * this migration will set \\`Default title\\` on all documents that are missing a title\n * and make \\`true\\` the default value for the \\`enabled\\` field\n */\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  async *migrate(documents, context) {\n    for await (const document of documents()) {\n      yield patch(document._id, [\n        at('title', setIfMissing('Default title')),\n        at('enabled', setIfMissing(true)),\n      ])\n    }\n  }\n})\n`\n","export const minimalSimple = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {at, defineMigration, setIfMissing, unset} from 'sanity/migrate'\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    document(doc, context) {\n      // this will be called for every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n\n      return at('title', setIfMissing('Default title'))\n    },\n    node(node, path, context) {\n      // this will be called for every node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n\n      if (typeof node === 'string' && node === 'deleteme') {\n        return unset()\n      }\n    },\n    object(node, path, context) {\n      // this will be called for every object node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n      if (node._type === 'author') {\n        // make sure all authors objects have a books array\n        return at('books', setIfMissing([]))\n      }\n    },\n    array(node, path, context) {\n      // this will be called for every array node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    string(node, path, context) {\n      // this will be called for every string node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    number(node, path, context) {\n      // this will be called for every number node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    boolean(node, path, context) {\n      // this will be called for every boolean node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    null(node, path, context) {\n      // this will be called for every null node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n  },\n})\n`\n","export const renameField = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {defineMigration, at, setIfMissing, unset} from 'sanity/migrate'\n\nconst from = 'oldFieldName'\nconst to = 'newFieldName'\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    document(doc, context) {\n      return [\n        at(to, setIfMissing(doc[from])),\n        at(from, unset())\n      ]\n    }\n  }\n})\n`\n","export const renameType = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {defineMigration, at, set} from 'sanity/migrate'\n\nconst oldType = 'old'\nconst newType = 'new'\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    object(object, path, context) {\n      if (object._type === oldType) {\n        return at('_type', set(newType))\n      }\n    }\n  }\n})\n`\n","export const stringToPTE = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {pathsAreEqual, stringToPath} from 'sanity'\nimport {defineMigration, set} from 'sanity/migrate'\n\nconst targetPath = stringToPath('some.path')\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    string(node, path, ctx) {\n      if (pathsAreEqual(path, targetPath)) {\n        return set([\n          {\n            style: 'normal',\n            _type: 'block',\n            children: [\n              {\n                _type: 'span',\n                marks: [],\n                text: node,\n              },\n            ],\n            markDefs: [],\n          },\n        ])\n      }\n    },\n  },\n})\n`\n","import {existsSync, mkdirSync} from 'node:fs'\nimport {writeFile} from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {deburr} from 'lodash'\n\nimport {MIGRATIONS_DIRECTORY} from './constants'\nimport {minimalAdvanced} from './templates/minimalAdvanced'\nimport {minimalSimple} from './templates/minimalSimple'\nimport {renameField} from './templates/renameField'\nimport {renameType} from './templates/renameType'\nimport {stringToPTE} from './templates/stringToPTE'\n\nconst helpText = `\nExamples:\n  # Create a new migration, prompting for title and options\n  sanity migration create\n\n  # Create a new migration with the provided title, prompting for options\n  sanity migration create \"Rename field from location to address\"\n`\n\n// eslint-disable-next-line @typescript-eslint/no-empty-interface\ninterface CreateMigrationFlags {}\n\nconst TEMPLATES = [\n  {name: 'Minimalistic migration to get you started', template: minimalSimple},\n  {name: 'Rename an object type', template: renameType},\n  {name: 'Rename a field', template: renameField},\n  {name: 'Convert string field to Portable Text', template: stringToPTE},\n  {\n    name: 'Advanced template using async iterators providing more fine grained control',\n    template: minimalAdvanced,\n  },\n]\n\nconst createMigrationCommand: CliCommandDefinition<CreateMigrationFlags> = {\n  name: 'create',\n  group: 'migration',\n  signature: '[TITLE]',\n  helpText,\n  description: 'Create a new migration within your project',\n  action: async (args, context) => {\n    const {output, prompt, workDir, chalk} = context\n\n    let [title] = args.argsWithoutOptions\n\n    while (!title?.trim()) {\n      title = await prompt.single({\n        type: 'input',\n        suffix: ' (e.g. \"Rename field from location to address\")',\n        message: 'Title of migration',\n      })\n      if (!title.trim()) {\n        output.error(chalk.red('Name cannot be empty'))\n      }\n    }\n    const types = await prompt.single({\n      type: 'input',\n      suffix: ' (optional)',\n      message: 'Type of documents to migrate. You can add multiple types separated by comma',\n    })\n\n    const templatesByName = Object.fromEntries(TEMPLATES.map((t) => [t.name, t]))\n    const template = await prompt.single({\n      type: 'list',\n      message: 'Select a template',\n      choices: TEMPLATES.map((definedTemplate) => ({\n        name: definedTemplate.name,\n        value: definedTemplate.name,\n      })),\n    })\n\n    const sluggedName = deburr(title.toLowerCase())\n      .replace(/\\s+/g, '-')\n      .replace(/[^a-z0-9-]/g, '')\n\n    const destDir = path.join(workDir, MIGRATIONS_DIRECTORY, sluggedName)\n    if (existsSync(destDir)) {\n      if (\n        !(await prompt.single({\n          type: 'confirm',\n          message: `Migration directory ${chalk.cyan(destDir)} already exists. Overwrite?`,\n          default: false,\n        }))\n      ) {\n        return\n      }\n    }\n    mkdirSync(destDir, {recursive: true})\n\n    const renderedTemplate = (templatesByName[template].template || minimalSimple)({\n      migrationName: title,\n      documentTypes: types\n        .split(',')\n        .map((t) => t.trim())\n        .filter(Boolean),\n    })\n\n    const definitionFile = path.join(destDir, 'index.ts')\n\n    await writeFile(definitionFile, renderedTemplate)\n    // To dry run it, run \\`sanity migration run ${sluggedName}\\``)\n    output.print()\n    output.print(`${chalk.green('✓')} Migration created!`)\n    output.print()\n    output.print('Next steps:')\n    output.print(\n      `Open ${chalk.bold(\n        definitionFile,\n      )} in your code editor and write the code for your migration.`,\n    )\n    output.print(\n      `Dry run the migration with:\\n\\`${chalk.bold(\n        `sanity migration run ${sluggedName} --project=<projectId> --dataset <dataset> `,\n      )}\\``,\n    )\n    output.print(\n      `Run the migration against a dataset with:\\n \\`${chalk.bold(\n        `sanity migration run ${sluggedName} --project=<projectId> --dataset <dataset> --no-dry-run`,\n      )}\\``,\n    )\n    output.print()\n    output.print(\n      `👉 Learn more about schema and content migrations at ${chalk.bold(\n        'https://www.sanity.io/docs/schema-and-content-migrations',\n      )}`,\n    )\n  },\n}\nexport default createMigrationCommand\n","import path from 'node:path'\n\nimport {type Migration} from '@sanity/migrate'\nimport {isPlainObject} from 'lodash'\n\nimport {MIGRATION_SCRIPT_EXTENSIONS, MIGRATIONS_DIRECTORY} from '../constants'\n\ninterface ResolvedMigrationScript {\n  /**\n   * Relative path from the working directory to the migration script\n   */\n  relativePath: string\n\n  /**\n   * Absolute path to the migration script\n   */\n  absolutePath: string\n\n  /**\n   * The migration module, if it could be resolved - otherwise `undefined`\n   */\n  mod?: {default: Migration; up?: unknown; down?: unknown}\n}\n\n/**\n * Resolves the potential paths to a migration script.\n * Considers the following paths (where `<ext>` is 'mjs', 'js', 'ts' or 'cjs'):\n *\n * - `<migrationsDir>/<migrationName>.<ext>`\n * - `<migrationsDir>/<migrationName>/index.<ext>`\n *\n * Note that all possible paths are returned, even if the files do not exist.\n * Check the `mod` property to see if a module could actually be loaded.\n *\n * @param workDir - Working directory of the studio\n * @param migrationName - The name of the migration directory to resolve\n * @returns An array of potential migration scripts\n * @internal\n */\nexport function resolveMigrationScript(\n  workDir: string,\n  migrationName: string,\n): ResolvedMigrationScript[] {\n  return [migrationName, path.join(migrationName, 'index')].flatMap((location) =>\n    MIGRATION_SCRIPT_EXTENSIONS.map((ext) => {\n      const relativePath = path.join(MIGRATIONS_DIRECTORY, `${location}.${ext}`)\n      const absolutePath = path.resolve(workDir, relativePath)\n      let mod\n      try {\n        // eslint-disable-next-line import/no-dynamic-require\n        mod = require(absolutePath)\n      } catch (err) {\n        if (err.code !== 'MODULE_NOT_FOUND') {\n          throw new Error(`Error: ${err.message}\"`)\n        }\n      }\n      return {relativePath, absolutePath, mod}\n    }),\n  )\n}\n\n/**\n * Checks whether or not the passed resolved migration script is actually loadable (eg has a default export)\n *\n * @param script - The resolved migration script to check\n * @returns `true` if the script is loadable, `false` otherwise\n * @internal\n */\nexport function isLoadableMigrationScript(\n  script: ResolvedMigrationScript,\n): script is Required<ResolvedMigrationScript> {\n  if (typeof script.mod === 'undefined' || !isPlainObject(script.mod.default)) {\n    return false\n  }\n\n  const mod = script.mod.default\n  return typeof mod.title === 'string' && mod.migrate !== undefined\n}\n","import {readdir} from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {type Migration} from '@sanity/migrate'\nimport {Table} from 'console-table-printer'\nimport {register} from 'esbuild-register/dist/node'\n\nimport {MIGRATION_SCRIPT_EXTENSIONS, MIGRATIONS_DIRECTORY} from './constants'\nimport {isLoadableMigrationScript, resolveMigrationScript} from './utils/resolveMigrationScript'\n\nconst helpText = ``\n\nconst listMigrationCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'migration',\n  signature: '',\n  helpText,\n  description: 'List available migrations',\n  action: async (_, context) => {\n    const {workDir, output, chalk} = context\n    try {\n      const migrations = await resolveMigrations(workDir)\n\n      if (migrations.length === 0) {\n        output.print('No migrations found in migrations folder of the project')\n        output.print(\n          `\\nRun ${chalk.green(`\\`sanity migration create <NAME>\\``)} to create a new migration`,\n        )\n        return\n      }\n\n      const table = new Table({\n        title: `Found ${migrations.length} migrations in project`,\n        columns: [\n          {name: 'id', title: 'ID', alignment: 'left'},\n          {name: 'title', title: 'Title', alignment: 'left'},\n        ],\n      })\n\n      migrations.forEach((definedMigration) => {\n        table.addRow({id: definedMigration.id, title: definedMigration.migration.title})\n      })\n      table.printTable()\n      output.print('\\nRun `sanity migration run <ID>` to run a migration')\n    } catch (error) {\n      if (error.code === 'ENOENT') {\n        output.print('No migrations folder found in the project')\n        output.print(\n          `\\nRun ${chalk.green(`\\`sanity migration create <NAME>\\``)} to create a new migration`,\n        )\n        return\n      }\n      throw new Error(`An error occurred while listing migrations: ${error.message}`)\n    }\n  },\n}\n\n/**\n * A resolved migration, where you are guaranteed that the migration file exists\n *\n * @internal\n */\nexport interface ResolvedMigration {\n  id: string\n  migration: Migration\n}\n\n/**\n * Resolves all migrations in the studio working directory\n *\n * @param workDir - The studio working directory\n * @returns Array of migrations and their respective paths\n * @internal\n */\nexport async function resolveMigrations(workDir: string): Promise<ResolvedMigration[]> {\n  let unregister\n  if (!__DEV__) {\n    unregister = register({\n      target: `node${process.version.slice(1)}`,\n    }).unregister\n  }\n\n  const migrationsDir = path.join(workDir, MIGRATIONS_DIRECTORY)\n  const migrationEntries = await readdir(migrationsDir, {withFileTypes: true})\n\n  const migrations: ResolvedMigration[] = []\n  for (const entry of migrationEntries) {\n    const entryName = entry.isDirectory() ? entry.name : removeMigrationScriptExtension(entry.name)\n    const candidates = resolveMigrationScript(workDir, entryName).filter(isLoadableMigrationScript)\n\n    for (const candidate of candidates) {\n      migrations.push({\n        id: entryName,\n        migration: candidate.mod.default,\n      })\n    }\n  }\n\n  if (unregister) {\n    unregister()\n  }\n\n  return migrations\n}\n\nfunction removeMigrationScriptExtension(fileName: string) {\n  // Remove `.ts`, `.js` etc from the end of a filename\n  return MIGRATION_SCRIPT_EXTENSIONS.reduce(\n    (name, ext) => (name.endsWith(`.${ext}`) ? path.basename(name, `.${ext}`) : name),\n    fileName,\n  )\n}\n\nexport default listMigrationCommand\n","export default {\n  name: 'migration',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages content migrations for Content Lake datasets',\n}\n","import {isIndexSegment, isIndexTuple, isKeySegment, type Path} from '@sanity/types'\n\n// FIXME: de-dupe this\n// copy/paste of `pathToString` from 'sanity' to prevent circular imports\nfunction pathToString(path: Path): string {\n  if (!Array.isArray(path)) {\n    throw new Error('Path is not an array')\n  }\n\n  return path.reduce<string>((target, segment, i) => {\n    if (isIndexSegment(segment)) {\n      return `${target}[${segment}]`\n    }\n\n    if (isKeySegment(segment) && segment._key) {\n      return `${target}[_key==\"${segment._key}\"]`\n    }\n\n    if (isIndexTuple(segment)) {\n      const [from, to] = segment\n      return `${target}[${from}:${to}]`\n    }\n\n    if (typeof segment === 'string') {\n      const separator = i === 0 ? '' : '.'\n      return `${target}${separator}${segment}`\n    }\n\n    throw new Error(`Unsupported path segment \\`${JSON.stringify(segment)}\\``)\n  }, '')\n}\n\ninterface BaseNode {\n  path: Path\n}\n\nexport interface Tree<Node extends BaseNode> {\n  nodes?: Node[]\n  children?: Record<string, Tree<Node>>\n}\n\n/**\n * Recursively calculates the max length of all the keys in the given validation\n * tree respecting extra length due to indentation depth. Used to calculate the\n * padding for the rest of the tree.\n */\nexport const maxKeyLength = (children: Record<string, Tree<BaseNode>> = {}, depth = 0): number => {\n  return Object.entries(children)\n    .map(([key, child]) =>\n      Math.max(key.length + depth * 2, maxKeyLength(child.children, depth + 1)),\n    )\n    .reduce((max, next) => (next > max ? next : max), 0)\n}\n\ninterface Options<Node extends BaseNode> {\n  node?: Record<string, Tree<Node>>\n  paddingLength: number\n  indent?: string\n  getNodes?: (node: Tree<Node>) => Node[] | undefined\n  getMessage: (node: Node) => string\n}\n\n/**\n * Recursively formats a given tree into a printed user-friendly tree structure\n */\nexport const formatTree = <Node extends BaseNode>({\n  node = {},\n  paddingLength,\n  indent = '',\n  getNodes: getLeaves = ({nodes}) => nodes,\n  getMessage,\n}: Options<Node>): string => {\n  const entries = Object.entries(node)\n\n  return entries\n    .map(([key, child], index) => {\n      const isLast = index === entries.length - 1\n      const nextIndent = `${indent}${isLast ? '  ' : '│ '}`\n      const leaves = getLeaves(child)\n\n      const nested = formatTree({\n        node: child.children,\n        paddingLength,\n        indent: nextIndent,\n        getNodes: getLeaves,\n        getMessage,\n      })\n\n      if (!leaves?.length) {\n        const current = `${indent}${isLast ? '└' : '├'}─ ${key}`\n        return [current, nested].filter(Boolean).join('\\n')\n      }\n\n      const [first, ...rest] = leaves\n      const firstPadding = '.'.repeat(paddingLength - indent.length - key.length)\n      const elbow = isLast ? '└' : '├'\n      const subsequentPadding = ' '.repeat(paddingLength - indent.length + 2)\n\n      const firstMessage = `${indent}${elbow}─ ${key} ${firstPadding} ${getMessage(first)}`\n      const subsequentMessages = rest\n        .map((marker) => `${nextIndent}${subsequentPadding} ${getMessage(marker)}`)\n        .join('\\n')\n\n      const current = [firstMessage, subsequentMessages].filter(Boolean).join('\\n')\n      return [current, nested].filter(Boolean).join('\\n')\n    })\n    .join('\\n')\n}\n\n/**\n * Converts a set of markers with paths into a tree of markers where the paths\n * are embedded in the tree\n */\nexport function convertToTree<const Node extends BaseNode>(nodes: Node[]): Tree<Node> {\n  const root: Tree<Node> = {}\n\n  // add the markers to the tree\n  function addNode(node: Node, tree: Tree<Node> = root) {\n    // if we've traversed the whole path\n    if (!node.path.length) {\n      if (!tree.nodes) tree.nodes = [] // ensure markers is defined\n\n      // then add the marker to the front\n      tree.nodes.push(node)\n      return\n    }\n\n    const [current, ...rest] = node.path\n    const key = pathToString([current])\n\n    // ensure the current node has children and the next node\n    if (!tree.children) tree.children = {}\n    if (!(key in tree.children)) tree.children[key] = {}\n\n    addNode({...node, path: rest}, tree.children[key])\n  }\n\n  for (const node of nodes) addNode(node)\n  return root\n}\n","import {isatty} from 'node:tty'\n\nimport {type Migration, type Mutation, type NodePatch, type Transaction} from '@sanity/migrate'\nimport {type KeyedSegment} from '@sanity/types'\nimport {type Chalk} from 'chalk'\n\nimport {convertToTree, formatTree, maxKeyLength} from '../../util/tree'\n\ntype ItemRef = string | number\ntype Impact = 'destructive' | 'maybeDestructive' | 'incremental'\ntype Variant = Impact | 'info'\n\nconst isTty = isatty(1)\n\ninterface FormatterOptions<Subject> {\n  chalk: Chalk\n  subject: Subject\n  migration: Migration\n  indentSize?: number\n}\n\nexport function prettyFormat({\n  chalk,\n  subject,\n  migration,\n  indentSize = 0,\n}: FormatterOptions<Mutation | Transaction | (Mutation | Transaction)[]>): string {\n  return (Array.isArray(subject) ? subject : [subject])\n    .map((subjectEntry) => {\n      if (subjectEntry.type === 'transaction') {\n        return [\n          [\n            badge('transaction', 'info', chalk),\n            typeof subjectEntry.id === 'undefined' ? null : chalk.underline(subjectEntry.id),\n          ]\n            .filter(Boolean)\n            .join(' '),\n          indent(\n            prettyFormat({\n              chalk,\n              subject: subjectEntry.mutations,\n              migration,\n              indentSize: indentSize,\n            }),\n          ),\n        ].join('\\n\\n')\n      }\n      return prettyFormatMutation({\n        chalk,\n        subject: subjectEntry,\n        migration,\n        indentSize,\n      })\n    })\n    .join('\\n\\n')\n}\n\nfunction encodeItemRef(ref: number | KeyedSegment): ItemRef {\n  return typeof ref === 'number' ? ref : ref._key\n}\n\nfunction badgeStyle(chalk: Chalk, variant: Variant): Chalk {\n  const styles: Record<Variant, Chalk> = {\n    info: chalk.bgWhite.black,\n    incremental: chalk.bgGreen.black.bold,\n    maybeDestructive: chalk.bgYellow.black.bold,\n    destructive: chalk.bgRed.black.bold,\n  }\n\n  return styles[variant]\n}\n\nfunction badge(label: string, variant: Variant, chalk: Chalk): string {\n  if (!isTty) {\n    return `[${label}]`\n  }\n\n  return badgeStyle(chalk, variant)(` ${label} `)\n}\n\nconst mutationImpact: Record<Mutation['type'], Impact> = {\n  create: 'incremental',\n  createIfNotExists: 'incremental',\n  createOrReplace: 'maybeDestructive',\n  delete: 'destructive',\n  patch: 'maybeDestructive',\n}\n\nfunction documentId(mutation: Mutation): string | undefined {\n  if ('id' in mutation) {\n    return mutation.id\n  }\n\n  if ('document' in mutation) {\n    return mutation.document._id\n  }\n\n  return undefined\n}\n\nconst listFormatter = new Intl.ListFormat('en-US', {\n  type: 'disjunction',\n})\n\nfunction mutationHeader(chalk: Chalk, mutation: Mutation, migration: Migration): string {\n  const mutationType = badge(mutation.type, mutationImpact[mutation.type], chalk)\n\n  const documentType =\n    'document' in mutation || migration.documentTypes\n      ? badge(\n          'document' in mutation\n            ? mutation.document._type\n            : listFormatter.format(migration.documentTypes ?? []),\n          'info',\n          chalk,\n        )\n      : null\n\n  // TODO: Should we list documentType when a mutation can be yielded for any document type?\n  return [mutationType, documentType, chalk.underline(documentId(mutation))]\n    .filter(Boolean)\n    .join(' ')\n}\n\nexport function prettyFormatMutation({\n  chalk,\n  subject,\n  migration,\n  indentSize = 0,\n}: FormatterOptions<Mutation>): string {\n  const lock =\n    'options' in subject ? chalk.cyan(`(if revision==${subject.options?.ifRevision})`) : ''\n  const header = [mutationHeader(chalk, subject, migration), lock].join(' ')\n  const padding = ' '.repeat(indentSize)\n\n  if (\n    subject.type === 'create' ||\n    subject.type === 'createIfNotExists' ||\n    subject.type === 'createOrReplace'\n  ) {\n    return [header, '\\n', indent(JSON.stringify(subject.document, null, 2), indentSize)].join('')\n  }\n\n  if (subject.type === 'patch') {\n    const tree = convertToTree<NodePatch>(subject.patches.flat())\n    const paddingLength = Math.max(maxKeyLength(tree.children) + 2, 30)\n\n    return [\n      header,\n      '\\n',\n      formatTree<NodePatch>({\n        node: tree.children,\n        paddingLength,\n        indent: padding,\n        getMessage: (patch) => formatPatchMutation(chalk, patch),\n      }),\n    ].join('')\n  }\n\n  return header\n}\n\nfunction formatPatchMutation(chalk: Chalk, patch: NodePatch): string {\n  const {op} = patch\n  const formattedType = chalk.bold(op.type)\n  if (op.type === 'unset') {\n    return `${chalk.red(formattedType)}()`\n  }\n  if (op.type === 'diffMatchPatch') {\n    return `${chalk.yellow(formattedType)}(${op.value})`\n  }\n  if (op.type === 'inc' || op.type === 'dec') {\n    return `${chalk.yellow(formattedType)}(${op.amount})`\n  }\n  if (op.type === 'set') {\n    return `${chalk.yellow(formattedType)}(${JSON.stringify(op.value)})`\n  }\n  if (op.type === 'setIfMissing') {\n    return `${chalk.green(formattedType)}(${JSON.stringify(op.value)})`\n  }\n  if (op.type === 'insert') {\n    return `${chalk.green(formattedType)}(${op.position}, ${encodeItemRef(\n      op.referenceItem,\n    )}, ${JSON.stringify(op.items)})`\n  }\n  if (op.type === 'replace') {\n    return `${chalk.yellow(formattedType)}(${encodeItemRef(op.referenceItem)}, ${JSON.stringify(\n      op.items,\n    )})`\n  }\n  if (op.type === 'truncate') {\n    return `${chalk.red(formattedType)}(${op.startIndex}, ${op.endIndex})`\n  }\n  // @ts-expect-error all cases are covered\n  throw new Error(`Invalid operation type: ${op.type}`)\n}\n\nfunction indent(subject: string, size = 2): string {\n  const padding = ' '.repeat(size)\n\n  return subject\n    .split('\\n')\n    .map((line) => padding + line)\n    .join('\\n')\n}\n","import path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {\n  DEFAULT_MUTATION_CONCURRENCY,\n  dryRun,\n  MAX_MUTATION_CONCURRENCY,\n  type Migration,\n  type MigrationProgress,\n  run,\n} from '@sanity/migrate'\nimport {Table} from 'console-table-printer'\nimport {register} from 'esbuild-register/dist/node'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {debug} from '../../debug'\nimport {MIGRATIONS_DIRECTORY} from './constants'\nimport {resolveMigrations} from './listMigrationsCommand'\nimport {prettyFormat} from './prettyMutationFormatter'\nimport {isLoadableMigrationScript, resolveMigrationScript} from './utils/resolveMigrationScript'\n\nconst helpText = `\nOptions\n  --no-dry-run By default the migration runs in dry mode. Pass this option to migrate dataset.\n  --concurrency <concurrent> How many mutation requests to run in parallel. Must be between 1 and ${MAX_MUTATION_CONCURRENCY}. Default: ${DEFAULT_MUTATION_CONCURRENCY}.\n  --no-progress Don't output progress. Useful if you want debug your migration script and see the output of console.log() statements.\n  --dataset <dataset> Dataset to migrate. Defaults to the dataset configured in your Sanity CLI config.\n  --project <project id> Project ID of the dataset to migrate. Defaults to the projectId configured in your Sanity CLI config.\n  --no-confirm Skip the confirmation prompt before running the migration. Make sure you know what you're doing before using this flag.\n  --from-export <export.tar.gz> Use a local dataset export as source for migration instead of calling the Sanity API. Note: this is only supported for dry runs.\n\n\nExamples\n  # dry run the migration\n  sanity migration run <id>\n\n  # execute the migration against a dataset\n  sanity migration run <id> --no-dry-run --project xyz --dataset staging\n\n  # execute the migration using a dataset export as the source\n  sanity migration run <id>  --from-export=production.tar.gz --no-dry-run --projectId xyz --dataset staging\n`\n\ninterface CreateFlags {\n  ['dry-run']?: boolean\n  concurrency?: number\n  ['from-export']?: string\n  progress?: boolean\n  dataset?: string\n  project?: string\n  confirm?: boolean\n}\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .options('dry-run', {type: 'boolean', default: true})\n    .options('concurrency', {type: 'number', default: DEFAULT_MUTATION_CONCURRENCY})\n    .options('progress', {type: 'boolean', default: true})\n    .options('dataset', {type: 'string'})\n    .options('from-export', {type: 'string'})\n    .options('project', {type: 'string'})\n    .options('confirm', {type: 'boolean', default: true}).argv\n}\n\nconst runMigrationCommand: CliCommandDefinition<CreateFlags> = {\n  name: 'run',\n  group: 'migration',\n  signature: 'ID',\n  helpText,\n  description: 'Run a migration against a dataset',\n  // eslint-disable-next-line max-statements\n  action: async (args, context) => {\n    const {apiClient, output, prompt, chalk, workDir} = context\n    const [id] = args.argsWithoutOptions\n    const migrationsDirectoryPath = path.join(workDir, MIGRATIONS_DIRECTORY)\n\n    const flags = await parseCliFlags(args)\n\n    const fromExport = flags.fromExport\n    const dry = flags.dryRun\n    const dataset = flags.dataset\n    const project = flags.project\n\n    if ((dataset && !project) || (project && !dataset)) {\n      throw new Error('If either --dataset or --project is provided, both must be provided')\n    }\n\n    if (!id) {\n      output.error(chalk.red('Error: Migration ID must be provided'))\n      const migrations = await resolveMigrations(workDir)\n      const table = new Table({\n        title: `Migrations found in project`,\n        columns: [\n          {name: 'id', title: 'ID', alignment: 'left'},\n          {name: 'title', title: 'Title', alignment: 'left'},\n        ],\n      })\n\n      migrations.forEach((definedMigration) => {\n        table.addRow({id: definedMigration.id, title: definedMigration.migration.title})\n      })\n      table.printTable()\n      output.print('\\nRun `sanity migration run <ID>` to run a migration')\n\n      return\n    }\n\n    if (!__DEV__) {\n      register({\n        target: `node${process.version.slice(1)}`,\n      })\n    }\n\n    const candidates = resolveMigrationScript(workDir, id)\n    const resolvedScripts = candidates.filter(isLoadableMigrationScript)\n\n    if (resolvedScripts.length > 1) {\n      // todo: consider prompt user about which one to run? note: it's likely a mistake if multiple files resolve to the same name\n      throw new Error(\n        `Found multiple migrations for \"${id}\" in ${chalk.cyan(migrationsDirectoryPath)}: \\n - ${candidates\n          .map((candidate) => path.relative(migrationsDirectoryPath, candidate.absolutePath))\n          .join('\\n - ')}`,\n      )\n    }\n\n    const script = resolvedScripts[0]\n    if (!script) {\n      throw new Error(\n        `No migration found for \"${id}\" in ${chalk.cyan(chalk.cyan(migrationsDirectoryPath))}. Make sure that the migration file exists and exports a valid migration as its default export.\\n\n Tried the following files:\\n - ${candidates\n   .map((candidate) => path.relative(migrationsDirectoryPath, candidate.absolutePath))\n   .join('\\n - ')}`,\n      )\n    }\n\n    const mod = script.mod\n    if ('up' in mod || 'down' in mod) {\n      // todo: consider adding support for up/down as separate named exports\n      // For now, make sure we reserve the names for future use\n      throw new Error(\n        'Only \"up\" migrations are supported at this time, please use a default export',\n      )\n    }\n\n    const migration: Migration = mod.default\n\n    if (fromExport && !dry) {\n      throw new Error('Can only dry run migrations from a dataset export file')\n    }\n\n    const concurrency = flags.concurrency\n    if (concurrency !== undefined) {\n      if (concurrency > MAX_MUTATION_CONCURRENCY) {\n        throw new Error(\n          `Concurrency exceeds the maximum allowed value of ${MAX_MUTATION_CONCURRENCY}`,\n        )\n      }\n\n      if (concurrency === 0) {\n        throw new Error(`Concurrency must be a positive number, got ${concurrency}`)\n      }\n    }\n\n    const projectConfig = apiClient({\n      requireUser: true,\n      requireProject: true,\n    }).config()\n\n    const apiConfig = {\n      dataset: dataset ?? projectConfig.dataset!,\n      projectId: project ?? projectConfig.projectId!,\n      apiHost: projectConfig.apiHost!,\n      token: projectConfig.token!,\n      apiVersion: 'v2024-01-29',\n    } as const\n    if (dry) {\n      dryRunHandler()\n      return\n    }\n\n    output.print(\n      `\\n${chalk.yellow(chalk.bold('Note: During migrations, your webhooks stay active.'))}`,\n    )\n    output.print(\n      `To adjust them, launch the management interface with ${chalk.cyan('sanity manage')}, navigate to the API settings, and toggle the webhooks before and after the migration as needed.\\n`,\n    )\n\n    const response =\n      flags.confirm &&\n      (await prompt.single<boolean>({\n        message: `This migration will run on the ${chalk.yellow(\n          chalk.bold(apiConfig.dataset),\n        )} dataset in ${chalk.yellow(chalk.bold(apiConfig.projectId))} project. Are you sure?`,\n        type: 'confirm',\n      }))\n\n    if (response === false) {\n      debug('User aborted migration')\n      return\n    }\n\n    const spinner = output.spinner(`Running migration \"${id}\"`).start()\n    await run({api: apiConfig, concurrency, onProgress: createProgress(spinner)}, migration)\n    spinner.stop()\n\n    function createProgress(progressSpinner: ReturnType<typeof output.spinner>) {\n      return function onProgress(progress: MigrationProgress) {\n        if (!flags.progress) {\n          progressSpinner.stop()\n          return\n        }\n        if (progress.done) {\n          progressSpinner.text = `Migration \"${id}\" completed.\n\n  Project id:  ${chalk.bold(apiConfig.projectId)}\n  Dataset:     ${chalk.bold(apiConfig.dataset)}\n\n  ${progress.documents} documents processed.\n  ${progress.mutations} mutations generated.\n  ${chalk.green(progress.completedTransactions.length)} transactions committed.`\n          progressSpinner.stopAndPersist({symbol: chalk.green('✔')})\n          return\n        }\n\n        ;[null, ...progress.currentTransactions].forEach((transaction) => {\n          progressSpinner.text = `Running migration \"${id}\" ${dry ? 'in dry mode...' : '...'}\n\n  Project id:     ${chalk.bold(apiConfig.projectId)}\n  Dataset:        ${chalk.bold(apiConfig.dataset)}\n  Document type:  ${chalk.bold(migration.documentTypes?.join(','))}\n\n  ${progress.documents} documents processed…\n  ${progress.mutations} mutations generated…\n  ${chalk.blue(progress.pending)} requests pending…\n  ${chalk.green(progress.completedTransactions.length)} transactions committed.\n\n  ${\n    transaction && !progress.done\n      ? `» ${prettyFormat({chalk, subject: transaction, migration, indentSize: 2})}`\n      : ''\n  }`\n        })\n      }\n    }\n\n    async function dryRunHandler() {\n      output.print(`Running migration \"${id}\" in dry mode`)\n\n      if (fromExport) {\n        output.print(`Using export ${chalk.cyan(fromExport)}`)\n      }\n\n      output.print()\n      output.print(`Project id:  ${chalk.bold(apiConfig.projectId)}`)\n      output.print(`Dataset:     ${chalk.bold(apiConfig.dataset)}`)\n\n      for await (const mutation of dryRun({api: apiConfig, exportPath: fromExport}, migration)) {\n        if (!mutation) continue\n        output.print()\n        output.print(\n          prettyFormat({\n            chalk,\n            subject: mutation,\n            migration,\n          }),\n        )\n      }\n    }\n  },\n}\n\nexport default runMigrationCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type StartPreviewServerCommandFlags} from '../../actions/preview/previewAction'\n\nconst helpText = `\nNotes\n  Changing the hostname or port number might require a new entry to the CORS-origins allow list.\n\nOptions\n  --port <port> TCP port to start server on. [default: 3333]\n  --host <host> The local network interface at which to listen. [default: \"127.0.0.1\"]\n\nExamples\n  sanity preview --host=0.0.0.0\n  sanity preview --port=1942\n  sanity preview some/build-output-dir\n`\n\nconst previewCommand: CliCommandDefinition = {\n  name: 'preview',\n  signature: '[BUILD_OUTPUT_DIR] [--port <port>] [--host <host>]',\n  description: 'Starts a server to preview a production build of Sanity Studio',\n  action: async (\n    args: CliCommandArguments<StartPreviewServerCommandFlags>,\n    context: CliCommandContext,\n  ) => {\n    const previewAction = await getPreviewAction()\n\n    return previewAction(args, context)\n  },\n  helpText,\n}\n\nasync function getPreviewAction() {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n    const mod: typeof import('../../actions/preview/previewAction') = require('../../actions/preview/previewAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/preview/previewAction')\n\n  return mod.default\n}\n\nexport default previewCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = 'Extracts a JSON representation of a Sanity schema within a Studio context.'\n\nconst helpText = `\n**Note**: This command is experimental and subject to change.\n\nOptions\n  --workspace <name> The name of the workspace to generate a schema for\n  --path Optional path to specify destination of the schema file\n  --enforce-required-fields Makes the schema generated treat fields marked as required as non-optional. Defaults to false.\n  --format=[groq-type-nodes] Format the schema as GROQ type nodes. Only available format at the moment.\n\nExamples\n  # Extracts schema types in a Sanity project with more than one workspace\n  sanity schema extract --workspace default\n`\n\nconst extractSchemaCommand: CliCommandDefinition = {\n  name: 'extract',\n  group: 'schema',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/schema/extractAction')\n\n    return mod.default(args, context)\n  },\n} satisfies CliCommandDefinition\n\nexport default extractSchemaCommand\n","export default {\n  name: 'schema',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Interacts with Sanity Studio schema configurations',\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = 'Validates all schema types specified in a workspace.'\n\nconst helpText = `\nOptions\n  --workspace <name> The name of the workspace to use when validating all schema types.\n  --format <pretty|ndjson|json> The output format used to print schema errors and warnings.\n  --level <error|warning> The minimum level reported out. Defaults to warning.\n\nExamples\n  # Validates all schema types in a Sanity project with more than one workspace\n  sanity schema validate --workspace default\n\n  # Save the results of the report into a file\n  sanity schema validate > report.txt\n\n  # Report out only errors\n  sanity schema validate --level error\n`\n\nconst validateDocumentsCommand: CliCommandDefinition = {\n  name: 'validate',\n  group: 'schema',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/schema/validateAction')\n\n    return mod.default(args, context)\n  },\n} satisfies CliCommandDefinition\n\nexport default validateDocumentsCommand\n","/* eslint-disable no-process-env */\nexport const isInteractive =\n  process.stdout.isTTY && process.env.TERM !== 'dumb' && !('CI' in process.env)\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type StartPreviewServerCommandFlags} from '../../actions/preview/previewAction'\nimport {isInteractive} from '../../util/isInteractive'\nimport {getDevAction} from '../dev/devCommand'\n\nconst helpText = `\nNotes\n  Changing the hostname or port number might require a new CORS-entry to be added.\n\nOptions\n  --port <port> TCP port to start server on. [default: 3333]\n  --host <host> The local network interface at which to listen. [default: \"127.0.0.1\"]\n\nExamples\n  sanity start --host=0.0.0.0\n  sanity start --port=1942\n  sanity start some/build-output-dir\n`\n\nconst startCommand: CliCommandDefinition = {\n  name: 'start',\n  signature: '[BUILD_OUTPUT_DIR] [--port <port>] [--host <host>]',\n  description: 'Alias for `sanity preview`',\n  action: async (\n    args: CliCommandArguments<StartPreviewServerCommandFlags>,\n    context: CliCommandContext,\n  ) => {\n    const {output, chalk, prompt} = context\n    const previewAction = await getPreviewAction()\n\n    const warn = (msg: string) => output.warn(chalk.yellow.bgBlack(msg))\n    const error = (msg: string) => output.warn(chalk.red.bgBlack(msg))\n    warn('╭───────────────────────────────────────────────────────────╮')\n    warn('│                                                           │')\n    warn(\"│  You're running Sanity Studio v3. In this version the     │\")\n    warn('│  [start] command is used to preview static builds.        |')\n    warn('│                                                           │')\n    warn('│  To run a development server, use the [npm run dev] or    |')\n    warn('│  [npx sanity dev] command instead. For more information,  │')\n    warn('│  see https://www.sanity.io/help/studio-v2-vs-v3           │')\n    warn('│                                                           │')\n    warn('╰───────────────────────────────────────────────────────────╯')\n    warn('') // Newline to separate from other output\n\n    try {\n      await previewAction(args, context)\n    } catch (err) {\n      if (err.name !== 'BUILD_NOT_FOUND') {\n        throw err\n      }\n\n      error(err.message)\n      error('\\n')\n\n      const shouldRunDevServer =\n        isInteractive &&\n        (await prompt.single({\n          message: 'Do you want to start a development server instead?',\n          type: 'confirm',\n        }))\n\n      if (shouldRunDevServer) {\n        const devAction = await getDevAction()\n        await devAction(args, context)\n      } else {\n        // Indicate that this isn't an expected exit\n        // eslint-disable-next-line no-process-exit\n        process.exit(1)\n      }\n    }\n  },\n  helpText,\n}\n\nasync function getPreviewAction() {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n    const mod: typeof import('../../actions/preview/previewAction') = require('../../actions/preview/previewAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/preview/previewAction')\n\n  return mod.default\n}\n\nexport default startCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst uninstallCommand: CliCommandDefinition = {\n  name: 'uninstall',\n  signature: '[plugin]',\n  helpText: '',\n  description: 'Removes a Sanity plugin from the current Sanity configuration',\n  hideFromHelp: true,\n  action: async (args, context) => {\n    await context.output.error('`sanity uninstall` is no longer supported - use npm/yarn')\n  },\n}\n\nexport default uninstallCommand\n","export function prettifyQuotaError(message: string) {\n  return (err: Error & {statusCode?: number}): Error & {statusCode?: number} => {\n    if (err.statusCode === 402) {\n      err.message = message\n      throw err\n    }\n\n    throw err\n  }\n}\n","import {type CliCommandDefinition, type CliPrompter} from '@sanity/cli'\n\nimport {prettifyQuotaError} from '../../util/prettifyQuotaError'\nimport {type Role} from './types'\n\nconst helpText = `\nOptions\n  --role Role to invite the user as\n\nExamples\n  # Invite a new user to the project (prompt for details)\n  sanity users invite\n\n  # Send a new user invite to the email \"pippi@sanity.io\", prompt for role\n  sanity users invite pippi@sanity.io\n\n  # Send a new user invite to the email \"pippi@sanity.io\", as administrator\n  sanity users invite pippi@sanity.io --role administrator\n`\n\ninterface InviteFlags {\n  role?: string\n}\n\nconst inviteUserCommand: CliCommandDefinition<InviteFlags> = {\n  name: 'invite',\n  group: 'users',\n  signature: '[EMAIL]',\n  helpText,\n  description: 'Invite a new user to the project',\n  action: async (args, context) => {\n    const {apiClient, output, prompt} = context\n    const [selectedEmail] = args.argsWithoutOptions\n    const flags = args.extOptions\n\n    const client = apiClient().clone().config({useProjectHostname: false, apiVersion: '2021-06-07'})\n    const {projectId} = client.config()\n    const roles = (await client.request<Role[]>({uri: `/projects/${projectId}/roles`})).filter(\n      (role) => role.appliesToUsers,\n    )\n    const email = selectedEmail || (await promptForEmail(prompt))\n    const selectedRole = flags.role || (await promptForRole(prompt, roles))\n    const role = roles.find(({name}) => name.toLowerCase() === selectedRole.toLowerCase())\n    if (!role) {\n      throw new Error(`Role name \"${selectedRole}\" not found`)\n    }\n\n    await client\n      .clone()\n      .request({\n        method: 'POST',\n        uri: `/invitations/project/${projectId}`,\n        body: {email, role: role.name},\n        useGlobalApi: true,\n        maxRedirects: 0,\n      })\n      .catch(\n        prettifyQuotaError(\n          'Project is already at user quota, add billing details to the project in order to allow overage charges.',\n        ),\n      )\n\n    output.print(`Invitation sent to ${email}`)\n  },\n}\n\nexport default inviteUserCommand\n\nfunction promptForEmail(prompt: CliPrompter): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Email to invite:',\n    filter: (val) => val.trim(),\n    validate: (name) => {\n      if (!name || !name.includes('@')) {\n        return 'Invalid email'\n      }\n\n      return true\n    },\n  })\n}\n\nfunction promptForRole(prompt: CliPrompter, roles: Role[]): Promise<string> {\n  return prompt.single({\n    type: 'list',\n    message: 'Which role should the user have?',\n    choices: roles.map((role) => ({\n      value: role.name,\n      name: `${role.title} (${role.description})`,\n    })),\n  })\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport {size, sortBy} from 'lodash'\n\nimport {type Invite, type PartialProjectResponse, type User} from './types'\n\nconst sortFields = ['id', 'name', 'role', 'date']\n\nconst helpText = `\nOptions\n  --no-invitations Don't include pending invitations\n  --no-robots Don't include robots (token users)\n  --sort <field> Sort users by specified column: ${sortFields.join(', ')}\n  --order <asc/desc> Sort output ascending/descending\n\nExamples\n  # List all users of the project\n  sanity users list\n\n  # List all users of the project, but exclude pending invitations and robots\n  sanity users list --no-invitations --no-robots\n\n  # List all users, sorted by role\n  sanity users list --sort role\n`\n\nconst listUsersCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'users',\n  signature: '',\n  helpText,\n  description: 'List all users of the project',\n  action: async (args, context) => {\n    const {apiClient, output, chalk} = context\n    const {sort, order, robots, invitations} = {\n      sort: 'date',\n      order: 'asc',\n      robots: true,\n      invitations: true,\n      ...args.extOptions,\n    }\n\n    if (!sortFields.includes(sort)) {\n      throw new Error(`Can't sort by field \"${sort}\". Must be one of ${sortFields.join(', ')}`)\n    }\n\n    if (order !== 'asc' && order !== 'desc') {\n      throw new Error(`Unknown sort order \"${order}\", must be either \"asc\" or \"desc\"`)\n    }\n\n    const client = apiClient()\n    const globalClient = client.clone().config({useProjectHostname: false})\n    const {projectId} = client.config()\n\n    const useGlobalApi = true\n    const [pendingInvitations, project] = await Promise.all([\n      invitations\n        ? globalClient\n            .request<Invite[]>({uri: `/invitations/project/${projectId}`, useGlobalApi})\n            .then(getPendingInvitations)\n        : [],\n      globalClient.request<PartialProjectResponse>({uri: `/projects/${projectId}`, useGlobalApi}),\n    ])\n\n    const memberIds = project.members.map((member) => member.id)\n    const users = await globalClient\n      .request<User | User[]>({uri: `/users/${memberIds.join(',')}`, useGlobalApi})\n      .then((user) => (Array.isArray(user) ? user : [user]))\n\n    const projectMembers = project.members\n      .map((member) => ({\n        ...member,\n        ...getUserProps(users.find((candidate) => candidate.id === member.id)),\n      }))\n      .filter((member) => !member.isRobot || robots)\n\n    const members = [...projectMembers, ...pendingInvitations]\n\n    const ordered = sortBy(\n      members.map(({id, name, role, date}) => [id, name, role, date]),\n      [sortFields.indexOf(sort)],\n    )\n\n    const rows = order === 'asc' ? ordered : ordered.reverse()\n\n    const maxWidths = rows.reduce(\n      (max, row) => row.map((current, index) => Math.max(size(current), max[index])),\n      sortFields.map((str) => size(str)),\n    )\n\n    const printRow = (row: string[]) => {\n      const isInvite = row[0] === '<pending>'\n      const textRow = row.map((col, i) => `${col}`.padEnd(maxWidths[i])).join('   ')\n      return isInvite ? chalk.dim(textRow) : textRow\n    }\n\n    output.print(chalk.cyan(printRow(sortFields)))\n    rows.forEach((row) => output.print(printRow(row)))\n  },\n}\n\nfunction getUserProps(user: User | undefined) {\n  const {displayName: name, createdAt: date} = user || {}\n  return {name: name || '', date: date || ''}\n}\n\nfunction getPendingInvitations(invitations: Invite[]) {\n  return invitations\n    .filter((invite) => !invite.isAccepted && !invite.isRevoked && !invite.acceptedByUserId)\n    .map((invite) => ({\n      id: '<pending>',\n      name: invite.email,\n      role: invite.role,\n      date: invite.createdAt,\n    }))\n}\n\nexport default listUsersCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nexport const usersGroup: CliCommandGroupDefinition = {\n  name: 'users',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages users of your Sanity project',\n}\n\nexport default usersGroup\n","import {type CliCommandDefinition, type CliCommandGroupDefinition} from '@sanity/cli'\n\nimport backupGroup from './backup/backupGroup'\nimport disableBackupCommand from './backup/disableBackupCommand'\nimport downloadBackupCommand from './backup/downloadBackupCommand'\nimport enableBackupCommand from './backup/enableBackupCommand'\nimport listBackupCommand from './backup/listBackupCommand'\nimport buildCommand from './build/buildCommand'\nimport checkCommand from './check/checkCommand'\nimport configCheckCommand from './config/configCheckCommand'\nimport addCorsOriginCommand from './cors/addCorsOriginCommand'\nimport corsGroup from './cors/corsGroup'\nimport deleteCorsOriginCommand from './cors/deleteCorsOriginCommand'\nimport listCorsOriginsCommand from './cors/listCorsOriginsCommand'\nimport aliasDatasetCommand from './dataset/alias/aliasCommands'\nimport copyDatasetCommand from './dataset/copyDatasetCommand'\nimport createDatasetCommand from './dataset/createDatasetCommand'\nimport datasetGroup from './dataset/datasetGroup'\nimport datasetVisibilityCommand from './dataset/datasetVisibilityCommand'\nimport deleteDatasetCommand from './dataset/deleteDatasetCommand'\nimport exportDatasetCommand from './dataset/exportDatasetCommand'\nimport importDatasetCommand from './dataset/importDatasetCommand'\nimport listDatasetsCommand from './dataset/listDatasetsCommand'\nimport deployCommand from './deploy/deployCommand'\nimport undeployCommand from './deploy/undeployCommand'\nimport devCommand from './dev/devCommand'\nimport createDocumentsCommand from './documents/createDocumentsCommand'\nimport deleteDocumentsCommand from './documents/deleteDocumentsCommand'\nimport documentsGroup from './documents/documentsGroup'\nimport getDocumentsCommand from './documents/getDocumentsCommand'\nimport queryDocumentsCommand from './documents/queryDocumentsCommand'\nimport validateDocumentsCommand from './documents/validateDocumentsCommand'\nimport execCommand from './exec/execCommand'\nimport deleteGraphQLAPICommand from './graphql/deleteGraphQLAPICommand'\nimport deployGraphQLAPICommand from './graphql/deployGraphQLAPICommand'\nimport graphqlGroup from './graphql/graphqlGroup'\nimport listGraphQLAPIsCommand from './graphql/listGraphQLAPIsCommand'\nimport createHookCommand from './hook/createHookCommand'\nimport deleteHookCommand from './hook/deleteHookCommand'\nimport hookGroup from './hook/hookGroup'\nimport listHookLogsCommand from './hook/listHookLogsCommand'\nimport listHooksCommand from './hook/listHooksCommand'\nimport printHookAttemptCommand from './hook/printHookAttemptCommand'\nimport createMigrationCommand from './migration/createMigrationCommand'\nimport listMigrationsCommand from './migration/listMigrationsCommand'\nimport migrationGroup from './migration/migrationGroup'\nimport runMigrationCommand from './migration/runMigrationCommand'\nimport previewCommand from './preview/previewCommand'\nimport extractSchemaCommand from './schema/extractSchemaCommand'\nimport schemaGroup from './schema/schemaGroup'\nimport validateSchemaCommand from './schema/validateSchemaCommand'\nimport startCommand from './start/startCommand'\nimport uninstallCommand from './uninstall/uninstallCommand'\nimport inviteUserCommand from './users/inviteUserCommand'\nimport listUsersCommand from './users/listUsersCommand'\nimport usersGroup from './users/usersGroup'\n\nconst commands: (CliCommandDefinition | CliCommandGroupDefinition)[] = [\n  buildCommand,\n  checkCommand,\n  configCheckCommand,\n  datasetGroup,\n  deployCommand,\n  undeployCommand,\n  listDatasetsCommand,\n  createDatasetCommand,\n  datasetVisibilityCommand,\n  exportDatasetCommand,\n  importDatasetCommand,\n  deleteDatasetCommand,\n  copyDatasetCommand,\n  aliasDatasetCommand,\n  backupGroup,\n  listBackupCommand,\n  downloadBackupCommand,\n  disableBackupCommand,\n  enableBackupCommand,\n  corsGroup,\n  listCorsOriginsCommand,\n  addCorsOriginCommand,\n  deleteCorsOriginCommand,\n  usersGroup,\n  inviteUserCommand,\n  listUsersCommand,\n  hookGroup,\n  listHooksCommand,\n  createHookCommand,\n  migrationGroup,\n  createMigrationCommand,\n  runMigrationCommand,\n  listMigrationsCommand,\n  deleteHookCommand,\n  listHookLogsCommand,\n  printHookAttemptCommand,\n  documentsGroup,\n  getDocumentsCommand,\n  queryDocumentsCommand,\n  deleteDocumentsCommand,\n  createDocumentsCommand,\n  validateDocumentsCommand,\n  graphqlGroup,\n  listGraphQLAPIsCommand,\n  deployGraphQLAPICommand,\n  deleteGraphQLAPICommand,\n  devCommand,\n  startCommand,\n  schemaGroup,\n  validateSchemaCommand,\n  extractSchemaCommand,\n  previewCommand,\n  uninstallCommand,\n  execCommand,\n]\n\n/**\n * @deprecated Not actually deprecated, but these are internals and should not be relied upon outside of the Sanity team\n * @internal\n */\nexport const cliProjectCommands = {\n  requiredCliVersionRange: '^3.0.0',\n  commands,\n}\n"],"names":["defaultApiVersion","debug","debugIt","helpText","createWriteStream","zlib","progress","rimraf","CONNECTION_TIMEOUT","READ_TIMEOUT","request","getIt","keepAlive","promise","url","path","pipeline","Readable","prettyMs","size","createDebug","parseCliFlags","yargs","hideBin","mkdtemp","tmpdir","mkdirSync","Mutex","finished","isString","absolutify","existsSync","isAfter","Table","lightFormat","parse","isValid","promptForOrigin","oneline","logSymbols","fs","aliasClient.listAliases","aliasClient.createAlias","aliasClient.removeAlias","aliasClient.updateAlias","aliasClient.unlinkAlias","formatDistanceToNow","parseISO","formatDistance","Observable","EventSource","parseFlags","exportDataset","createReadStream","sanityImport","padStart","warn","json5","uuid","os","chokidar","execa","noop","isEqual","isPlainObject","pluralize","tokenize","description","validateDocumentsCommand","open","promptForHook","groupBy","inspect","types","deburr","writeFile","register","readdir","isIndexSegment","isKeySegment","isIndexTuple","node","indent","isatty","MAX_MUTATION_CONCURRENCY","DEFAULT_MUTATION_CONCURRENCY","run","dryRun","getPreviewAction","role","sortBy","aliasDatasetCommand","backupGroup","listBackupCommand","disableBackupCommand","enableBackupCommand","listMigrationsCommand","validateSchemaCommand"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAGO,MAAMA,sBAAoB,eAE3B,qBAAgD;AAAA,EACpD,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf;ACAA,SAAS,YAAY,KAAkB;AAVvC,MAAA,IAAA,IAAA,IAAA;AAWE,QAAM,SAAS,CAAA;AACX,SAAA,IAAI,OACN,OAAO,aAAa,IAAI,OACf,IAAI,eACb,OAAO,aAAa,IAAI,aAGtB,IAAI,UACN,OAAO,UAAU,IAAI,UACZ,IAAI,gBACb,OAAO,UAAU,IAAI,iBACZ,MAAK,KAAA,OAAA,OAAA,SAAA,IAAA,aAAL,mBAAe,SAAf,QAAA,GAAqB,UAC9B,OAAO,UAAU,IAAI,SAAS,KAAK,WAC1B,MAAK,KAAA,OAAA,OAAA,SAAA,IAAA,aAAL,OAAe,SAAA,GAAA,SAAf,WAAqB,UAC9B,OAAO,UAAU,IAAI,SAAS,KAAK,UAGnC,OAAO,UAAU,KAAK,UAAU,GAAG,GAG9B;AACT;AC9Ba,MAAAC,UAAQC,uBAAQ,aAAa;ACAnC,SAAS,oBAAoB,aAAqC;AACvE,MAAI,CAAC;AACI,WAAA;AAGH,QAAA,OAAO,GAAG,WAAW;AAEvB,SAAA,KAAK,YAAY,MAAM,OAClB,kDAGL,KAAK,SAAS,IACT,sDAGL,KAAK,SAAS,KACT,+CAGJ,YAAY,KAAK,IAAI,IAIrB,wBAAwB,KAAK,IAAI,IAIlC,QAAQ,KAAK,IAAI,IACZ,2DAGF,KAPE,4EAJA;AAYX;AC9BO,SAAS,qBACd,QACA,UAAgD,IAC/B;AACjB,SAAO,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAAS;AAAA,IACT,UAAU,CAAC,SACG,oBAAoB,IAAI,KAK7B;AAAA,IAET,GAAG;AAAA,EAAA,CACJ;AACH;AChBA,eAAsB,oBACpB,SACA,UAAuD,IACtC;AACjB,QAAM,EAAC,WAAW,WAAU,SACtB,EAAC,SAAS,cAAa,IAAI,SAC3B,SAAS,UAAA,GAET,WAAW,MAAM,OAAO,SAAS,KAAA,GACjC,gBAAgB,SAAS,KAAK,CAAC,YAAY,QAAQ,SAAS,YAAY,GACxE,iBAAiB,SAAS,IAAI,CAAC,aAAa,EAAC,OAAO,QAAQ,KAAI,EAAE,GAClE,WAAW,MAAM,OAAO,OAAO;AAAA,IACnC,SAAS,WAAW;AAAA,IACpB,MAAM;AAAA,IACN,SAAS,gBACL,CAAC,EAAC,OAAO,OAAO,MAAM,qBAAoB,GAAG,IAAI,OAAO,UAAa,GAAA,GAAG,cAAc,IACtF;AAAA,EAAA,CACL;AAED,MAAI,aAAa,OAAO;AACtBD,YAAM,wDAAwD;AACxD,UAAA,iBAAiB,MAAM,qBAAqB,QAAQ;AAAA,MACxD,SAAS;AAAA,MACT,SAAS,gBAAgB,SAAY;AAAA,IAAA,CACtC;AACD,WAAA,MAAM,OAAO,SAAS,OAAO,cAAc,GACpC;AAAA,EACT;AAEO,SAAA;AACT;ACvBA,eAAe,iBACb,SACA,aACA,YAC4B;AACtB,QAAA,EAAC,UAAa,IAAA;AAEpB,MAAI,SAAS;AACb,QAAM,EAAC,WAAW,MAAK,IAAI,OAAO,OAAO;AAEzC,MAAI,CAAC;AACG,UAAA,IAAI,MAAM,wBAAwB;AAK1C,MAAI,kBAA0B;AAC9B,SAAK,oBACH,kBAAkB,MAAM,oBAAoB,SAAS;AAAA,IACnD,SAAS;AAAA,EAAA,CACV,IAGH,SAAS,OAAO,WAAW,EAAC,SAAS,aAAa,WAAU,CAAC,GAEtD;AAAA,IACL;AAAA,IACA,aAAa;AAAA,IACb;AAAA,IACA;AAAA,EAAA;AAEJ;ACrCA,MAAME,aAAW;AAAA;AAAA;AAAA,GAKX,8BAAoD;AAAA,EACxD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbA;AAAAA,EACA,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,QAAQ,MAAA,IAAS,SAClB,CAAC,OAAO,IAAI,KAAK,oBACjB,EAAC,WAAW,aAAa,OAAO,OAAA,IAAU,MAAM;AAAA,MACpD;AAAA,MACA;AAAA,MACAH;AAAAA,IAAA;AAGE,QAAA;AACF,YAAM,OAAO,QAAQ;AAAA,QACnB,QAAQ;AAAA,QACR,SAAS,EAAC,eAAe,UAAU,KAAK,GAAE;AAAA,QAC1C,KAAK,aAAa,SAAS,aAAa,WAAW;AAAA,QACnD,MAAM;AAAA,UACJ,SAAS;AAAA,QACX;AAAA,MAAA,CACD,GACD,OAAO,MAAM,GAAG,MAAM,MAAM,sCAAsC,WAAW;AAAA,CAAI,CAAC,EAAE;AAAA,aAC7E,OAAO;AACd,YAAM,EAAC,QAAA,IAAW,YAAY,KAAK;AACnC,aAAO,MAAM,GAAG,MAAM,IAAI,oCAAoC,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAC9E;AAAA,EACF;AACF;ACzCA,IAAA,UAAe,QAAQ,OAAO,EAAE,eAAe;ACO/C,MAAM,WAAW,QAAQ,UAAU;AAMnC,SAAS,WAAW,WAAmB,aAAqB,YAAuC;AACjG,SAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AAChC,UAAA,qBAAqBI,qBAAkB,WAAW;AACrC,uBAAA,GAAG,SAAS,CAAC,QAAe;AAC7C,aAAO,GAAG;AAAA,IACX,CAAA,GAED,mBAAmB,GAAG,SAAS,MAAM;AAC3B;IAAA,CACT;AAEK,UAAA,UAAU,SAAS,OAAO;AAAA,MAC9B,MAAM;AAAA,MACN,aAAa,EAAC,OAAOC,sBAAK,UAAU,sBAAqB;AAAA,IAAA,CAC1D;AAEO,YAAA,GAAG,SAAS,CAAC,QAAe;AAC5BJ,cAAA;AAAA,KAA0B,IAAI,KAAK,GACzC,OAAO,GAAG;AAAA,IACX,CAAA,GAGD,QAAQ,GAAG,WAAW,CAAC,QAAe;AAC9BA,cAAA,uBAAuB,IAAI,OAAO;AAAA,IACzC,CAAA,GAED,QAAQ,GAAG,YAAY,CAACK,cAA2B;AACtC,iBAAAA,UAAS,GAAG,cAAc;AAAA,IACtC,CAAA,GAGD,QAAQ,KAAK,kBAAkB,GAC/B,QAAQ,UAAU,WAAW,EAAK,GAClC,QAAQ,SAAS;AAAA,EAAA,CAClB;AACH;ACzCA,MAAM,oBAAoB;AAE1B,eAAe,qBACb,SACA,aACiB;AAZnB,MAAA;AAaE,QAAM,EAAC,OAAU,IAAA,SAEX,EAAC,WAAW,OAAO,OAAU,IAAA,MAAM,iBAAiB,SAAS,aAAaN,mBAAiB;AAE7F,MAAA;AAGI,UAAA,WAAW,MAAM,OAAO,QAAQ;AAAA,MACpC,SAAS,EAAC,eAAe,UAAU,KAAK,GAAE;AAAA,MAC1C,KAAK,aAAa,SAAS,aAAa,WAAW;AAAA,MACnD,OAAO,EAAC,OAAO,kBAAkB,WAAU;AAAA,IAAA,CAC5C;AAED,UAAI,KAAU,YAAA,OAAA,SAAA,SAAA,YAAV,OAAmB,SAAA,GAAA,UAAS,GAAG;AACjC,YAAM,kBAAkB,SAAS,QAAQ,IAAI,CAAC,YAA0B;AAAA,QACtE,OAAO,OAAO;AAAA,MACd,EAAA;AACe,aAAA,MAAM,OAAO,OAAO;AAAA,QACnC,SAAS,sCAAsC,iBAAiB;AAAA,QAChE,MAAM;AAAA,QACN,SAAS;AAAA,MAAA,CACV;AAAA,IAGH;AAAA,WACO,KAAK;AACZ,UAAM,IAAI,MAAM,uCAAuC,WAAW,KAAK,IAAI,OAAO,EAAE;AAAA,EACtF;AAEM,QAAA,IAAI,MAAM,kBAAkB;AACpC;ACvCA,SAAS,cAAc,QAAsB;AACpCO,0BAAA,QAAQ,CAAC,QAAQ;AAClB,WACFN,QAAM,sCAAsC,IAAI,OAAO,EAAE;AAAA,EAAA,CAE5D;AACH;ACRA,MAAM,cAAc,GACd,qBAAqB,KAErB,qBAAqB,CAAC,eAAuB,KAAK,IAAI,GAAG,UAAU,IAAI;AAE7E,eAAe,UACb,WACA,aAAqB,aACT;AACH,WAAA,aAAa,GAAG,aAAa,YAAY;AAC5C,QAAA;AACF,aAAO,MAAM,UAAU;AAAA,aAChB,KAAK;AAEZ,UAAI,IAAI,YAAY,IAAI,SAAS,cAAc,IAAI,SAAS,aAAa;AACjE,cAAA;AAGF,YAAA,aAAa,mBAAmB,UAAU;AAChDA,cAAM,qCAAqC,UAAU,UAAU,IAAI,OAAO,GAC1E,MAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,UAAU,CAAC;AAAA,IAChE;AAGI,QAAA,IAAI,MAAM,oCAAoC;AACtD;AChBA,MAAMO,uBAAqB,KAAK,KAC1BC,iBAAe,IAAI,KAAK,KAExBC,YAAUC,MAAA,MAAM,CAACC,WAAAA,UAAa,GAAAC,WAAA,QAAA,CAAS,CAAC;AAE9C,eAAe,cACbC,MACA,UACA,UACA,QACe;AAIT,QAAA,qBAAqBC,cAAAA,QAAK,SAAS,QAAQ,GAE3C,gBAAgB,iBAAiB,oBAAoB,UAAU,MAAM;AAC3E,QAAM,UAAU,YAAY;AACpB,UAAA,WAAW,MAAML,UAAQ;AAAA,MAC7B,KAAAI;AAAA,MACA,cAAc;AAAA,MACd,SAAS,EAAC,SAASN,sBAAoB,QAAQC,eAAY;AAAA,MAC3D,QAAQ;AAAA,IAAA,CACT;AAEKR,YAAA,yCAAyC,oBAAoB,YAAA,OAAA,SAAA,SAAU,UAAU,GAEvF,MAAMe,SAAA,SAAS,SAAS,MAAMZ,GAAkB,kBAAA,aAAa,CAAC;AAAA,EAAA,CAC/D;AACH;AAEA,SAAS,iBAAiB,UAAkB,UAAkB,QAAwB;AAGpF,MAAI,gBAAgB;AACpB,SAAI,aAAa,UACf,gBAAgBW,cAAAA,QAAK,KAAK,QAAQ,UAAU,QAAQ,IAC3C,aAAa,WACtB,gBAAgBA,cAAAA,QAAK,KAAK,QAAQ,SAAS,QAAQ,IAG9C;AACT;AC9CA,MAAM,qBAAqB,KAAK,KAC1B,eAAe,IAAI,KAAK,KAExB,UAAUJ,MAAA,MAAM,CAACC,WAAAA,UAAa,GAAAC,WAAA,QAAA,CAAS,CAAC;AAG9C,eAAe,iBAAiBC,MAA2B;AACzD,QAAM,WAAW,MAAM;AAAA,IAA8B,MACnD,QAAQ;AAAA,MACN,KAAAA;AAAA,MACA,cAAc;AAAA,MACd,SAAS,EAAC,SAAS,oBAAoB,QAAQ,aAAY;AAAA,IAAA,CAC5D;AAAA,EAAA;AAGH,SAAAb,QAAM,iDAAiDa,MAAK,YAAU,OAAA,SAAA,SAAA,UAAU,GAEzE,SAAS;AAClB;;ACRA,MAAM,iCAAiCG,YAAAA,SAAS;AAAA,EAS9C,YACE,QACA,WACA,aACA,UACA,OACA;AACM,UAAA,EAAC,YAAY,GAAK,CAAA,GAf1B,cAAA,MAAQ,UAAS,EAAA,GACA,cAAA,MAAA,QAAA,GACA,cAAA,MAAA,WAAA,GACA,cAAA,MAAA,aAAA,GACA,cAAA,MAAA,UAAA,GACA,cAAA,MAAA,OAAA,GACjB,cAAA,MAAO,cAAa,CAAA,GAUlB,KAAK,SAAS,QACd,KAAK,YAAY,WACjB,KAAK,cAAc,aACnB,KAAK,WAAW,UAChB,KAAK,QAAQ;AAAA,EACf;AAAA,EAEA,MAAM,QAAuB;AACvB,QAAA;AACI,YAAA,OAAO,MAAM,KAAK;AAGpB,WAAK,eAAe,MACtB,KAAK,aAAa,KAAK,aAGzB,KAAK,MAAM,QAAQ,CAAC,SAAe,KAAK,KAAK,IAAI,CAAC,GAE9C,OAAO,KAAK,cAAe,YAAY,KAAK,eAAe,KAC7D,KAAK,SAAS,KAAK,aAGnB,KAAK,KAAK,IAAI;AAAA,aAET,KAAK;AACZ,WAAK,QAAQ,GAAY;AAAA,IAC3B;AAAA,EACF;AAAA;AAAA,EAGA,MAAM,sBAAkD;AAChD,UAAA,QAAqB,KAAK,WAAW,KAAK,CAAK,IAAA,EAAC,YAAY,KAAK;AAEnE,QAAA;AACK,aAAA,MAAM,KAAK,OAAO,QAAQ;AAAA,QAC/B,SAAS,EAAC,eAAe,UAAU,KAAK,KAAK,GAAE;AAAA,QAC/C,KAAK,aAAa,KAAK,SAAS,aAAa,KAAK,WAAW,YAAY,KAAK,QAAQ;AAAA,QACtF;AAAA,MAAA,CACD;AAAA,aACM,OAAO;AAEd,UAAI,MAAM,MAAM,aAAa,MAAM,SAAS,KAAK,UAAU,MAAM;AAG7D,YAAA,QAAQ,WACV,MAAM,OAAO,KAAK,IAEd,IAAI,MAAM,sCAAsC,GAAG,EAAE;AAAA,IAC7D;AAAA,EACF;AACF;ACnEA,MAAM,cAAc,CAAC,QAAsB,cAAuC;AAChF,MAAI,UAAU,OAAO,QAAQ,SAAS,EAAE,MAAM,GAC1C,eAA8B,EAAC,MAAM,UACrC,GAAA,QAAQ,KAAK,IAAI;AAEf,QAAA,QAAQ,CAACX,cAA4B;AACzC,UAAM,UAAUY,kBAAAA,QAAS,KAAK,QAAQ,KAAK;AACvC,IAAAZ,UAAS,WAAWA,UAAS,UAAU,KAAKA,UAAS,SAASA,UAAS,QAAQ,IACjF,QAAQ,OAAO,GAAGA,UAAS,IAAI,KAAKA,UAAS,OAAO,IAAIA,UAAS,KAAK,MAAM,OAAO,MAEnF,QAAQ,OAAO,GAAGA,UAAS,IAAI,KAAK,OAAO;AAAA,EAAA;AAIxC,SAAA;AAAA,IACL,KAAK,CAACA,cAA4B;AAC5B,MAAAA,UAAS,SAAS,aAAa,QACjC,MAAM,YAAY,GAClB,QAAQ,QAAQ,GAChB,UAAU,OAAO,QAAQA,UAAS,IAAI,EAAE,MAAA,GACxC,QAAQ,KAAK,SACJA,UAAS,SAAS,aAAa,QAAQA,UAAS,UACzD,MAAMA,SAAQ,GAEhB,eAAeA;AAAA,IACjB;AAAA,IACA,QAAQ,CAACA,cAA4B;AAC7B,YAAAA,SAAQ,GACd,eAAeA;AAAA,IACjB;AAAA,IACA,SAAS,MAAM;AACb,cAAQ,QAAQ,GAChB,QAAQ,KAAK,IAAI;AAAA,IACnB;AAAA,IACA,MAAM,MAAM;AACV,cAAQ,KAAK,GACb,QAAQ,KAAK,IAAI;AAAA,IACnB;AAAA,EAAA;AAEJ;ACxDA,SAAS,cAAca,OAAsB;AAC3C,QAAM,IAAIA,SAAQ,IAAI,IAAI,KAAK,MAAM,KAAK,IAAIA,KAAI,IAAI,KAAK,IAAI,IAAI,CAAC;AACpE,SAAO,IAAIA,QAAO,KAAK,IAAI,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,IAAI,CAAC,KAAK,MAAM,MAAM,MAAM,IAAI,EAAE,CAAC,CAAC;AACrF;ACHA,SAAS,cAAc,UAA2B;AAEzC,SAAA,CAAC,SAAS,KAAK,QAAQ;AAChC;AC8BA,MAAM,QAAQC,eAAAA,QAAY,eAAe,GAEnC,+BAA+B,IAC/B,2BAA2B,IAa3BjB,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAajB,SAASkB,gBAAc,MAAyB;AAC9C,SAAOC,eAAAA,QAAMC,QAAAA,QAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EACrD,QAAQ,aAAa,EAAC,MAAM,UAAS,EACrC,QAAQ,OAAO,EAAC,MAAM,SAAS,CAAA,EAC/B,QAAQ,eAAe,EAAC,MAAM,UAAU,SAAS,6BAA6B,CAAA,EAC9E,QAAQ,aAAa,EAAC,MAAM,WAAW,SAAS,GAAA,CAAM,EAAE;AAC7D;AAEA,MAAM,wBAA8C;AAAA,EAClD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbpB;AAAAA;AAAAA,EAEA,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,QAAQ,UAAS,SAClB,CAAC,QAAQ,IAAI,IAAI,MAAM,qBAAqB,SAAS,IAAI,GACzD,EAAC,WAAW,aAAa,UAAU,QAAQ,YAAe,IAAA;AAG5D,QAAA,WAAW,MAAM,gBAAgB,IAAI;AACvC,aAAO,MAAM,sBAAsB;AACnC;AAAA,IACF;AACA,UAAM,cAAcY,cAAA,QAAK,KAAK,QAAQ,WAAW;AAEjD,WAAO,MAAM,gXAA+D,GAC5E,OAAO,MAAM,yEAA+D,GAC5E,OAAO,MAAM,yEAA+D,GAC5E,OAAO,MAAM,UAAK,MAAM,KAAK,WAAW,CAAC,KAAK,MAAM,KAAK,SAAS,EAAE,OAAO,EAAE,CAAC,SAAI,GAClF,OAAO,MAAM,UAAK,MAAM,KAAK,SAAS,CAAC,KAAK,MAAM,KAAK,WAAW,EAAE,OAAO,EAAE,CAAC,SAAI,GAClF,OAAO,MAAM,UAAK,MAAM,KAAK,UAAU,CAAC,KAAK,MAAM,KAAK,QAAQ,EAAE,OAAO,EAAE,CAAC,SAAI,GAChF,OAAO,MAAM,yEAA+D,GAC5E,OAAO,MAAM,gXAA+D,GAC5E,OAAO,MAAM,EAAE,GACf,OAAO,MAAM,0BAA0B,MAAM,KAAK,WAAW,CAAC,GAAG;AAEjE,UAAM,QAAQ,KAAK,IAAA,GACb,kBAAkB,YAAY,QAAQ,kCAAkC,GAKxE,YAAY,MAAMS,KAAQ,QAAAT,sBAAK,KAAKU,GAAAA,OAAO,GAAG,gBAAgB,CAAC;AAGrE,eAAW,OAAO,CAAC,QAAQV,cAAAA,QAAK,KAAK,WAAW,QAAQ,GAAGA,cAAAA,QAAK,KAAK,WAAW,OAAO,CAAC;AACtFW,SAAAA,UAAU,KAAK,EAAC,WAAW,GAAK,CAAA;AAGlC,UAAM,qCAAqC,SAAS;AACpD,UAAM,sBAAsBX,cAAA,QAAK,KAAK,WAAW,aAAa,GAGxD,eAAeX,GAAAA,kBAAkB,mBAAmB,GACpD,gBAAgB,IAAIuB,WAAM,MAAA;AAE5B,QAAA;AACF,YAAM,mBAAmB,IAAI;AAAA,QAC3B;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MAAA,GAGD,QAAgB,CAAA;AACtB,UAAI,IAAI;AACR,uBAAiB,QAAQ;AACvB,cAAM,KAAK,IAAI,GACf,KACA,gBAAgB,IAAI;AAAA,UAClB,MAAM;AAAA,UACN,QAAQ;AAAA,UACR,SAAS;AAAA,UACT,OAAO,iBAAiB;AAAA,QAAA,CACzB;AAGH,UAAI,uBAAuB;AAE3B,YAAM,EAAC,SAAS,KAAQ,IAAA,MAAM,OAAO,OAAO;AACtC,YAAA;AAAA,QACJ;AAAA,QACA,OAAO,SAAe;AACpB,cAAI,KAAK,SAAS,UAAU,KAAK,SAAS;AACxC,kBAAM,cAAc,KAAK,KAAK,KAAK,MAAM,KAAK,MAAM,SAAS;AAAA,eACxD;AACL,kBAAM,MAAM,MAAM,iBAAiB,KAAK,GAAG;AACrC,kBAAA,cAAc,aAAa,MAAM;AACxB,2BAAA,MAAM,GAAG,GAAG;AAAA,CAAI;AAAA,YAAA,CAC9B;AAAA,UACH;AAEwB,kCAAA,GACxB,gBAAgB,IAAI;AAAA,YAClB,MAAM;AAAA,YACN,QAAQ;AAAA,YACR,SAAS;AAAA,YACT,OAAO,iBAAiB;AAAA,UAAA,CACzB;AAAA,QACH;AAAA,QACA,EAAC,aAAa,KAAK,YAAW;AAAA,MAAA;AAAA,aAEzB,OAAO;AACd,sBAAgB,KAAK;AACrB,YAAM,EAAC,QAAA,IAAW,YAAY,KAAK;AACnC,YAAM,IAAI,MAAM,sCAAsC,OAAO,EAAE;AAAA,IACjE;AAEA,iBAAa,IAAI,GACjB,MAAMC,SAAAA,SAAS,YAAY,GAE3B,gBAAgB,IAAI,EAAC,MAAM,qCAAqC,QAAQ,GAAK,CAAA;AACzE,QAAA;AACF,YAAM,WAAW,WAAW,aAAa,CAAC,mBAA2B;AACnE,wBAAgB,OAAO;AAAA,UACrB,MAAM,mCAAmC,cAAc,cAAc,CAAC;AAAA,QAAA,CACvE;AAAA,MAAA,CACF;AAAA,aACM,KAAK;AACZ,YAAA,gBAAgB,KACV,GAAA,IAAI,MAAM,4BAA4B,IAAI,OAAO,EAAE;AAAA,IAC3D;AAEA,oBAAgB,IAAI;AAAA,MAClB,MAAM,kCAAkC,MAAM,KAAK,GAAG,SAAS,EAAE,CAAC;AAAA,IACnE,CAAA,GACD,cAAc,SAAS,GAEvB,gBAAgB,IAAI;AAAA,MAClB,MAAM,6BAA6BV,0BAAS,KAAK,QAAQ,KAAK,CAAC;AAAA,IAAA,CAChE,GACD,gBAAgB;EAClB;AACF;AAGA,eAAe,qBACb,SACA,MACgD;AAC1C,QAAA,QAAQ,MAAMG,gBAAc,IAAI,GAChC,CAAC,OAAO,IAAI,KAAK,oBACjB,EAAC,QAAQ,YAAW,SACpB,EAAC,WAAW,aAAa,WAAU,MAAM;AAAA,IAC7C;AAAA,IACA;AAAA,IACArB;AAAAA,EAGI,GAAA,EAAC,MAAK,IAAI,OAAO,OAAO;AAC9B,MAAI,CAAC6B,kBAAAA,QAAS,KAAK,KAAK,MAAM,SAAS;AAC/B,UAAA,IAAI,MAAM,kBAAkB;AAGpC,MAAI,CAACA,kBAAAA,QAAS,WAAW,KAAK,YAAY,SAAS;AACjD,UAAM,IAAI,MAAM,WAAW,WAAW,+BAA+B;AAGjE,QAAA,WAAW,OAAO,MAAM,WAAW,KAAM,MAAM,qBAAqB,SAAS,WAAW,CAAE;AAChG,MAAI,SAAS,SAAS;AACpB,UAAM,IAAI,MAAM,aAAa,MAAM,WAAW,CAAC,2BAA2B;AAG5E,MAAI,iBAAiB,UACf,MAAM,cAAc,KAAK,MAAM,cAAc;AAC/C,UAAM,IAAI,MAAM,iCAAiC,wBAAwB,QAAQ;AAIrF,QAAM,qBAAqB,GAAG,WAAW,WAAW,QAAQ;AAC5D,MAAI,MAAM,OAAO,YACX,MAAM,QAAQ,SAETC,KAAW,WAAA,MAAM,GAAG,IAGf,MAAM,OAAO,OAAO;AAAA,IAChC,MAAM;AAAA,IACN,SAAS;AAAA,IACT,SAASf,cAAA,QAAK,KAAK,SAAS,kBAAkB;AAAA,IAC9C,QAAQe,KAAA;AAAA,EACT,CAAA;AAKH,SAAI,cAAc,GAAG,MACnB,MAAMf,cAAAA,QAAK,KAAK,KAAK,kBAAkB,IAIrC,CAAC,MAAM,aAAagB,GAAA,WAAW,GAAG,MACZ,MAAM,OAAO,OAAO;AAAA,IAC1C,MAAM;AAAA,IACN,SAAS,SAAS,GAAG;AAAA,IACrB,SAAS;AAAA,EAAA,CACV,MAKC,MAAM,MAIH;AAAA,IACL;AAAA,IACA;AAAA,MACE;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,QAAQhB,cAAAA,QAAK,QAAQ,GAAG;AAAA,MACxB,aAAaA,cAAAA,QAAK,SAAS,GAAG;AAAA,MAC9B,WAAW,MAAM;AAAA,MACjB,aAAa,MAAM,eAAe;AAAA,IACpC;AAAA,EAAA;AAEJ;ACrRA,MAAMZ,aAAW;AAAA;AAAA;AAAA,GAKX,6BAAmD;AAAA,EACvD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbA;AAAAA,EACA,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,QAAQ,MAAA,IAAS,SAClB,CAAC,OAAO,IAAI,KAAK,oBACjB,EAAC,WAAW,aAAa,OAAO,OAAA,IAAU,MAAM;AAAA,MACpD;AAAA,MACA;AAAA,MACAH;AAAAA,IAAA;AAGE,QAAA;AACF,YAAM,OAAO,QAAQ;AAAA,QACnB,QAAQ;AAAA,QACR,SAAS,EAAC,eAAe,UAAU,KAAK,GAAE;AAAA,QAC1C,KAAK,aAAa,SAAS,aAAa,WAAW;AAAA,QACnD,MAAM;AAAA,UACJ,SAAS;AAAA,QACX;AAAA,MAAA,CACD,GAED,OAAO;AAAA,QACL,GAAG,MAAM;AAAA,UACP,+BAA+B,WAAW;AAAA;AAAA;AAAA,QAAA,CAC3C;AAAA,SAGH,OAAO;AAAA,QACL,GAAG,MAAM,KAAK;AAAA,CAAsE,CAAC;AAAA,MAAA;AAAA,aAEhF,OAAO;AACd,YAAM,EAAC,QAAA,IAAW,YAAY,KAAK;AACnC,aAAO,MAAM,GAAG,MAAM,IAAI,mCAAmC,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAC7E;AAAA,EACF;AACF,GCxCM,4BAA4B,IAuB5BG,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAajB,SAASkB,gBAAc,MAAyB;AAC9C,SAAOC,eAAAA,QAAMC,QAAAA,QAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EACrD,QAAQ,SAAS,EAAC,MAAM,UAAS,EACjC,QAAQ,UAAU,EAAC,MAAM,SAAS,CAAA,EAClC,QAAQ,SAAS,EAAC,MAAM,UAAU,SAAS,2BAA2B,OAAO,IAAA,CAAI,EAAE;AACxF;AAEA,MAAM,2BAAyE;AAAA,EAC7E,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbpB;AAAAA,EACA,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,QAAQ,UAAS,SAClB,QAAQ,MAAMkB,gBAAc,IAAI,GAChC,CAAC,OAAO,IAAI,KAAK,oBAEjB,EAAC,WAAW,aAAa,OAAO,OAAM,IAAI,MAAM;AAAA,MACpD;AAAA,MACA;AAAA,MACArB;AAAAA,OAGI,QAAsC,EAAC,OAAO,0BAA0B,SAAU,EAAA;AACxF,QAAI,MAAM,OAAO;AAGf,UAAI,MAAM,QAAQ,KAAK,MAAM,QAAQ,OAAO;AAC1C,cAAM,IAAI;AAAA,UACR,qDAAqD,OAAO,gBAAgB;AAAA,QAAA;AAG1E,YAAA,QAAQ,MAAM,MAAM,SAAS;AAAA,IACrC;AAEI,QAAA,MAAM,UAAU,MAAM;AACpB,UAAA;AACI,cAAA,eAAe,iBAAiB,MAAM,MAAM,GAC5C,cAAc,iBAAiB,MAAM,KAAK;AAEhD,YAAI,eAAe,gBAAgBgC,gBAAQ,aAAa,YAAY;AAC5D,gBAAA,IAAI,MAAM,sCAAsC;AAGxD,cAAM,SAAS,MAAM,QACrB,MAAM,QAAQ,MAAM;AAAA,eACb,KAAK;AACZ,cAAM,IAAI,MAAM,uBAAuB,GAAG,EAAE;AAAA,MAC9C;AAGE,QAAA;AACA,QAAA;AACS,iBAAA,MAAM,OAAO,QAA4B;AAAA,QAClD,SAAS,EAAC,eAAe,UAAU,KAAK,GAAE;AAAA,QAC1C,KAAK,aAAa,SAAS,aAAa,WAAW;AAAA,QACnD,OAAO,EAAC,GAAG,MAAK;AAAA,MAAA,CACjB;AAAA,aACM,OAAO;AACd,YAAM,EAAC,QAAA,IAAW,YAAY,KAAK;AACnC,aAAO,MAAM,GAAG,MAAM,IAAI,+BAA+B,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IACzE;AAEI,QAAA,YAAY,SAAS,SAAS;AAC5B,UAAA,SAAS,QAAQ,WAAW,GAAG;AACjC,eAAO,MAAM,mBAAmB;AAChC;AAAA,MACF;AAEM,YAAA,QAAQ,IAAIC,0BAAM;AAAA,QACtB,SAAS;AAAA,UACP,EAAC,MAAM,YAAY,OAAO,YAAY,WAAW,OAAM;AAAA,UACvD,EAAC,MAAM,aAAa,OAAO,cAAc,WAAW,OAAM;AAAA,UAC1D,EAAC,MAAM,YAAY,OAAO,aAAa,WAAW,OAAM;AAAA,QAC1D;AAAA,MAAA,CACD;AAEQ,eAAA,QAAQ,QAAQ,CAAC,WAAmC;AACrD,cAAA,EAAC,IAAI,UAAa,IAAA;AACxB,cAAM,OAAO;AAAA,UACX,UAAU;AAAA,UACV,WAAWC,QAAY,YAAA,KAAK,MAAM,SAAS,GAAG,qBAAqB;AAAA,UACnE,UAAU;AAAA,QAAA,CACX;AAAA,MAAA,CACF,GAED,MAAM;IACR;AAAA,EACF;AACF;AAEA,SAAS,iBAAiB,MAA4C;AACpE,MAAI,CAAC,KAAM;AACX,QAAM,aAAaC,QAAAA,MAAM,MAAM,cAAc,oBAAI,MAAM;AACvD,MAAIC,QAAAA,QAAQ,UAAU;AACb,WAAA;AAGT,QAAM,IAAI,MAAM,WAAW,IAAI,8BAA8B;AAC/D;AC/IA,MAAMjC,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAWX,eAAqC;AAAA,EACzC,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OACN,MACA,SACA,eAEoB,MAAM,kBAEP,MAAM,SAAS,SAAS;AAAA,EAAA,UAE7CA;AACF;AAEA,eAAe,iBAAiB;AAUlB,UAAA,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,kBAAiC;AAAA,EAE/C,CAAA,GAAA;AACb;ACzCA,MAAM,eAAqC;AAAA,EACzC,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,UAAU;AAAA,EACV,cAAc;AAAA,EACd,QAAQ,CAAC,OAAO,YAAY;AACpB,UAAA,EAAC,OAAU,IAAA;AACjB,WAAA,OAAO,MAAM,2DAA2D,GACjE,QAAQ,QAAQ;AAAA,EACzB;AACF,GCXM,qBAA2C;AAAA,EAC/C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,UAAU;AAAA,EACV,cAAc;AAAA,EACd,QAAQ,OAAO,MAAM,aACnB,QAAQ,OAAO,MAAM,iDAAiD,GAC/D,QAAQ;AAEnB,GCNM,sBAAsB,6BACtB,kBAAkB;AAMF,eAAA,cACpB,aACA,OACA,SACkB;AAClB,QAAM,EAAC,WAAW,QAAQ,OAAU,IAAA,SAC9B,SAAS,OAAO,cAClB,wBAAwB,WAAW,IACnCkC,kBAAgB,MAAM,IAEpB,cAAc,OAAO,SAAS,GAAG;AACvC,MAAI,eAAe,CAAE,MAAM,8BAA8B,QAAQ,OAAO;AAC/D,WAAA;AAEH,QAAA,mBACJ,OAAO,MAAM,cAAgB,MACzB,MAAM,qBAAqB,aAAa,OAAO,IAC/C,CAAA,CAAQ,MAAM;AAEhB,SAAA,gBAAgB,UAClB,OAAO,MAAM,wBAAwB,MAAM,EAAE,GAQ/C,MALe,UAAU;AAAA,IACvB,aAAa;AAAA,IACb,gBAAgB;AAAA,EACjB,CAAA,EAEY,QAAQ;AAAA,IACnB,QAAQ;AAAA,IACR,KAAK;AAAA,IACL,MAAM,EAAC,QAAQ,iBAAgB;AAAA,IAC/B,cAAc;AAAA,EAAA,CACf,GAEM;AACT;AAEA,SAAS,qBAAqB,aAAsB,SAA6C;AAC/F,QAAM,EAAC,QAAQ,QAAQ,MAAA,IAAS;AAEhC,SAAA,OAAO,MAAM,EAAE,GACX,cACF,OAAO,MAAMC;QACT,MAAM,OAAO,GAAGC,oBAAW,QAAA,OAAO,WAAW,CAAC;AAAA,WAC3C,MAAM,IAAI,MAAM,UAAU,QAAQ,CAAC,CAAC;AAAA;AAAA,iCAEd,MAAM,UAAU,gBAAgB,CAAC;AAAA;AAAA,KAE7D,IAED,OAAO,MAAMD;QACT,MAAM,OAAO,GAAGC,oBAAW,QAAA,OAAO,WAAW,CAAC;AAAA;AAAA;AAAA,iBAGrC,MAAM,UAAU,gBAAgB,CAAC;AAAA;AAAA;AAAA,KAG7C,GAGH,OAAO,MAAM,EAAE,GAER,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAASD,iBAAAA;AAAAA;AAAAA;AAAAA,IAGT,SAAS;AAAA,EAAA,CACV;AACH;AAEA,SAAS,8BACP,QACA,SACkB;AAClB,QAAM,EAAC,QAAQ,QAAQ,MAAA,IAAS;AAEhC,SAAA,OAAO,MAAM,EAAE,GACf,OAAO,MAAM,MAAM,OAAO,GAAGC,oBAAAA,QAAW,OAAO,wCAAwC,CAAC,GAEpF,WAAW,OACb,OAAO,MAAM,kCAAkC,GAC/C,OAAO,MAAM,2CAA2C,GACxD,OAAO,MAAM,iCAAiC,GAC9C,OAAO,MAAM,2BAA2B,MAExC,OAAO,MAAM,KAAK,OAAO,QAAQ,OAAO,OAAO,EAAE,QAAQ,OAAO,KAAK,CAAC,EAAE,GACxE,OAAO,MAAM,KAAK,OAAO,QAAQ,OAAO,OAAO,EAAE,QAAQ,OAAO,SAAS,CAAC,EAAE,IAG9E,OAAO,MAAM,EAAE,GAER,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAASD,iBAAAA;AAAAA,+BACkB,MAAM,IAAI,OAAO,CAAC;AAAA,gBACjC,MAAM,UAAU,iBAAiB,CAAC;AAAA,IAC9C,SAAS;AAAA,EAAA,CACV;AACH;AAEA,SAASD,kBAAgB,QAAsC;AAC7D,SAAO,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAAS;AAAA,IACT,QAAQ;AAAA,IACR,UAAU,CAAC,WAAW,eAAe,QAAQ,MAAM;AAAA,EAAA,CACpD;AACH;AAEA,SAAS,aAAa,QAA+B;AACnD,MAAI,WAAW,OAAO,WAAW,eAAe,WAAW;AAClD,WAAA;AAGL,MAAA;AACF,UAAM,UAAU,OACb,QAAQ,aAAa,KAAK,mBAAmB,EAAE,EAC/C,QAAQ,OAAO,eAAe,GAE3B,SAASvB,aAAAA,QAAI,MAAM,OAAO;AAC5B,QAAA,OAAO,OAAO,QAAQ;AAC1B,WAAI,YAAY,KAAK,OAAO,YAAY,EAAE,MACxC,OAAO,KAAK,QAAQ,cAAc,EAAE,IAGtC,OAAO,KAAK,QAAQ,iBAAiB,IAAI,EAAE,QAAQ,IAAI,OAAO,qBAAqB,GAAG,GAAG,GAAG,GAErF,GAAG,OAAO,QAAQ,KAAK,IAAI;AAAA,EAAA,QACtB;AACL,WAAA;AAAA,EACT;AACF;AAEA,SAAS,eAAe,QAAuB,aAAoC;AACjF,MAAI,WAAW,OAAO,WAAW,eAAe,WAAW;AAClD,WAAA;AAGL,MAAA;AACE,WAAAA,aAAAA,QAAA,MAAM,UAAW,CAAmB,GACjC;AAAA,EAAA,QACK;AAAA,EAEd;AAEA,SAAI,aAAa,KAAK,WAAW,IACxB,+DAGF,mBAAmB,WAAW;AACvC;AAEA,SAAS,wBAAwB,aAA6B;AAC5D,QAAM,SAAS,aAAa,WAAW,GACjC,SAAS,eAAe,QAAQ,WAAW;AACjD,MAAI,WAAW;AACP,UAAA,IAAI,MAAM,MAAM;AAGxB,MAAI,CAAC;AACG,UAAA,IAAI,MAAM,gBAAgB;AAG3B,SAAA;AACT;AC5KA,MAAMX,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAUX,uBAA6C;AAAA,EACjD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,OAAM,IAAI,SACX,CAAC,MAAM,IAAI,KAAK;AAEtB,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,yDAAyD;AAG3E,UAAM,QAAQ,KAAK;AAGJqC,gBAAAA,QAAG,WAAWzB,sBAAK,KAAK,QAAQ,IAAO,GAAA,MAAM,CAAC,KAE3D,OAAO,KAAK,WAAW,MAAM,mDAAmD,GAGlE,MAAM,cAAc,QAAQ,OAAO,OAAO,KAExD,OAAO,MAAM,gCAAgC;AAAA,EAEjD;AACF,GC1CM,YAAuC;AAAA,EAC3C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf,GCHMZ,aAAW;AAAA;AAAA;AAAA;AAAA,GAMX,0BAAgD;AAAA,EACpD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,QAAQ,UAAS,IAAI,SACtB,CAAC,MAAM,IAAI,KAAK,oBAChB,SAAS,UAAU,EAAC,aAAa,IAAM,gBAAgB,GAAK,CAAA,GAC5D,WAAW,MAAM,gBAAgB,QAAQ,OAAO;AAClD,QAAA;AACF,YAAM,OAAO,QAAQ,EAAC,QAAQ,UAAU,KAAK,SAAS,QAAQ,GAAE,CAAC,GACjE,OAAO,MAAM,gBAAgB;AAAA,aACtB,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAA4B,IAAI,OAAO,EAAE;AAAA,IAC3D;AAAA,EACF;AACF;AAIA,eAAe,gBAAgB,WAA+B,SAA4B;AAClF,QAAA,kBAAkB,aAAa,UAAU,YAAY,GACrD,EAAC,QAAQ,UAAa,IAAA,SAGtB,UAAU,MAFD,UAAU,EAAC,aAAa,IAAM,gBAAgB,GAAI,CAAC,EAErC,QAAsB,EAAC,KAAK,QAAA,CAAQ;AACjE,MAAI,iBAAiB;AACb,UAAA,WAAW,QAAQ,OAAO,CAAC,WAAW,OAAO,OAAO,YAAY,MAAM,eAAe,EAAE,CAAC;AAC9F,QAAI,CAAC;AACH,YAAM,IAAI,MAAM,WAAW,SAAS,aAAa;AAGnD,WAAO,SAAS;AAAA,EAClB;AAEA,QAAM,UAAU,QAAQ,IAAI,CAAC,YAAY,EAAC,OAAO,OAAO,IAAI,MAAM,OAAO,OAAA,EAAQ;AACjF,SAAO,OAAO,OAAO;AAAA,IACnB,SAAS;AAAA,IACT,MAAM;AAAA,IACN;AAAA,EAAA,CACD;AACH;ACjDA,MAAMA,aAAW;AAAA;AAAA;AAAA,GAKX,yBAA+C;AAAA,EACnD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,OAAU,IAAA,SACX,EAAC,UAAS,IAAI,SAEd,UAAU,MADD,UAAU,EAAC,aAAa,IAAM,gBAAgB,GAAK,CAAA,EACrC,QAAsB,EAAC,KAAK,QAAA,CAAQ;AAC1D,WAAA,MAAM,QAAQ,IAAI,CAAC,WAAW,OAAO,MAAM,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,EAChE;AACF;ACpBO,SAAS,yBAAyB,aAAqC;AAC5E,MAAI,CAAC;AACI,WAAA;AAGH,QAAA,OAAO,GAAG,WAAW;AAEvB,SAAA,KAAK,YAAY,MAAM,OAClB,gDAGL,KAAK,SAAS,IACT,oDAGL,KAAK,SAAS,KACT,6CAGJ,aAAa,KAAK,IAAI,IAItB,yBAAyB,KAAK,IAAI,IAInC,QAAQ,KAAK,IAAI,IACZ,yDAGF,KAPE,0EAJA;AAYX;AC9BO,SAAS,0BACd,QACA,UAAgD,IAC/B;AACjB,SAAO,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAAS;AAAA,IACT,UAAU,CAAC,SACG,yBAAyB,IAAI,KAKlC;AAAA,IAET,GAAG;AAAA,EAAA,CACJ;AACH;AChBO,MAAM,eAAe;AAErB,SAAS,YAAY,QAAyD;AACnF,SAAO,OAAO,QAAkC,EAAC,KAAK,WAAW,CAAA;AACnE;AAEgB,SAAA,YACd,QACA,WACA,aACsC;AAC/B,SAAA,OAAO,QAAQ,OAAO,WAAW,cAAc,EAAC,YAAA,IAAe,MAAS;AACjF;AAEgB,SAAA,YACd,QACA,WACA,aACsC;AAC/B,SAAA,OAAO,QAAQ,SAAS,WAAW,cAAc,EAAC,YAAA,IAAe,MAAS;AACnF;AAEgB,SAAA,YACd,QACA,WACsC;AACb,SAClB,OAAO,QAAQ,SAAS,GAAG,SAAS,WAAW,CAAA,CAAE;AAC1D;AAEgB,SAAA,YAAY,QAAsB,WAAgD;AACzF,SAAA,OAAO,QAAQ,UAAU,SAAS;AAC3C;AAEA,SAAS,OACP,QACA,QACA,WACA,MACA;AACO,SAAA,OAAO,QAAQ,EAAC,QAAQ,KAAK,YAAY,SAAS,IAAI,KAAA,CAAK;AACpE;ACrCa,MAAA,qBAAuC,OAAO,MAAM,YAAY;AAC3E,QAAM,EAAC,WAAW,QAAQ,OAAU,IAAA,SAC9B,CAAA,EAAG,OAAO,aAAa,IAAI,KAAK,oBAChC,SAAS,aAET,YAAY,SAAS,yBAAyB,KAAK;AACrD,MAAA;AACI,UAAA,IAAI,MAAM,SAAS;AAG3B,QAAM,CAAC,UAAU,SAAS,eAAe,IAAI,MAAM,QAAQ,IAAI;AAAA,IAC7D,OAAO,SAAS,KAAK,EAAE,KAAK,CAAC,SAAS,KAAK,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;AAAA,IAC/DsC,YAAwB,MAAM,EAAE,KAAK,CAAC,SAAS,KAAK,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;AAAA,IACxE,OAAO,QAAQ,EAAC,KAAK,aAAY;AAAA,EAAA,CAClC;AAED,MAAI,YAAY,OAAO,SAAS,0BAA0B,MAAM,IAC5D,kBAAkB;AAQtB,MANI,UAAU,WAAW,YAAY,IACnC,YAAY,UAAU,MAAM,CAAC,IAE7B,kBAAkB,GAAG,YAAY,GAAG,SAAS,IAG3C,QAAQ,SAAS,SAAS;AAC5B,UAAM,IAAI,MAAM,kBAAkB,eAAe,kBAAkB;AAGrE,MAAI,eAAe;AACX,UAAA,aAAa,oBAAoB,aAAa;AAChD,QAAA;AACI,YAAA,IAAI,MAAM,UAAU;AAAA,EAE9B;AAEA,QAAM,cAAc,OAAO,iBAAiB,qBAAqB,MAAM;AACvE,MAAI,eAAe,CAAC,SAAS,SAAS,WAAW;AAC/C,UAAM,IAAI,MAAM,YAAY,WAAW,mBAAmB;AAIxD,MAAA,CADmB,gBAAgB,SAAS,2BAA2B;AAEnE,UAAA,IAAI,MAAM,4CAA4C;AAG1D,MAAA;AACF,UAAMC,YAAwB,QAAQ,WAAW,WAAW,GAC5D,OAAO;AAAA,MACL,iBAAiB,eAAe,YAC9B,eAAe,iBAAiB,WAAW,EAC7C;AAAA,IAAA;AAAA,WAEK,KAAK;AACZ,UAAM,IAAI,MAAM;AAAA,EAAmC,IAAI,OAAO,EAAE;AAAA,EAClE;AACF;ACzDA,SAASrB,gBAAc,MAAyB;AAC9C,SAAOC,eAAAA,QAAMC,QAAAA,QAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EAAE,OAAO,SAAS,EAAC,MAAM,UAAA,CAAU,EAAE;AAC/F;AAMa,MAAA,qBAAyD,OAAO,MAAM,YAAY;AACvF,QAAA,EAAC,WAAW,QAAQ,WAAU,SAC9B,CAAG,EAAA,EAAE,IAAI,KAAK,oBACd,EAAC,UAAS,MAAMF,gBAAc,IAAI,GAClC,SAAS;AACf,MAAI,CAAC;AACG,UAAA,IAAI,MAAM,qCAAqC;AAGnD,MAAA,YAAY,GAAG,EAAE;AACf,QAAA,UAAU,yBAAyB,SAAS;AAC9C,MAAA;AACI,UAAA;AAER,cAAY,UAAU,WAAW,YAAY,IAAI,UAAU,MAAM,CAAC,IAAI;AAEtE,QAAM,CAAC,cAAc,IAAI,MAAM,QAAQ,IAAI,CAACoB,YAAwB,MAAM,CAAC,CAAC,GACtE,cAAc,eAAe,KAAK,CAAC,SAAS,KAAK,SAAS,SAAS,GACnE,UACJ,eAAe,YAAY,cACvB,mCAAmC,YAAY,WAAW,OAC1D;AAEF,SAAA,QACF,OAAO,KAAK,0DAA0D,SAAS,GAAG,IAElF,MAAM,OAAO,OAAO;AAAA,IAClB,MAAM;AAAA,IACN,SAAS,GAAG,OAAO;AAAA;AAAA,IACnB,QAAQ,CAAC,UAAU,GAAG,KAAK,GAAG,KAAK;AAAA,IACnC,UAAU,CAAC,UACF,UAAU,aAAa;AAAA,EAEjC,CAAA,GAGIE,YAAwB,QAAQ,SAAS,EAAE,KAAK,MAAM;AAC3D,WAAO,MAAM,oCAAoC;AAAA,EAAA,CAClD;AACH,GC9Ca,mBAAqC,OAAO,MAAM,YAAY;AACnE,QAAA,EAAC,WAAW,QAAQ,WAAU,SAC9B,GAAG,OAAO,aAAa,IAAI,KAAK,oBAChC,QAAQ,KAAK,YACb,SAAS,aAET,YAAY,SAAS,yBAAyB,KAAK;AACrD,MAAA;AACI,UAAA,IAAI,MAAM,SAAS;AAG3B,QAAM,CAAC,UAAU,cAAc,IAAI,MAAM,QAAQ,IAAI;AAAA,IACnD,OAAO,SAAS,KAAK,EAAE,KAAK,CAAC,SAAS,KAAK,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;AAAA,IAC/DF,YAAwB,MAAM;AAAA,EAAA,CAC/B,GACK,UAAU,eAAe,IAAI,CAAC,OAAO,GAAG,IAAI;AAElD,MAAI,YAAY,OAAO,SAAS,0BAA0B,MAAM,IAC5D,kBAAkB;AAQtB,MANI,UAAU,WAAW,YAAY,IACnC,YAAY,UAAU,MAAM,CAAC,IAE7B,kBAAkB,GAAG,YAAY,GAAG,SAAS,IAG3C,CAAC,QAAQ,SAAS,SAAS;AAC7B,UAAM,IAAI,MAAM,kBAAkB,eAAe,mBAAmB;AAGhE,QAAA,cAAc,OAAO,iBAAiB,qBAAqB,MAAM,IACjE,aAAa,oBAAoB,WAAW;AAC9C,MAAA;AACI,UAAA,IAAI,MAAM,UAAU;AAGxB,MAAA,CAAC,SAAS,SAAS,WAAW;AAChC,UAAM,IAAI,MAAM,YAAY,WAAW,mBAAmB;AAG5D,QAAM,cAAc,eAAe,KAAK,CAAC,SAAS,KAAK,SAAS,SAAS;AAErE,MAAA,eAAe,YAAY,aAAa;AAC1C,QAAI,YAAY,gBAAgB;AAC9B,YAAM,IAAI,MAAM,iBAAiB,eAAe,sBAAsB,WAAW,EAAE;AAGhF,UAAM,SACT,MAAM,OAAO,OAAO;AAAA,MAClB,MAAM;AAAA,MACN,SAAS,oCAAoC,YAAY,WAAW;AAAA;AAAA;AAAA,MAEpE,QAAQ,CAAC,UAAU,GAAG,KAAK,GAAG,YAAY;AAAA,MAC1C,UAAU,CAAC,UACF,UAAU,SAAS;AAAA,IAAA,CAE7B;AAAA,EAEL;AAEI,MAAA;AACF,UAAMG,YAAwB,QAAQ,WAAW,WAAW,GAC5D,OAAO,MAAM,iBAAiB,eAAe,cAAc,WAAW,eAAe;AAAA,WAC9E,KAAK;AACZ,UAAM,IAAI,MAAM;AAAA,EAA+B,IAAI,OAAO,EAAE;AAAA,EAC9D;AACF;AC9DA,SAASvB,gBAAc,MAAyB;AAC9C,SAAOC,eAAAA,QAAMC,QAAAA,QAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EAAE,OAAO,SAAS,EAAC,MAAM,UAAA,CAAU,EAAE;AAC/F;AAEa,MAAA,qBAAoD,OAAO,MAAM,YAAY;AAClF,QAAA,EAAC,WAAW,QAAQ,OAAM,IAAI,SAC9B,CAAA,EAAG,KAAK,IAAI,KAAK,oBACjB,EAAC,MAAK,IAAI,MAAMF,gBAAc,IAAI,GAClC,SAAS,aAET,YAAY,SAAS,yBAAyB,KAAK;AACrD,MAAA;AACI,UAAA,IAAI,MAAM,SAAS;AAG3B,QAAM,iBAAiB,MAAMoB,YAAwB,MAAM;AAE3D,MAAI,YAAY,OAAO,SAAS,0BAA0B,MAAM,IAC5D,kBAAkB;AAElB,YAAU,WAAW,YAAY,IACnC,YAAY,UAAU,MAAM,CAAC,IAE7B,kBAAkB,GAAG,YAAY,GAAG,SAAS;AAI/C,QAAM,cAAc,eAAe,KAAK,CAAC,SAAS,KAAK,SAAS,SAAS;AACzE,MAAI,CAAC;AACH,UAAM,IAAI,MAAM,kBAAkB,eAAe,kBAAkB;AAGrE,MAAI,CAAC,YAAY;AACf,UAAM,IAAI,MAAM,kBAAkB,eAAe,8BAA8B;AAG7E,UACF,OAAO,KAAK,2DAA2D,eAAe,GAAG,IAEzF,MAAM,OAAO,OAAO;AAAA,IAClB,MAAM;AAAA,IACN,SAAS,mEAAmE,YAAY,WAAW;AAAA;AAAA;AAAA,IAEnG,QAAQ,CAAC,UAAU,GAAG,KAAK,GAAG,YAAY;AAAA,IAC1C,UAAU,CAAC,UACF,UAAU,SAAS;AAAA,EAAA,CAE7B;AAGC,MAAA;AACF,UAAM,SAAS,MAAMI,YAAwB,QAAQ,SAAS;AACvD,WAAA;AAAA,MACL,iBAAiB,eAAe,kBAAkB,OAAO,WAAW;AAAA,IAAA;AAAA,WAE/D,KAAK;AACZ,UAAM,IAAI,MAAM;AAAA,EAAiC,IAAI,OAAO,EAAE;AAAA,EAChE;AACF,GC/DM1C,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAoCX,eAAqC;AAAA,EACzC,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,CAAC,IAAI,IAAI,KAAK;AACpB,YAAQ,MAAM;AAAA,MACZ,KAAK;AACG,cAAA,mBAAmB,MAAM,OAAO;AACtC;AAAA,MACF,KAAK;AACG,cAAA,mBAAmB,MAAM,OAAO;AACtC;AAAA,MACF,KAAK;AACG,cAAA,mBAAmB,MAAM,OAAO;AACtC;AAAA,MACF,KAAK;AACG,cAAA,iBAAiB,MAAM,OAAO;AACpC;AAAA,MACF;AACE,cAAM,IAAI,MAAMmC;;;SAGf;AAAA,IACL;AAAA,EACF;AACF;ACrDsB,eAAA,oBACpB,OACA,SACe;AACf,QAAM,EAAC,WAAW,QAAQ,MAAA,IAAS,SAC7B,SAAS,UAAU,GACnB,YAAY,OAAO,OAAA,EAAS,WAC5B,QAA2C,CAAA;AAC7C,MAAA;AAEA,QAAM,UAAU,MAAM,UAAU,MAClC,MAAM,SAAS,GAAG,MAAM,MAAM,KAE5B,MAAM,SAAS,MAAM,QAAQ,MAC/B,MAAM,QAAQ,GAAG,MAAM,KAAK;AAG1B,MAAA;AACS,eAAA,MAAM,OAAO,QAAiC;AAAA,MACvD,QAAQ;AAAA,MACR,KAAK,aAAa,SAAS;AAAA,MAC3B;AAAA,IAAA,CACD;AAAA,WACM,OAAO;AACV,UAAM,aACR,OAAO,MAAM,GAAG,MAAM,IAAI;AAAA,EAA8B,MAAM,SAAS,KAAK,OAAO,EAAE,CAAC;AAAA,CAAI,IAE1F,OAAO,MAAM,GAAG,MAAM,IAAI;AAAA,EAA8B,MAAM,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,EAEhF;AAEI,MAAA,YAAY,SAAS,SAAS,GAAG;AAC7B,UAAA,QAAQ,IAAIL,0BAAM;AAAA,MACtB,OAAO;AAAA,MACP,SAAS;AAAA,QACP,EAAC,MAAM,MAAM,OAAO,UAAU,WAAW,OAAM;AAAA,QAC/C,EAAC,MAAM,iBAAiB,OAAO,kBAAkB,WAAW,OAAM;AAAA,QAClE,EAAC,MAAM,iBAAiB,OAAO,kBAAkB,WAAW,OAAM;AAAA,QAClE,EAAC,MAAM,SAAS,OAAO,SAAS,WAAW,OAAM;AAAA,QACjD,EAAC,MAAM,eAAe,OAAO,gBAAgB,WAAW,OAAM;AAAA,QAC9D,EAAC,MAAM,eAAe,OAAO,gBAAgB,WAAW,OAAM;AAAA,QAC9D,EAAC,MAAM,aAAa,OAAO,cAAc,WAAW,OAAM;AAAA,MAC5D;AAAA,IAAA,CACD;AAEQ,aAAA,QAAQ,CAAC,QAAQ;AAClB,YAAA,EAAC,IAAI,OAAO,WAAW,WAAW,eAAe,eAAe,YAAe,IAAA;AAErF,UAAI,cAAc;AACd,oBAAc,OAChB,cAAca,QAAAA,oBAAoBC,QAAAA,SAAS,SAAS,CAAC;AAGvD,UAAI,YAAY;AACZ,oBAAc,OAChB,YAAYC,uBAAeD,QAAAA,SAAS,SAAS,GAAGA,QAAS,SAAA,SAAS,CAAC;AAGjE,UAAA;AACJ,cAAQ,OAAO;AAAA,QACb,KAAK;AACK,kBAAA;AACR;AAAA,QACF,KAAK;AACK,kBAAA;AACR;AAAA,QACF,KAAK;AACK,kBAAA;AACR;AAAA,QACF;AACU,kBAAA;AAAA,MACZ;AAEM,YAAA;AAAA,QACJ;AAAA,UACE;AAAA,UACA;AAAA,UACA;AAAA,UACA,aAAa,GAAG,WAAW;AAAA,UAC3B;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,EAAC,MAAK;AAAA,MAAA;AAAA,IACR,CACD,GAED,MAAM;EACR;AACE,WAAO,MAAM,iDAAiD;AAElE;AC5GO,MAAM,eAAe,CAAC,QAAsB,KAAa,SAAS,OAAkB;AACnF,QAAA,SAAS,OAAO;AAEf,SAAA,GADM,SAAS,OAAO,SAAS,OAAO,GAC/B,IAAI,IAAI,QAAQ,OAAO,EAAE,CAAC;AAC1C,GCOM5C,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAuCjB,SAASkB,gBAAc,MAAyB;AACvC,SAAAC,eAAA,QAAMC,gBAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EACrD,OAAO,UAAU,EAAC,MAAM,UAAS,EACjC,OAAO,QAAQ,EAAC,MAAM,UAAS,CAAC,EAChC,OAAO,SAAS,EAAC,MAAM,SAAQ,CAAC,EAChC,OAAO,UAAU,EAAC,MAAM,SAAS,CAAA,EACjC,OAAO,gBAAgB,EAAC,MAAM,UAAU,CAAA,EACxC,OAAO,UAAU,EAAC,MAAM,WAAU,EAAE;AACzC;AAEA,MAAM,WAAW,CAACT,SACT,IAAImC,KAAA,WAAoC,CAAC,aAAa;AAC3D,MAAI,iBAAiB,IAAIC,qBAAY,QAAApC,IAAG,GACpC,UAAU;AAEd,WAAS,QAAQ,OAAgB;AAC3B,sBACF,eAAe,SAGjBb,QAAM,mBAAmB,KAAK,EAAE,GAC5B,CAAA,YAGJ,SAAS,KAAK,EAAC,MAAM,YAAY,CAAA,GACjC,iBAAiB,IAAIiD,qBAAAA,QAAYpC,IAAG;AAAA,EACtC;AAEA,WAAS,eAAe,OAAqB;AAC3C,cAAU,IACV,eAAe,MACf,GAAA,SAAS,MAAM,KAAK;AAAA,EACtB;AAEA,WAAS,UAAU,OAAqB;AACtC,UAAM,OAAO,KAAK,MAAM,MAAM,IAAI;AAC9B,SAAK,UAAU,YACjBb,QAAM,wBAAwB,KAAK,GACnC,SAAS,MAAM,KAAK,KACX,KAAK,UAAU,eACxBA,QAAM,2BAA2B,KAAK,GACtC,WAAW,MAEXA,QAAM,4BAA4B,KAAK,GACvC,SAAS,KAAK,IAAI;AAAA,EAEtB;AAEA,WAAS,aAAa;AACL,mBAAA,oBAAoB,SAAS,OAAO,GACnD,eAAe,oBAAoB,iBAAiB,cAAc,GAClE,eAAe,oBAAoB,OAAO,SAAS,GACnD,eAAe,oBAAoB,QAAQ,UAAU,GACrD,eAAe,MAAA,GACf,SAAS,SAAS;AAAA,EACpB;AAEA,iBAAe,iBAAiB,SAAS,OAAO,GAChD,eAAe,iBAAiB,iBAAiB,cAAc,GAC/D,eAAe,iBAAiB,OAAO,SAAS,GAChD,eAAe,iBAAiB,QAAQ,UAAU;AACpD,CAAC,GAGG,iBAAiB,CACrB,OACA,QACA,WACkB;AAClB,MAAI,kBAAkB;AAEtB,QAAM,UAAU,OAAO,QAAQ,CAAE,CAAA,EAAE,MAAM,GACnC,YAAY,aAAa,QAAQ,QAAQ,KAAK,SAAS;AAEvD,SAAAA,QAAA,gBAAgB,SAAS,EAAE,GAE1B,IAAI,QAAQ,CAAC,SAAS,WAAW;AAC7B,aAAA,SAAS,EAAE,UAAU;AAAA,MAC5B,MAAM,CAAC,UAAU;AACX,eAAO,MAAM,YAAa,aAC5B,kBAAkB,MAAM,WAG1B,QAAQ,OAAO,qBAAqB,eAAe;AAAA,MACrD;AAAA,MACA,OAAO,CAAC,QAAQ;AACN,gBAAA,QACR,OAAO,IAAI,MAAM,GAAG,IAAI,IAAI,EAAE,CAAC;AAAA,MACjC;AAAA,MACA,UAAU,MAAM;AACN,gBAAA,QAAQ,gBAAgB,GAChC,QAAQ;AAAA,MACV;AAAA,IAAA,CACD;AAAA,EAAA,CACF;AACH,GAEM,qBAA6D;AAAA,EACjE,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXE;AAAAA,EACA,aACE;AAAA,EACF,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,QAAQ,QAAQ,MAAK,IAAI,SAErC,QAA0B,MAAMkB,gBAAc,IAAI,GAClD,SAAS,UAAU;AAEzB,QAAI,MAAM,MAAM;AACR,YAAA,oBAAoB,OAAO,OAAO;AACxC;AAAA,IACF;AAEA,QAAI,MAAM,QAAQ;AAChB,YAAM,QAAQ,MAAM;AAEpB,UAAI,CAAC;AACG,cAAA,IAAI,MAAM,uBAAuB;AAGnC,YAAA,eAAe,OAAO,QAAQ,MAAM;AAC1C;AAAA,IACF;AAEA,UAAM,CAAC,eAAe,aAAa,IAAI,KAAK,oBACtC,oBAAoB,CAAQ,CAAA,MAAM,cAAc,GAEhD,YAAY,iBAAiB,oBAAoB,aAAa;AAChE,QAAA;AACI,YAAA,IAAI,MAAM,SAAS;AAGrB,UAAA,mBAAmB,MAAM,OAAO,SACnC,KAAA,EACA,KAAK,CAAC,aAAa,SAAS,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,GAE7C,oBAAoB,OAAO,iBAC/B,qBAAqB,QAAQ,EAAC,SAAS,uBAAA,CAAuB;AAC5D,QAAA,CAAC,iBAAiB,SAAS,iBAAiB;AAC9C,YAAM,IAAI,MAAM,mBAAmB,iBAAiB,iBAAiB;AAGjE,UAAA,oBAAoB,OAAO,iBAC/B,qBAAqB,QAAQ,EAAC,SAAS,uBAAuB,CAAA;AAC5D,QAAA,iBAAiB,SAAS,iBAAiB;AAC7C,YAAM,IAAI,MAAM,mBAAmB,iBAAiB,kBAAkB;AAGlE,UAAA,MAAM,oBAAoB,iBAAiB;AAC7C,QAAA;AACI,YAAA,IAAI,MAAM,GAAG;AAGjB,QAAA;AACI,YAAA,WAAW,MAAM,OAAO,QAA6B;AAAA,QACzD,QAAQ;AAAA,QACR,KAAK,aAAa,iBAAiB;AAAA,QACnC,MAAM;AAAA,UACJ,eAAe;AAAA,UACf,aAAa;AAAA,QACf;AAAA,MAAA,CACD;AAcD,UAZA,OAAO;AAAA,QACL,mBAAmB,MAAM,MAAM,iBAAiB,CAAC,OAAO,MAAM,MAAM,iBAAiB,CAAC;AAAA,MAAA,GAGnF,qBACH,OAAO;AAAA,QACL;AAAA,MACF,GAGF,OAAO,MAAM,OAAO,MAAM,MAAM,SAAS,KAAK,CAAC,UAAU,GAErD,MAAM;AACR;AAGF,YAAM,eAAe,SAAS,OAAO,QAAQ,MAAM,GACnD,OAAO,MAAM,OAAO,MAAM,MAAM,SAAS,KAAK,CAAC,YAAY;AAAA,aACpD,OAAO;AACV,YAAM,aACR,OAAO,MAAM,GAAG,MAAM,IAAI;AAAA,EAA4B,MAAM,SAAS,KAAK,OAAO,EAAE,CAAC;AAAA,CAAI,IAExF,OAAO,MAAM,GAAG,MAAM,IAAI;AAAA,EAA4B,MAAM,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAE9E;AAAA,EACF;AACF,GC7OMlB,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAUX,eAAe,CAAC,WAAW,UAAU,QAAQ,GAM7C,uBAA0D;AAAA,EAC9D,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,QAAQ,OAAA,IAAU,SAC9B,QAAQ,KAAK,YACb,CAAC,OAAO,IAAI,KAAK,oBACjB,SAAS,UAAA,GAET,YAAY,WAAW,oBAAoB,OAAO;AACpD,QAAA;AACI,YAAA,IAAI,MAAM,SAAS;AAG3B,UAAM,CAAC,UAAU,eAAe,IAAI,MAAM,QAAQ,IAAI;AAAA,MACpD,OAAO,SAAS,KAAK,EAAE,KAAK,CAAC,SAAS,KAAK,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;AAAA,MAC/D,OAAO,QAAQ,EAAC,KAAK,aAAY;AAAA,IAAA,CAClC;AAED,QAAI,MAAM,cAAc,CAAC,aAAa,SAAS,MAAM,UAAU;AAC7D,YAAM,IAAI,MAAM,oBAAoB,MAAM,UAAU,eAAe;AAGrE,UAAM,cAAc,OAAO,WAAW,qBAAqB,MAAM;AAC7D,QAAA,SAAS,SAAS,WAAW;AAC/B,YAAM,IAAI,MAAM,YAAY,WAAW,kBAAkB;AAGrD,UAAA,mBAAmB,gBAAgB,SAAS,gBAAgB;AAC5DF,YAAA,8BAA8B,mBAAmB,QAAQ,QAAQ;AAGjE,UAAA,UAAU,QADO,mBAAmB,MAAM,aAAa,aACpB,2BAA2B,QAAQ,MAAM;AAE9E,QAAA;AACI,YAAA,OAAO,SAAS,OAAO,aAAa,EAAC,QAAQ,CAAA,GACnD,OAAO,MAAM,8BAA8B;AAAA,aACpC,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAA6B,IAAI,OAAO,EAAE;AAAA,IAC5D;AAAA,EACF;AACF;AAEA,eAAe,2BAA2B,QAAqB,QAAsB;AAC7E,QAAA,OAAO,MAAM,OAAO,OAA6B;AAAA,IACrD,MAAM;AAAA,IACN,SAAS;AAAA,IACT,SAAS;AAAA,MACP;AAAA,QACE,OAAO;AAAA,QACP,MAAM;AAAA,MACR;AAAA,MACA;AAAA,QACE,OAAO;AAAA,QACP,MAAM;AAAA,MACR;AAAA,IACF;AAAA,EAAA,CACD;AAEG,SAAA,SAAS,aACX,OAAO;AAAA,IACL;AAAA;AAAA,EAIG,GAAA;AACT;AC3FA,IAAe,eAAA;AAAA,EACb,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf;ACDA,MAAM,2BAAiD;AAAA,EACrD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,UAAU;AAAA,EACV,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,WAAU,SACtB,CAAC,QAAQ,IAAI,OAAO,IAAI,KAAK,oBAC7B,SAAS,UAAU;AAErB,QAAA,CAAC,OAAO,SAAS;AACnB,YAAM,IAAI,MAAM;AAAA,6BAAmE;AAGrF,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,mCAAmC;AAGrD,QAAI,CAAC,CAAC,OAAO,KAAK,EAAE,SAAS,MAAM;AAC3B,YAAA,IAAI,MAAM,uCAAuC;AAGzD,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,+BAA+B;AAG7C,QAAA,WAAW,SAAS,CAAC;AACjB,YAAA,IAAI,MAAM,mDAAmD;AAGrE,UAAM,UAAU,GAAG,EAAE,IACf,UAAU,oBAAoB,OAAO;AACvC,QAAA;AACI,YAAA,IAAI,MAAM,OAAO;AAGnB,UAAA,WAAW,MAAM,OAAO,SAAS,KAAA,GAAQ,KAAK,CAAC,SAAS,KAAK,SAAS,OAAO;AAEnF,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,mBAAmB;AAGrC,QAAI,WAAW,OAAO;AACb,aAAA,MAAM,QAAQ,OAAO;AAC5B;AAAA,IACF;AAEI,QAAA,QAAQ,YAAY,SAAS;AACxB,aAAA,MAAM,uBAAuB,OAAO,QAAQ;AACnD;AAAA,IACF;AAEI,gBAAY,aACd,OAAO;AAAA,MACL;AAAA;AAAA,IAIJ,GAAA,MAAM,OAAO,SAAS,KAAK,SAAS,EAAC,QAAA,CAAyC,GAC9E,OAAO,MAAM,4BAA4B;AAAA,EAC3C;AACF,GC5DME,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUjB,SAASkB,gBAAc,MAAyB;AAC9C,SAAOC,eAAAA,QAAMC,QAAAA,QAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EAAE,OAAO,SAAS,EAAC,MAAM,UAAA,CAAU,EAAE;AAC/F;AAMA,MAAM,uBAAiE;AAAA,EACrE,MAAM;AAAA,EACN,OAAO;AAAA,EAAA,UACPpB;AAAAA,EACA,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,QAAQ,OAAM,IAAI,SAC9B,EAAC,MAAA,IAAS,MAAMkB,gBAAc,IAAI,GAClC,CAAC,EAAE,IAAI,KAAK;AAClB,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,+BAA+B;AAGjD,UAAM,UAAU,GAAG,EAAE,IACf,UAAU,oBAAoB,OAAO;AACvC,QAAA;AACI,YAAA;AAGJ,YACF,OAAO,KAAK,4DAA4D,OAAO,GAAG,IAElF,MAAM,OAAO,OAAO;AAAA,MAClB,MAAM;AAAA,MACN,SACE;AAAA;AAAA,MACF,QAAQ,CAAC,UAAU,GAAG,KAAK,GAAG,KAAK;AAAA,MACnC,UAAU,CAAC,UACF,UAAU,WAAW;AAAA,IAAA,CAE/B,GAGH,MAAM,UAAU,EAAE,SAAS,OAAO,OAAO,GACzC,OAAO,MAAM,8BAA8B;AAAA,EAC7C;AACF,GClDM,OAAO,MAAM,MAEblB,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAqCjB,SAASgD,aAAW,UAA0C;AAC5D,QAAM,QAA2B,CAAA;AACjC,SAAI,SAAS,UACX,MAAM,QAAQ,GAAG,SAAS,KAAK,GAAG,MAAM,GAAG,IAGzC,SAAS,mBAAmB,MAC9B,MAAM,mBAAmB,SAAS,SAAS,mBAAmB,GAAG,EAAE,IAGjE,OAAO,SAAS,MAAQ,QAC1B,MAAM,MAAM,CAAQ,CAAA,SAAS,MAG3B,OAAO,SAAS,SAAW,QAC7B,MAAM,SAAS,CAAQ,CAAA,SAAS,SAG9B,OAAO,SAAS,SAAW,QAC7B,MAAM,SAAS,CAAA,CAAQ,SAAS,SAG9B,OAAO,SAAS,WAAa,QAC/B,MAAM,WAAW,CAAA,CAAQ,SAAS,WAGhC,OAAO,SAAS,YAAc,QAChC,MAAM,YAAY,CAAA,CAAQ,SAAS,YAG9B;AACT;AASA,MAAM,uBAA0D;AAAA,EAC9D,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbhD;AAAAA,EACA,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,QAAQ,OAAO,SAAS,OAAM,IAAI,SAC9C,SAAS,UAAA,GACT,CAAC,eAAe,iBAAiB,IAAI,KAAK,oBAC1C,QAAQgD,aAAW,KAAK,UAAU;AAExC,QAAI,UAAU,gBAAgB,GAAG,aAAa,KAAK;AAC9C,gBACH,UAAU,MAAM,oBAAoB,SAAS,EAAC,SAAS,2BAA2B,CAAA;AAG9E,UAAA,UAAU,oBAAoB,OAAO;AACvC,QAAA;AACI,YAAA;AAKJ,QAAA,EADa,MAAM,OAAO,SAAS,KAAA,GACzB,KAAK,CAAC,QAAQ,IAAI,SAAS,OAAO;AAC9C,YAAM,IAAI,MAAM,sBAAsB,OAAO,aAAa;AAI5D,UAAM,EAAC,UAAA,IAAa,OAAO,OAAO;AAE3B,WAAA,MAAM,wSAAmD,GAChE,OAAO,MAAM,6DAAmD,GAChE,OAAO,MAAM,6DAAmD,GAChE,OAAO,MAAM,UAAK,MAAM,KAAK,WAAW,CAAC,KAAK,MAAM,KAAK,SAAS,EAAE,OAAO,EAAE,CAAC,SAAI,GAClF,OAAO,MAAM,UAAK,MAAM,KAAK,SAAS,CAAC,KAAK,MAAM,KAAK,OAAO,EAAE,OAAO,EAAE,CAAC,SAAI,GAC9E,OAAO,MAAM,6DAAmD,GAChE,OAAO,MAAM,wSAAmD,GAChE,OAAO,MAAM,EAAE;AAEf,QAAI,kBAAkB;AACjB,wBACH,kBAAkB,MAAM,OAAO,OAAO;AAAA,MACpC,MAAM;AAAA,MACN,SAAS;AAAA,MACT,SAASpC,cAAK,QAAA,KAAK,SAAS,GAAG,OAAO,SAAS;AAAA,MAC/C,QAAQe,KAAA;AAAA,IACT,CAAA;AAGH,UAAM,aAAa,MAAM,cAAc,iBAAiB,SAAS,QAAQ,KAAK;AAC9E,QAAI,CAAC,YAAY;AACf,aAAO,MAAM,WAAW;AACxB;AAAA,IACF;AAGI,mBAAe,OACjB,OAAO,MAAM,sBAAsB,MAAM,KAAK,OAAO,CAAC,SAAS,MAAM,KAAK,UAAU,CAAC,GAAG;AAG1F,QAAI,cAAc,0BACd,UAAU,OAAO,QAAQ,WAAW,EAAE;AACpC,UAAA,aAAa,CAACxB,cAA4B;AAC1C,MAAAA,UAAS,SAAS,eACpB,QAAQ,WACR,UAAU,OAAO,QAAQA,UAAS,IAAI,EAAE,MAAA,KAC/BA,UAAS,SAAS,eAAeA,UAAS,WACnD,QAAQ,OAAO,GAAGA,UAAS,IAAI,KAAKA,UAAS,OAAO,IAAIA,UAAS,KAAK,MAGxE,cAAcA,UAAS;AAAA,IAAA,GAGnB,QAAQ,KAAK;AACf,QAAA;AACF,YAAM8C,+BAAc;AAAA,QAClB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,GAAG;AAAA,MAAA,CACJ,GACD,QAAQ;aACD,KAAK;AACZ,YAAA,QAAQ,KACF,GAAA;AAAA,IACR;AAEO,WAAA,MAAM,oBAAoBlC,0BAAS,KAAK,QAAQ,KAAK,CAAC,GAAG;AAAA,EAClE;AACF;AAGA,eAAe,cACb,aACA,SACA,QACA,OACA;AACA,MAAI,gBAAgB;AACX,WAAA;AAGH,QAAA,UAAUH,cAAAA,QAAK,WAAW,WAAW,IACvC,cACAA,cAAA,QAAK,QAAQ,QAAQ,IAAI,GAAG,WAAW;AAE3C,MAAI,WAAW,MAAMyB,sBAAG,KAAK,OAAO,EAAE,MAAM,IAAI;AAC1C,QAAA,gBAAgB,WAAW,SAAS,OAAO,IAAIzB,cAAK,QAAA,SAAS,OAAO,EAAE,QAAQ,GAAG,MAAM;AAE7F,MAAI,CAAC,UAAU;AACb,UAAM,aAAa,gBAAgBA,cAAAA,QAAK,QAAQ,OAAO,IAAI;AAE3D,UAAMyB,cAAAA,QAAG,MAAM,YAAY,EAAC,WAAW,IAAK;AAAA,EAC9C;AAEM,QAAA,YAAY,gBAAgB,UAAUzB,sBAAK,KAAK,SAAS,GAAG,OAAO,SAAS;AAGlF,SAFA,WAAW,MAAMyB,sBAAG,KAAK,SAAS,EAAE,MAAM,IAAI,GAE1C,CAAC,MAAM,aAAa,YAAY,SAAS,OAAA,KAOvC,CANoB,MAAM,OAAO,OAAO;AAAA,IAC1C,MAAM;AAAA,IACN,SAAS,SAAS,SAAS;AAAA,IAC3B,SAAS;AAAA,EAAA,CACV,IAGQ,KAIJ;AACT;AC/MA,MAAM,SAAS,CAAC,QAAgB,WAAa,GAAG,YAE1CrC,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA8DjB,SAAS,YAAY,MAAoC;AACvD,SAAO,OAAO,OAAS,MAAc,SAAY,CAAQ,CAAA;AAC3D;AAEA,SAAS,WAAW,UAA0C;AACtD,QAAA,gCAAgC,YAAY,SAAS,mCAAmC,CAAC,GACzF,qBAAqB,YAAY,SAAS,sBAAsB,CAAC,GACjE,mBAAmB,YAAY,SAAS,mBAAmB,CAAC,GAC5D,gBAAgB,YAAY,SAAS,gBAAgB,CAAC,GACtD,6BAA6B,YAAY,SAAS,+BAA+B,CAAC,GAClF,uBAAuB,YAAY,SAAS,wBAAwB,CAAC,GACrE,UAAU,YAAY,SAAS,OAAO,GACtC,UAAU,YAAY,SAAS,OAAO;AACrC,SAAA;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EAAA;AAEJ;AAEA,MAAM,uBAA6C;AAAA,EACjD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbA;AAAAA;AAAAA,EAEA,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,QAAQ,OAAO,gBAAA,IAAmB,SAC9C,QAAQ,WAAW,KAAK,UAAU,GAClC;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACE,IAAA,OAEE,YAAY,qBAAqB,KAAK,UAAU,GAChD,SAAS,UAAA,GAET,CAAC,MAAM,MAAM,IAAI,KAAK;AAC5B,QAAI,CAAC;AACH,YAAM,IAAI;AAAA,QACR,iFAAiF,MAAM;AAAA,UACrF;AAAA,QACD,CAAA;AAAA,MAAA;AAIL,UAAM,gBAAgB,MAAM,uBAAuB,QAAQ,OAAO;AAC5DF,YAAA,mCAAmC,aAAa,GAAG;AAEnD,UAAA,QAAQ,gBAAgB,KAAK,IAAI;AACnC,QAAA,aACA,YACA,iBAAiB;AAEjB,QAAA;AACFA,cAAM,2CAA2C,GACjD,cAAc,MAAM,aAAa,IAAI;AAAA,SAChC;AACL,YAAM,aAAac,cAAAA,QAAK,QAAQ,QAAQ,OAAO,IAAI,GAC7C,YAAY,MAAMyB,cAAAA,QAAG,KAAK,UAAU,EAAE,MAAM,MAAM,IAAI;AAC5D,UAAI,CAAC;AACH,cAAM,IAAI,MAAM,GAAG,UAAU,oCAAoC;AAGnE,uBAAiB,UAAU,YAAA,GACvB,iBACF,cAAc,cAEd,aAAazB,cAAK,QAAA,QAAQ,UAAU,GACpC,cAAc,MAAMsC,oBAAiB,UAAU;AAAA,IAEnD;AAEA,UAAM,eAAe,OAAO,MAAM,EAAE,OAAO,EAAC,SAAS,cAAa,CAAC,GAG7D,EAAC,WAAW,QAAO,IAAI,aAAa,OAAO;AAE1C,WAAA,MAAM,wSAAmD,GAChE,OAAO,MAAM,6DAAmD,GAChE,OAAO,MAAM,6DAAmD,GAChE,OAAO,MAAM,UAAK,MAAM,KAAK,WAAW,CAAC,KAAK,MAAM,KAAK,SAAS,EAAE,OAAO,EAAE,CAAC,SAAI,GAClF,OAAO,MAAM,UAAK,MAAM,KAAK,SAAS,CAAC,KAAK,MAAM,KAAK,OAAO,EAAE,OAAO,EAAE,CAAC,SAAI,GAC9E,OAAO,MAAM,6DAAmD,GAChE,OAAO,MAAM,wSAAmD,GAChE,OAAO,MAAM,EAAE;AAEf,QAAI,aACA,iBACA,WACA,eAAsD,MACtD;AAEJ,aAAS,WAAW,MAAqB;AACvC,YAAM,mBAAmB,KAAK,OACxB,WAAW,KAAK,QAAQ;AAU9B,UATA,UAAU,cAAc,IAAI,GAExB,oBAAoB,KAAK,UAAU,KAAK,YACtC,gBACF,cAAc,YAAY,GAE5B,eAAe,OAGb;AACF;AAIF,YAAM,WAAW,aACX,gBAAgB,aAAa,KAAK;AACxC,UAAA,YAAY,KAAK,OACjB,cAAc,KAAK,MAEf,mBAAmB,gBAAgB,SAAS;AAC9C,cAAM,YAAYnC,kBAAA,QAAS,KAAK,IAAA,IAAQ,eAAe;AAAA,UACrD,sBAAsB;AAAA,QAAA,CACvB;AACD,wBAAgB,OAAO,UAAU,QAAQ,KAAK,SAAS,KACvD,gBAAgB;MAClB;AAEA,wBAAkB,OAAO,QAAQ,QAAQ,KAAK,IAAI,UAAU,EAAE,MAE1D,GAAA,iBACF,cAAc,YAAY,GAC1B,eAAe,OAGjB,eAAe,YAAY,MAAM;AAC/B,cAAM,YAAYA,kBAAA,QAAS,KAAK,IAAA,IAAQ,eAAe;AAAA,UACrD,sBAAsB;AAAA,QAAA,CACvB;AAEG,4BACF,gBAAgB,OAAO,GAAG,OAAO,GAAG,KAAK,IAAI,KAAK,SAAS;AAAA,SAE5D,EAAE;AAAA,IACP;AAES,aAAA,QAAQ,EAAC,WAA8B;AAC1C,UAAA,gBACF,cAAc,YAAY,GAG5B,eAAe,MAEX,WAAW,aAAa,iBAAiB;AAC3C,cAAM,YAAYA,kBAAA,QAAS,KAAK,IAAA,IAAQ,WAAW;AAAA,UACjD,sBAAsB;AAAA,QAAA,CACvB;AACD,wBAAgB,OAAO,UAAU,WAAW,KAAK,SAAS,KAC1D,gBAAgB;MAAQ,MACf,oBACT,gBAAgB;IAEpB;AAGI,QAAA;AACF,YAAM,EAAC,SAAS,SAAY,IAAA,MAAMoC,sBAAAA,QAAa,aAAa;AAAA,QAC1D,QAAQ;AAAA,QACR;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MAAA,CACD;AAED,cAAQ,EAAC,SAAS,GAAK,CAAA,GAEvB,OAAO,MAAM;AAAA,GAAiD,SAAS,aAAa,GACpF,cAAc,UAAU,MAAM;AAAA,aACvB,KAAK;AASZ,UARA,QAAQ,EAAC,SAAS,GAAK,CAAC,GAQpB,EALF,CAAC,mBACD,IAAI,YACJ,IAAI,SAAS,eAAe,OAC5B,IAAI,SAAS;AAGP,cAAA;AAGR,YAAM,UAAU;AAAA,QACd,IAAI;AAAA,QACJ;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,KAAK;AAAA,CAAI,GAGL,QAAQ,IAAI,MAAM,OAAO;AACzB,YAAA,MAAA,UAAU,IAAI,SACpB,MAAM,WAAW,IAAI,UACrB,MAAM,eAAe,IAAI,cAEnB;AAAA,IACR;AAAA,EACF;AACF;AAEA,eAAe,uBAAuB,QAAgB,SAA4B;AAChF,QAAM,EAAC,WAAW,QAAQ,OAAU,IAAA,SAC9B,SAAS;AAEf,MAAI,QAAQ;AACJ,UAAA,UAAU,oBAAoB,MAAM;AACtC,QAAA;AACI,YAAA,IAAI,MAAM,OAAO;AAAA,EAE3B;AAEArD,UAAM,6BAA6B;AAC7B,QAAA,UAAU,OAAO,QAAQ,6BAA6B,EAAE,SACxD,WAAW,MAAM,OAAO,SAAS,KAAK;AAC5C,UAAQ,QAAQ,oCAAoC;AAEpD,MAAI,gBAAgB,SAAS,GAAG,MAAM,KAAK;AAC3C,MAAI,CAAC;AACa,oBAAA,MAAM,oBAAoB,SAAS;AAAA,MACjD,SAAS;AAAA,MACT,eAAe;AAAA,IAAA,CAChB;AAAA,WACQ,CAAC,SAAS,KAAK,CAAC,YAAY,QAAQ,SAAS,aAAa,GAAG;AAQtE,QAPAA,QAAM,uDAAuD,GAOzD,CANiB,MAAM,OAAO,OAAO;AAAA,MACvC,MAAM;AAAA,MACN,SAAS,YAAY,aAAa;AAAA,MAClC,SAAS;AAAA,IAAA,CACV;AAGC,YAAM,IAAI,MAAM,YAAY,aAAa,kBAAkB;AAGvD,UAAA,OAAO,SAAS,OAAO,aAAa;AAAA,EAC5C;AAEO,SAAA;AACT;AAEA,SAAS,qBAAqB,OAA0B;AAChD,QAAA,EAAC,SAAS,QAAW,IAAA;AAC3B,MAAI,WAAW;AACP,UAAA,IAAI,MAAM,yCAAyC;AAG3D,SAAI,MAAM,UACD,oBAGL,MAAM,UACD,sBAGF;AACT;AAEA,SAAS,cAAc,MAAqB;AAC1C,MAAI,CAAC,KAAK,SAAS,OAAO,KAAK,UAAY;AAClC,WAAA;AAGT,QAAM,UAAU,KAAK,MAAO,KAAK,UAAU,KAAK,QAAS,GAAG;AAC5D,SAAO,IAAIsD,kBAAS,QAAA,GAAG,OAAO,IAAI,GAAG,GAAG,CAAC;AAC3C;AAEA,SAAS,aAAazC,MAAa;AAEjC,SADgBH,MAAM,MAAA,CAACE,WAAAA,QAAQ,EAAC,UAAU,GAAI,CAAC,CAAC,CAAC,EAClC,EAAC,KAAAC,MAAK,QAAQ,GAAK,CAAA;AACpC;AAEA,SAAS,cAAc,UAA2B,QAAsB;AACtE,QAAM,aAAa,SAAS,OAAO,CAAC0C,UAASA,MAAK,SAAS,OAAO;AAElE,MAAI,CAAC,WAAW;AACd;AAGF,QAAM,QAAQ,OAAO,QAAQ,OAAO,OAAO,KAAK,MAAM;AAEtD,OAAK,OAAO,2CAAsC,GAAG,WAAW,SAAS,IAAI,WAAW,OAAO,GAE/F,SAAS,QAAQ,CAAC,YAAY;AACvB,SAAA,KAAK,QAAQ,GAAG,EAAE;AAAA,EAAA,CACxB;AACH;AC7Xa,MAAA,qBAAuC,OAAO,MAAM,YAAY;AAC3E,QAAM,EAAC,WAAW,OAAM,IAAI,SACtB,SAAS,UAAU,GAEnB,UAAU,MAAMf,YAAwB,MAAM;AAC7C,SAAA;AAAA,IACL,QACG,IAAI,CAAC,QAAQ,GAAG,YAAY,GAAG,IAAI,IAAI,OAAO,IAAI,eAAe,YAAY,EAAE,EAC/E,KAAK;AAAA,CAAI;AAAA,EAAA;AAEhB,GCXM,sBAA4C;AAAA,EAChD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,UAAU;AAAA,EACV,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,OAAA,IAAU,SAEtB,WAAW,MADF,UACe,EAAA,SAAS;AAChC,WAAA,MAAM,SAAS,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE,KAAK;AAAA,CAAI,CAAC,GAGvD,MAAM,mBAAmB,MAAM,OAAO;AAAA,EACxC;AACF,GCXMtC,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAWX,gBAAsC;AAAA,EAC1C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OACN,MACA,aAEY,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,mBAAmC;AAAA,MAEjD,QAAQ,MAAM,OAAO;AAAA,EAAA,UAElCA;AACF,GC1BMA,aAAW;AAAA;AAAA;AAAA,GAKX,kBAAwC;AAAA,EAC5C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OACN,MACA,aAEY,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,qBAAqC;AAAA,MAEnD,QAAQ,MAAM,OAAO;AAAA,EAAA,UAElCA;AACF,GChBMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAaX,aAAmC;AAAA,EACvC,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OACN,MACA,aAEkB,MAAM,aAAa,GAEpB,MAAM,OAAO;AAAA,EAAA,UAEhCA;AACF;AAEA,eAAsB,eAKpB;AAUY,UAAA,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,gBAA6B;AAAA,EAE3C,CAAA,GAAA;AACb;AC1BA,MAAMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GA0BX,yBAA4D;AAAA,EAChE,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA;AAAA,EAEb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,OAAM,IAAI,SACtB,EAAC,SAAS,SAAS,OAAO,IAAI,QAAO,IAAI,KAAK,YAC9C,CAAC,IAAI,IAAI,KAAK,oBACd,WAAW,KAAK,WAAW,OAC3B,SAAS,UAAU,UAAY,EAAA,MAAA,EAAQ,OAAO,EAAC,QAAO,CAAC,IAAI,UAAU;AAE3E,QAAI,WAAW;AACP,YAAA,IAAI,MAAM,yCAAyC;AAG3D,QAAI,MAAM;AACF,YAAA,IAAI,MAAM,6CAA6C;AAG/D,QAAI,YAAmC;AAKvC,SAJI,WAAW,aACb,YAAY,UAAU,oBAAoB,sBAGxC,MAAM;AACF,YAAA,cAAcY,sBAAK,QAAQ,QAAQ,IAAO,GAAA,IAAI,GAC9C,UAAU0C,eAAAA,QAAM,MAAM,MAAMjB,cAAG,QAAA,SAAS,aAAa,MAAM,CAAC,GAC5D,SAAS,MAAM,eAAe,SAAS,WAAW,MAAM;AAC9D,aAAO,MAAM,iBAAiB,QAAQ,SAAS,CAAC;AAChD;AAAA,IACF;AAGA,UAAM,QAAQ,MAAMkB,KAAA,KAAA,GACd,MAAM,WAAW,UAAU,QAC3B,UAAU3C,cAAAA,QAAK,KAAK4C,YAAAA,QAAG,OAAA,GAAU,cAAc,GAAG,KAAK,IAAI,GAAG,EAAE,GAChE,YAAY,WAAWF,eAAAA,QAAM,YAAY,KAAK,WAC9C,eAAgB,MAAO,MAAM,OAAO,YAAY,EAAE,KAAO,EAAC,KAAK,OAAO,OAAO;AAC7E,UAAAjB,cAAA,QAAG,MAAMzB,cAAAA,QAAK,KAAK4C,oBAAG,UAAU,YAAY,GAAG,EAAC,WAAW,GAAK,CAAA,GACtE,MAAMnB,cAAAA,QAAG,UAAU,SAAS,UAAU,cAAc,MAAM,CAAC,GAAG,MAAM;AAEpE,UAAM,SAAS;AACX,aAEF,uBAAuB,OAAO,GAC9B,OAAO,MAAM,eAAe,OAAO,EAAE,GACrC,OAAO,MAAM,gDAAgD,GAC7D,OAAO,MAAM,kDAAkD,GAC/DoB,kBAAAA,QAAS,MAAM,OAAO,EAAE,GAAG,UAAU,OACnC,OAAO,MAAM,EAAE,GACR,8BAA8B,OAAO,EAC7C,GACDC,eAAAA,QAAM,OAAO,KAAK,OAAO,KAAK,OAAO,OAAO,GAAG,EAAC,OAAO,UAAU,CAAA,MAGjEA,eAAAA,QAAM,KAAK,OAAO,KAAK,OAAO,KAAK,OAAO,OAAO,GAAG,EAAC,OAAO,UAAU,CAAA,GACtE,MAAM,8BAA8B,OAAO,GAC3C,MAAMrB,cAAG,QAAA,OAAO,OAAO,EAAE,MAAMsB,cAAAA,OAAI;AAGrC,mBAAe,8BAA8B,UAAkB;AACzD,UAAA;AACA,UAAA;AACF,kBAAUL,eAAAA,QAAM,MAAM,MAAMjB,cAAAA,QAAG,SAAS,UAAU,MAAM,CAAC;AAAA,eAClD,KAAK;AACZ,eAAO,MAAM,yBAAyB,IAAI,OAAO,EAAE;AACnD;AAAA,MACF;AAEI,UAAAuB,iBAAA,QAAQ,SAAS,YAAY,GAAG;AAClC,eAAO,MAAM,oCAAoC,GACjD,OAAO,MAAM,sCAAsC;AACnD;AAAA,MACF;AAEI,UAAA;AACF,cAAM,cAAc,MAAM,eAAe,SAAS,WAAW,MAAM;AACnE,eAAO,MAAM,iBAAiB,aAAa,SAAS,CAAC;AAAA,eAC9C,KAAK;AACZ,eAAO,MAAM,8BAA8B,IAAI,OAAO,EAAE,GACpD,IAAI,QAAQ,SAAS,gBAAgB,KACvC,OAAO,MAAM,qDAAqD;AAAA,MAEtE;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,uBAAuB,SAAiB;AACvC,UAAA,GAAG,UAAU,YAAY;AACzB,UAAAvB,cAAA,QAAG,OAAO,OAAO,EAAE,MAAMsB,cAAI,OAAA,GAEnC,QAAQ,KAAK,GAAG;AAAA,EAAA,CACjB;AACH;AAEA,SAAS,eACP,WACA,WACA,QACA;AACA,QAAM,OAAO,MAAM,QAAQ,SAAS,IAAI,YAAY,CAAC,SAAS;AAC9D,MAAI,KAAK,WAAW;AACZ,UAAA,IAAI,MAAM,uBAAuB;AAGzC,QAAM,YAAY,KAAK,IAAI,CAAC,KAAK,UAAoB;AAEnD,QADA,iBAAiB,KAAK,OAAO,IAAI,GAC7B,cAAc;AACT,aAAA,EAAC,QAAQ;AAGlB,QAAI,cAAc,qBAAqB;AACrC,UAAI,2BAA2B,GAAG;AACzB,eAAA,EAAC,mBAAmB;AAG7B,YAAM,IAAI,MAAM,sCAAsC,SAAS,EAAE;AAAA,IACnE;AAEA,QAAI,cAAc,mBAAmB;AACnC,UAAI,2BAA2B,GAAG;AACzB,eAAA,EAAC,iBAAiB;AAG3B,YAAM,IAAI,MAAM,sCAAsC,SAAS,EAAE;AAAA,IACnE;AAEA,UAAM,IAAI,MAAM,yBAAyB,SAAS,EAAE;AAAA,EAAA,CACrD;AAED,SAAO,OAAO,YAAY,SAAS,EAAE,OAAO;AAC9C;AAEA,SAAS,iBAAiB,KAAc,OAAe,KAAgB;AAC/D,QAAA,WAAW,IAAI,WAAW;AAE5B,MAAA,CAACE,+BAAc,GAAG;AACpB,UAAM,IAAI,MAAM,gBAAgB,qBAAqB,OAAO,QAAQ,CAAC;AAGnE,MAAA,CAAC,oBAAoB,GAAG;AAC1B,UAAM,IAAI,MAAM,gBAAgB,+CAA+C,OAAO,QAAQ,CAAC;AAEnG;AAEA,SAAS,oBAAoB,KAAsC;AAE/D,SAAA,QAAQ,QACR,OAAO,OAAQ,YACf,WAAW,OACX,OAAQ,IAAY,SAAU;AAElC;AAEA,SAAS,2BAA2B,KAAmD;AAC9E,SAAA,oBAAoB,GAAG,KAAK,SAAS;AAC9C;AAEA,SAAS,gBAAgB,SAAiB,OAAe,UAA2B;AAClF,SAAO,WAAW,YAAY,OAAO,KAAK,qBAAqB,KAAK,IAAI,OAAO;AACjF;AAEA,SAAS,iBACP,QACA,WACQ;AACR,QAAM,SAAS;AAAA;AACf,MAAI,cAAc;AACT,WAAA;AAAA,MAAkB,OAAO,QAAQ,IAAI,CAAC,QAAQ,IAAI,EAAE,EAAE,KAAK,MAAM,CAAC;AAG3E,MAAI,cAAc;AACT,WAAA;AAAA,MAAiB,OAAO,QAAQ,IAAI,CAAC,QAAQ,IAAI,EAAE,EAAE,KAAK,MAAM,CAAC;AAI1E,QAAM,UAAoB,CAAA,GACpB,UAAoB;AAC1B,aAAW,OAAO,OAAO;AACnB,QAAI,cAAc,WACpB,QAAQ,KAAK,IAAI,EAAE,IAEnB,QAAQ,KAAK,IAAI,EAAE;AAIvB,SAAI,QAAQ,SAAS,KAAK,QAAQ,SAAS,IAClC;AAAA,IACL;AAAA,MAAiB,QAAQ,KAAK,MAAM,CAAC;AAAA,IACrC,4BAA4B,MAAM,GAAG,QAAQ,KAAK,MAAM,CAAC;AAAA,IACzD,KAAK;AAAA;AAAA,CAAM,IACJ,QAAQ,SAAS,IACnB;AAAA,MAAiB,QAAQ,KAAK,MAAM,CAAC,KAGvC;AAAA,MAAkC,QAAQ,KAAK,MAAM,CAAC;AAC/D;AAEA,SAAS,YAAY;AACnB,QAAM,gBAAgB,OAAO,KAAK,QAAQ,QAAQ,IAAI,YAAY,OAG5D,QADS,QAAQ,IAAI,UAAU,QAAQ,IAAI,UAAU,eACvC,MAAM,KAAK;AAE/B,SAAO,EAAC,KADI,KAAK,MAAM,KAAK,IACf;AACf;ACpQA,MAAM7D,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAwBX,yBAA4D;AAAA,EAChE,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,QAAQ,UAAS,SAC7B,EAAC,QAAO,IAAI,KAAK,YACjB,MAAM,KAAK,mBAAmB,IAAI,CAAC,QAAQ,GAAG,GAAG,EAAE;AAEzD,QAAI,CAAC,IAAI;AACD,YAAA,IAAI,MAAM,+BAA+B;AAG3C,UAAA,SAAS,UAAU,UAAA,EAAY,MAAA,EAAQ,OAAO,EAAC,QAAO,CAAC,IAAI,aAE3D,cAAc,IAAI,OAAO,CAAC,KAAK,OAAO,IAAI,OAAO,EAAE,GAAG,OAAO,YAAA,CAAa;AAC5E,QAAA;AACF,YAAM,EAAC,QAAW,IAAA,MAAM,YAAY,OAAA,GAC9B,UAAU,QAAQ,OAAO,CAAC,QAAQ,IAAI,cAAc,QAAQ,EAAE,IAAI,CAAC,QAAQ,IAAI,EAAE,GACjF,WAAW,IAAI,OAAO,CAAC,OAAO,CAAC,QAAQ,SAAS,EAAE,CAAC;AACrD,cAAQ,SAAS,KACnB,OAAO,MAAM,WAAW,QAAQ,MAAM,IAAI8D,2BAAU,YAAY,QAAQ,MAAM,CAAC,EAAE,GAG/E,SAAS,SAAS,KACpB,OAAO;AAAA,QACL,MAAM,IAAI,GAAGA,mBAAA,QAAU,YAAY,SAAS,MAAM,CAAC,eAAe,SAAS,KAAK,IAAI,CAAC,EAAE;AAAA,MAAA;AAAA,aAGpF,KAAK;AACZ,YAAM,IAAI,MAAM,oBAAoBA,2BAAU,YAAY,IAAI,MAAM,CAAC;AAAA,EAAM,IAAI,OAAO,EAAE;AAAA,IAC1F;AAAA,EACF;AACF,GC5DM,iBAA4C;AAAA,EAChD,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf,GCIM,WAAW,CAAC,QAAwB;AAE1B,SAAA,aAAa,OAAgB,OAA2C;AACtF,QAAM,aAA0E;AAAA,IAC9E,YAAY,MAAM;AAAA,IAClB,KAAK,MAAM;AAAA,IACX,QAAQ,MAAM;AAAA,IACd,QAAQ,MAAM;AAAA,IACd,SAAS,MAAM;AAAA,IACf,YAAY;AAAA,EAAA,GAGR,OAAO,KAAK,UAAU,OAAO,MAAM,CAAC;AAE1C,SAAOC,kBAAAA,QAAS,IAAI,EACjB,IAAI,CAAC,OAAO,GAAG,QAA4B;AAE1C,UAAM,YAAY,MAAM,IAAI,QAAQ,IAAI,IAAI,CAAC;AAC7C,WACE,MAAM,SAAS,YACf,UAAU,SAAS,gBACnB,UAAU,KAAK,UAAU,KAAK,IAEvB,EAAC,GAAG,OAAO,MAAM,MAGnB,IAAA;AAAA,EACR,CAAA,EACA,IAAI,CAAC,WACc,WAAW,MAAM,IAAI,KAAK,UAC3B,MAAM,GAAG,CAC3B,EACA,KAAK,EAAE;AACZ;ACxCA,MAAM/D,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAoBX,sBAA8D;AAAA,EAClE,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,QAAQ,UAAS,SAC7B,EAAC,QAAQ,QAAW,IAAA,KAAK,YACzB,CAAC,KAAK,IAAI,KAAK,mBAAmB,IAAI,CAAC,QAAQ,GAAG,GAAG,EAAE;AAE7D,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,+BAA+B;AAG3C,UAAA,SAAS,UAAU,UAAA,EAAY,MAAA,EAAQ,OAAO,EAAC,QAAA,CAAQ,IAAI;AAE7D,QAAA;AACF,YAAM,MAAM,MAAM,OAAO,YAAY,KAAK;AAC1C,UAAI,CAAC;AACH,cAAM,IAAI,MAAM,YAAY,KAAK,YAAY;AAGxC,aAAA,MAAM,SAAS,aAAa,KAAK,KAAK,IAAI,KAAK,UAAU,KAAK,MAAM,CAAC,CAAC;AAAA,aACtE,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAA8B,IAAI,OAAO,EAAE;AAAA,IAC7D;AAAA,EACF;AACF,GC9CM,oBAAoB,eAEpBA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oDAQmC,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAyBrE,IAAe,wBAAA;AAAA,EACb,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OACN,MACA,YACkB;AAlDtB,QAAA,IAAA;AAoDU,UAAA;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,eAAe;AAAA,IACb,IAAA,MAAMkB,gBAAc,IAAI,GACtB,EAAC,WAAW,QAAQ,OAAO,cAAa,SACxC,CAAC,KAAK,IAAI,KAAK;AAErB,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,yBAAyB;AAGtC,kBACH,OAAO,KAAK,MAAM,OAAO,wCAAwC,iBAAiB,IAAI,CAAC;AAGzF,UAAM,iBAAiB,CAAC,SAClB,iBAAiB,CAAC,SAClB,cAAc,CAAC;AAErB,QAAI,kBAAkB,GAAC,KAAW,aAAA,OAAA,SAAA,UAAA,QAAX,QAAgB,GAAA;AACrC,YAAM,IAAI;AAAA,QACR;AAAA,MAAA;AAIJ,QAAI,kBAAkB,GAAC,KAAW,aAAA,OAAA,SAAA,UAAA,QAAX,QAAgB,GAAA;AACrC,YAAM,IAAI;AAAA,QACR;AAAA,MAAA;AAIE,UAAA,aAAa,UAAU,EAAC,gBAAgB,aAAY,EAAE,SACtD,EAAC,SAAS,iBAAiB,WAAW,sBAAqB,WAAW,UAEtE,SAAS,WAAW,OAAO;AAAA,MAC/B,WAAW,WAAW;AAAA,MACtB,SAAS,WAAW;AAAA,MACpB,YAAY,cAAc;AAAA,IAAA,CAC3B;AAEG,QAAA;AACF,YAAM,OAAO,MAAM,OAAO,MAAM,KAAK;AACrC,UAAI,CAAC;AACG,cAAA,IAAI,MAAM,2BAA2B;AAGtC,aAAA,MAAM,SAAS,aAAa,MAAM,KAAK,IAAI,KAAK,UAAU,MAAM,MAAM,CAAC,CAAC;AAAA,aACxE,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAAyB,IAAI,OAAO,EAAE;AAAA,IACxD;AAAA,EACF;AACF;AAEA,SAASA,gBAAc,MAAiD;AAEhE,QAAA,qBAAqB,QAAQ,IAAI;AAChC,SAAAC,eAAA,QAAMC,gBAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EACrD,OAAO,UAAU,EAAC,MAAM,WAAW,SAAS,IAAM,EAClD,OAAO,WAAW,EAAC,MAAM,SAAA,CAAS,EAClC,OAAO,WAAW,EAAC,MAAM,SAAA,CAAS,EAClC,OAAO,aAAa,EAAC,MAAM,WAAW,SAAS,IAAM,EACrD,OAAO,eAAe,EAAC,MAAM,UAAU,SAAS,oBAAmB,EAAE;AAC1E;ACnHA,MAAM4C,gBAAc,iEAEdhE,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAwBXiE,6BAAiD;AAAA,EACrD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,aACXD;AAAAA,EAAA,UACAhE;AAAAA,EACA,QAAQ,OAAO,MAAM,aACP,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,sBAAyC;AAAA,MAEvD,QAAQ,MAAM,OAAO;AAEpC,GCrCMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAuBJ,cAAoC;AAAA,EAC/C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EAAA,UACbA;AAAAA,EACA,QAAQ,OAAO,MAAM,aACP,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,iBAA+B;AAAA,MAE7C,QAAQ,MAAM,OAAO;AAEpC,GC3BMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAeX,0BAAgD;AAAA,EACpD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OAAO,MAAkD,aACnD,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,sBAAuC;AAAA,MAErD,QAAQ,MAAM,OAAO;AAAA,EAAA,UAElCA;AACF,GChCMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAgCX,0BAAgD;AAAA,EACpD,MAAM;AAAA,EACN,WAAW;AAAA,EACX,OAAO;AAAA,EACP,aAAa;AAAA,EACb,QAAQ,OAAO,MAAyB,aAC1B,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,sBAAuC;AAAA,MAErD,QAAQ,MAAM,OAAO;AAAA,EAAA,UAElCA;AACF,GC3CM,eAA0C;AAAA,EAC9C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf,GCDMA,aAAW;AAAA;AAAA;AAAA,GAKX,yBAA+C;AAAA,EACnD,MAAM;AAAA,EACN,WAAW;AAAA,EACX,OAAO;AAAA,EACP,aAAa;AAAA,EACb,QAAQ,OACN,MACA,aAEY,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,qBAAsC;AAAA,MAEpD,QAAQ,MAAM,OAAO;AAAA,EAAA,UAElCA;AACF,GCtBM,oBAA0C;AAAA,EAC9C,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,UAAU;AAAA,EACV,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,OAAM,IAAI,SACtB,SAAS,UAAU,GAEnB,EAAC,UAAA,IAAa,OAAO,OAAO;AAClC,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,qBAAqB;AAKvC,UAAM,YAAY,wCAFG,MAAM,OAAO,SAAS,QAAQ,SAAS,KAAM,CAAA,GAC/B,kBAAkB,UACkB,YAAY,SAAS;AAE5F,WAAO,MAAM,WAAW,SAAS,EAAE,GACnCkE,cAAAA,QAAK,SAAS;AAAA,EAChB;AACF,GCrBM,oBAA0C;AAAA,EAC9C,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,UAAU;AAAA,EACV,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,UAAS,IAAI,SACd,CAAC,IAAI,IAAI,KAAK,oBACd,SAAS,UAET,GAAA,SAAS,MAAMC,gBAAc,MAAM,OAAO;AAC5C,QAAA;AACF,YAAM,OACH,QACA,OAAO,EAAC,YAAY,aAAY,CAAC,EACjC,QAAQ,EAAC,QAAQ,UAAU,KAAK,UAAU,MAAM,IAAG;AAAA,aAC/C,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAA0B,IAAI,OAAO,EAAE;AAAA,IACzD;AAAA,EACF;AACF;AAEA,eAAeA,gBAAc,WAA+B,SAA4B;AACtF,QAAM,gBAAgB,aAAa,UAAU,YAAA,GACvC,EAAC,QAAQ,cAAa,SAGtB,QAAQ,MAFC,UAAU,EAGtB,MAAM,EACN,OAAO,EAAC,YAAY,aAAa,CAAA,EACjC,QAAgB,EAAC,KAAK,UAAU,MAAM,GAAK,CAAA;AAE9C,MAAI,eAAe;AACX,UAAA,WAAW,MAAM,OAAO,CAAC,SAAS,KAAK,KAAK,YAAY,MAAM,aAAa,EAAE,CAAC;AACpF,QAAI,CAAC;AACH,YAAM,IAAI,MAAM,mBAAmB,SAAS,aAAa;AAG3D,WAAO,SAAS;AAAA,EAClB;AAEA,QAAM,UAAU,MAAM,IAAI,CAAC,UAAU,EAAC,OAAO,KAAK,IAAI,MAAM,KAAK,KAAA,EAAM;AACvE,SAAO,OAAO,OAAO;AAAA,IACnB,SAAS;AAAA,IACT,MAAM;AAAA,IACN;AAAA,EAAA,CACD;AACH;AClDA,MAAM,YAAuC;AAAA,EAC3C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf,GCHM,0BAAgD;AAAA,EACpD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,UAAU;AAAA,EACV,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,OAAU,IAAA,SACtB,CAAC,SAAS,IAAI,KAAK,oBACnB,SAAS,UAAU;AAErB,QAAA;AACA,QAAA;AACQ,gBAAA,MAAM,OAAO,QAAyB,EAAC,KAAK,mBAAmB,SAAS,IAAG;AAAA,aAC9E,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAAmC,IAAI,OAAO,EAAE;AAAA,IAClE;AAEA,UAAM,EAAC,WAAW,YAAY,YAAY,eAAe,WAAc,IAAA;AAUvE,QARA,OAAO,MAAM,SAAS,SAAS,EAAE,GACjC,OAAO,MAAM,WAAW,UAAU,OAAO,CAAC,EAAE,GAC5C,OAAO,MAAM,gBAAgB,UAAU,EAAE,GAErC,QAAQ,aACV,OAAO,MAAM,YAAY,cAAc,OAAO,CAAC,EAAE,GAG/C,CAAC,eAAe,CAAC,iBAAiB,kBAAkB,SAAS;AAC/D,YAAM,OAAO,aAAa;AAAA;AAAA,EAAU,UAAU;AAAA;AAAA,IAAY;AACnD,aAAA,MAAM,kBAAkB,IAAI,EAAE;AAAA,IACvC;AAAA,EACF;AACF;AAIO,SAAS,cACd,SACA,UAAmC,IAC3B;AACR,QAAM,EAAC,YAAA,IAAe,SAChB,EAAC,IAAI,eAAe,WAAU,IAAI,SAClC,OAAO,cAAc,8BAA8B,EAAE,oBAAoB;AAC/E,UAAQ,eAAe;AAAA,IACrB,KAAK;AACI,aAAA,QAAQ,UAAU,IAAI,IAAI;AAAA,IACnC,KAAK;AACI,aAAA;AAAA,IACT,KAAK;AACI,aAAA;AAAA,EAGX;AAEO,SAAA;AACT;AAEO,SAAS,UAAU,SAAkC;AAC1D,SAAI,QAAQ,YACH,WAGL,QAAQ,aACH,gBAGF;AACT;AC5DA,MAAM,sBAA2D;AAAA,EAC/D,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,UAAU;AAAA,EACV,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,UAAS,IAAI,SACd,QAAQ,KAAK,YACb,CAAC,IAAI,IAAI,KAAK,oBACd,SAAS,aAET,SAAS,MAAM,cAAc,MAAM,OAAO;AAChD,QAAI,UACA;AACA,QAAA;AACF,iBAAW,MAAM,OAAO,QAAuB,EAAC,KAAK,UAAU,MAAM,YAAY,CAAA,GACjF,WAAW,MAAM,OAAO,QAA2B,EAAC,KAAK,UAAU,MAAM,aAAY;AAAA,aAC9E,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAAgC,IAAI,OAAO,EAAE;AAAA,IAC/D;AAEM,UAAA,kBAAkBC,yBAAQ,UAAU,WAAW,GAC/C,YAAY,SAAS,IAAI,CAAC,SAAsD;AAAA,MACpF,GAAG;AAAA,MACH,UAAU,gBAAgB,IAAI,EAAE;AAAA,IAChC,EAAA,GAEI,gBAAgB,SAAS,SAAS;AAC9B,cAAA,QAAQ,CAAC,SAAS,MAAM;AACnB,mBAAA,SAAS,SAAS,EAAC,UAAU,MAAM,SAAS,CAAA,GACzD,eAAe,SAAS,kBAAkB,CAAC;AAAA,IAAA,CAC5C;AAAA,EACH;AACF;AAIA,eAAe,cAAc,WAA+B,SAA4B;AACtF,QAAM,gBAAgB,aAAa,UAAU,YAAA,GACvC,EAAC,QAAQ,cAAa,SAGtB,QAAQ,MAFC,UAAU,EAGtB,MAAM,EACN,OAAO,EAAC,YAAY,aAAa,CAAA,EACjC,QAAgB,EAAC,KAAK,UAAU,MAAM,GAAK,CAAA;AAE9C,MAAI,eAAe;AACX,UAAA,WAAW,MAAM,OAAO,CAAC,SAAS,KAAK,KAAK,YAAY,MAAM,aAAa,EAAE,CAAC;AACpF,QAAI,CAAC;AACH,YAAM,IAAI,MAAM,mBAAmB,SAAS,aAAa;AAG3D,WAAO,SAAS;AAAA,EAClB;AAEA,MAAI,MAAM,WAAW;AACb,UAAA,IAAI,MAAM,+BAA+B;AAGjD,MAAI,MAAM,WAAW;AACZ,WAAA,MAAM,CAAC,EAAE;AAGlB,QAAM,UAAU,MAAM,IAAI,CAAC,UAAU,EAAC,OAAO,KAAK,IAAI,MAAM,KAAK,KAAA,EAAM;AACvE,SAAO,OAAO,OAAO;AAAA,IACnB,SAAS;AAAA,IACT,MAAM;AAAA,IACN;AAAA,EAAA,CACD;AACH;AAEA,SAAS,eAAe,SAA4B,MAAe;AAC5D,UACH,QAAQ,OAAO,MAAM;AAAA,CAAO;AAEhC;AAEA,SAAS,aACP,SACA,SACA,SACA;AACA,QAAM,EAAC,SAAQ,IAAI,SACb,EAAC,QAAQ,MAAS,IAAA;AAExB,SAAO,MAAM,SAAS,QAAQ,SAAS,EAAE,GACzC,OAAO,MAAM,WAAW,QAAQ,MAAM,EAAE,GACxC,OAAO,MAAM,gBAAgB,QAAQ,UAAU,EAAE,GAE7C,QAAQ,eAAe,KACzB,OAAO,MAAM,aAAa,QAAQ,YAAY,EAAE,GAG9C,aACF,OAAO,MAAM,UAAU,GACvB,OAAO,MAAMC,UAAAA,QAAQ,KAAK,MAAM,QAAQ,OAAO,GAAG,EAAC,QAAQ,GAAK,CAAA,CAAC,IAG/D,YAAY,QAAQ,aACtB,OAAO,MAAM,WAAW,GACxB,QAAQ,SAAS,QAAQ,CAAC,YAAY;AAEpC,UAAM,SAAS,MADF,QAAQ,UAAU,QAAQ,WAAW,GAAG,CAC5B;AAEzB,QAAI,QAAQ;AACH,aAAA,MAAM,GAAG,MAAM,IAAI,MAAM,OAAO,SAAS,CAAC,EAAE;AAAA,aAC1C,QAAQ,WAAW;AAC5B,YAAM,UAAU,cAAc,SAAS,EAAC,aAAa,IAAK;AACnD,aAAA,MAAM,GAAG,MAAM,IAAI,MAAM,OAAO,YAAY,OAAO,EAAE,CAAC,EAAE;AAAA,IACjE;AACS,aAAA,MAAM,GAAG,MAAM,kBAAkB,QAAQ,UAAU,KAAK,QAAQ,QAAQ,KAAK;AAAA,EAEvF,CAAA,IAIH,OAAO,MAAM,EAAE;AACjB;AC/HA,MAAM,mBAAyC;AAAA,EAC7C,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX,UAAU;AAAA,EACV,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,OAAA,IAAU,SACtB,SAAS;AAEX,QAAA;AACA,QAAA;AACF,cAAQ,MAAM,OACX,MAAM,EACN,OAAO,EAAC,YAAY,aAAY,CAAC,EACjC,QAAgB,EAAC,KAAK,SAAS,CAAA;AAAA,aAC3B,KAAK;AACZ,YAAM,IAAI,MAAM;AAAA,EAAgC,IAAI,OAAO,EAAE;AAAA,IAC/D;AAEM,UAAA,QAAQ,CAAC,SAAS;AACtB,aAAO,MAAM,SAAS,KAAK,IAAI,EAAE,GACjC,OAAO,MAAM,YAAY,KAAK,OAAO,EAAE,GACvC,OAAO,MAAM,QAAQ,KAAK,GAAG,EAAE,GAE3B,KAAK,SAAS,eAChB,OAAO,MAAM,gBAAgB,KAAK,UAAU,EAAE,GAE1C,KAAK,eACP,OAAO,MAAM,gBAAgB,KAAK,WAAW,EAAE,IAInD,OAAO,MAAM,EAAE;AAAA,IAAA,CAChB;AAAA,EACH;AACF,GCxCa,uBAAuB,cACvB,8BAA8B,CAAC,OAAO,MAAM,MAAM,KAAK,GCDvD,kBAAkB,CAAC;AAAA,EAC9B;AAAA,EACA;AACF,MAGM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOM,aAAa;AAAA,EAEvB,cAAc,SAAS,IACnB,qBAAqB,cAAc,IAAI,CAAC,MAAM,KAAK,UAAU,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC;AAAA,IAC3E,EACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GClBa,gBAAgB,CAAC;AAAA,EAC5B;AAAA,EACA;AACF,MAGM;AAAA;AAAA;AAAA,YAGM,aAAa;AAAA,EAEvB,cAAc,SAAS,IACnB,qBAAqB,cAAc,IAAI,CAAC,MAAM,KAAK,UAAU,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC;AAAA,IAC3E,EACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCda,cAAc,CAAC;AAAA,EAC1B;AAAA,EACA;AACF,MAGM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMM,aAAa;AAAA,EAEvB,cAAc,SAAS,IACnB,qBAAqB,cAAc,IAAI,CAAC,MAAM,KAAK,UAAU,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC;AAAA,IAC3E,EACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCjBa,aAAa,CAAC;AAAA,EACzB;AAAA,EACA;AACF,MAGM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMM,aAAa;AAAA,EAEvB,cAAc,SAAS,IACnB,qBAAqB,cAAc,IAAI,CAAC,MAAM,KAAK,UAAU,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC;AAAA,IAC3E,EACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCjBa,cAAc,CAAC;AAAA,EAC1B;AAAA,EACA;AACF,MAGM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMM,aAAa;AAAA,EAEvB,cAAc,SAAS,IACnB,qBAAqB,cAAc,IAAI,CAAC,MAAM,KAAK,UAAU,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC;AAAA,IAC3E,EACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCHMrE,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAYX,YAAY;AAAA,EAChB,EAAC,MAAM,6CAA6C,UAAU,cAAa;AAAA,EAC3E,EAAC,MAAM,yBAAyB,UAAU,WAAU;AAAA,EACpD,EAAC,MAAM,kBAAkB,UAAU,YAAW;AAAA,EAC9C,EAAC,MAAM,yCAAyC,UAAU,YAAW;AAAA,EACrE;AAAA,IACE,MAAM;AAAA,IACN,UAAU;AAAA,EACZ;AACF,GAEM,yBAAqE;AAAA,EACzE,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,QAAQ,QAAQ,SAAS,UAAS;AAErC,QAAA,CAAC,KAAK,IAAI,KAAK;AAEnB,WAAO,EAAC,SAAO,QAAA,MAAA,KAAA;AACL,cAAA,MAAM,OAAO,OAAO;AAAA,QAC1B,MAAM;AAAA,QACN,QAAQ;AAAA,QACR,SAAS;AAAA,MAAA,CACV,GACI,MAAM,KAAK,KACd,OAAO,MAAM,MAAM,IAAI,sBAAsB,CAAC;AAG5C,UAAAsE,SAAQ,MAAM,OAAO,OAAO;AAAA,MAChC,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IAAA,CACV,GAEK,kBAAkB,OAAO,YAAY,UAAU,IAAI,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,GACtE,WAAW,MAAM,OAAO,OAAO;AAAA,MACnC,MAAM;AAAA,MACN,SAAS;AAAA,MACT,SAAS,UAAU,IAAI,CAAC,qBAAqB;AAAA,QAC3C,MAAM,gBAAgB;AAAA,QACtB,OAAO,gBAAgB;AAAA,MAAA,EACvB;AAAA,IAAA,CACH,GAEK,cAAcC,gBAAAA,QAAO,MAAM,YAAY,CAAC,EAC3C,QAAQ,QAAQ,GAAG,EACnB,QAAQ,eAAe,EAAE,GAEtB,UAAU3D,cAAAA,QAAK,KAAK,SAAS,sBAAsB,WAAW;AACpE,QAAIgB,cAAW,OAAO,KAElB,CAAE,MAAM,OAAO,OAAO;AAAA,MACpB,MAAM;AAAA,MACN,SAAS,uBAAuB,MAAM,KAAK,OAAO,CAAC;AAAA,MACnD,SAAS;AAAA,IAAA,CACV;AAED;AAGJL,OAAAA,UAAU,SAAS,EAAC,WAAW,GAAK,CAAA;AAEpC,UAAM,oBAAoB,gBAAgB,QAAQ,EAAE,YAAY,eAAe;AAAA,MAC7E,eAAe;AAAA,MACf,eAAe+C,OACZ,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAA,CAAM,EACnB,OAAO,OAAO;AAAA,IAAA,CAClB,GAEK,iBAAiB1D,cAAK,QAAA,KAAK,SAAS,UAAU;AAE9C,UAAA4D,eAAU,gBAAgB,gBAAgB,GAEhD,OAAO,MAAM,GACb,OAAO,MAAM,GAAG,MAAM,MAAM,QAAG,CAAC,qBAAqB,GACrD,OAAO,MAAA,GACP,OAAO,MAAM,aAAa,GAC1B,OAAO;AAAA,MACL,QAAQ,MAAM;AAAA,QACZ;AAAA,MACD,CAAA;AAAA,OAEH,OAAO;AAAA,MACL;AAAA,IAAkC,MAAM;AAAA,QACtC,wBAAwB,WAAW;AAAA,MACpC,CAAA;AAAA,OAEH,OAAO;AAAA,MACL;AAAA,KAAiD,MAAM;AAAA,QACrD,wBAAwB,WAAW;AAAA,MACpC,CAAA;AAAA,IAEH,GAAA,OAAO,SACP,OAAO;AAAA,MACL,+DAAwD,MAAM;AAAA,QAC5D;AAAA,MAAA,CACD;AAAA,IAAA;AAAA,EAEL;AACF;AC3FgB,SAAA,uBACd,SACA,eAC2B;AAC3B,SAAO,CAAC,eAAe5D,sBAAK,KAAK,eAAe,OAAO,CAAC,EAAE;AAAA,IAAQ,CAAC,aACjE,4BAA4B,IAAI,CAAC,QAAQ;AACvC,YAAM,eAAeA,cAAAA,QAAK,KAAK,sBAAsB,GAAG,QAAQ,IAAI,GAAG,EAAE,GACnE,eAAeA,cAAAA,QAAK,QAAQ,SAAS,YAAY;AACnD,UAAA;AACA,UAAA;AAEF,cAAM,QAAQ,YAAY;AAAA,eACnB,KAAK;AACZ,YAAI,IAAI,SAAS;AACf,gBAAM,IAAI,MAAM,UAAU,IAAI,OAAO,GAAG;AAAA,MAE5C;AACO,aAAA,EAAC,cAAc,cAAc;IAAG,CACxC;AAAA,EAAA;AAEL;AASO,SAAS,0BACd,QAC6C;AACzC,MAAA,OAAO,OAAO,MAAQ,OAAe,CAACiD,uBAAAA,QAAc,OAAO,IAAI,OAAO;AACjE,WAAA;AAGH,QAAA,MAAM,OAAO,IAAI;AACvB,SAAO,OAAO,IAAI,SAAU,YAAY,IAAI,YAAY;AAC1D;AClEA,MAAM7D,aAAW,IAEX,uBAA6C;AAAA,EACjD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,GAAG,YAAY;AAC5B,UAAM,EAAC,SAAS,QAAQ,MAAA,IAAS;AAC7B,QAAA;AACI,YAAA,aAAa,MAAM,kBAAkB,OAAO;AAE9C,UAAA,WAAW,WAAW,GAAG;AACpB,eAAA,MAAM,yDAAyD,GACtE,OAAO;AAAA,UACL;AAAA,MAAS,MAAM,MAAM,kCAAoC,CAAC;AAAA,QAAA;AAE5D;AAAA,MACF;AAEM,YAAA,QAAQ,IAAI8B,0BAAM;AAAA,QACtB,OAAO,SAAS,WAAW,MAAM;AAAA,QACjC,SAAS;AAAA,UACP,EAAC,MAAM,MAAM,OAAO,MAAM,WAAW,OAAM;AAAA,UAC3C,EAAC,MAAM,SAAS,OAAO,SAAS,WAAW,OAAM;AAAA,QACnD;AAAA,MAAA,CACD;AAEU,iBAAA,QAAQ,CAAC,qBAAqB;AACjC,cAAA,OAAO,EAAC,IAAI,iBAAiB,IAAI,OAAO,iBAAiB,UAAU,MAAA,CAAM;AAAA,MAAA,CAChF,GACD,MAAM,cACN,OAAO,MAAM,sDAAsD;AAAA,aAC5D,OAAO;AACV,UAAA,MAAM,SAAS,UAAU;AACpB,eAAA,MAAM,2CAA2C,GACxD,OAAO;AAAA,UACL;AAAA,MAAS,MAAM,MAAM,kCAAoC,CAAC;AAAA,QAAA;AAE5D;AAAA,MACF;AACA,YAAM,IAAI,MAAM,+CAA+C,MAAM,OAAO,EAAE;AAAA,IAChF;AAAA,EACF;AACF;AAmBA,eAAsB,kBAAkB,SAA+C;AACjF,MAAA;AAEF,eAAa2C,KAAAA,SAAS;AAAA,IACpB,QAAQ,OAAO,QAAQ,QAAQ,MAAM,CAAC,CAAC;AAAA,EACxC,CAAA,EAAE;AAGL,QAAM,gBAAgB7D,cAAAA,QAAK,KAAK,SAAS,oBAAoB,GACvD,mBAAmB,MAAM8D,KAAQ,QAAA,eAAe,EAAC,eAAe,GAAA,CAAK,GAErE,aAAkC;AACxC,aAAW,SAAS,kBAAkB;AACpC,UAAM,YAAY,MAAM,YAAA,IAAgB,MAAM,OAAO,+BAA+B,MAAM,IAAI,GACxF,aAAa,uBAAuB,SAAS,SAAS,EAAE,OAAO,yBAAyB;AAE9F,eAAW,aAAa;AACtB,iBAAW,KAAK;AAAA,QACd,IAAI;AAAA,QACJ,WAAW,UAAU,IAAI;AAAA,MAAA,CAC1B;AAAA,EAEL;AAEI,SAAA,cACF,WAGK,GAAA;AACT;AAEA,SAAS,+BAA+B,UAAkB;AAExD,SAAO,4BAA4B;AAAA,IACjC,CAAC,MAAM,QAAS,KAAK,SAAS,IAAI,GAAG,EAAE,IAAI9D,sBAAK,SAAS,MAAM,IAAI,GAAG,EAAE,IAAI;AAAA,IAC5E;AAAA,EAAA;AAEJ;AChHA,IAAe,iBAAA;AAAA,EACb,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf;ACDA,SAAS,aAAaA,OAAoB;AACpC,MAAA,CAAC,MAAM,QAAQA,KAAI;AACf,UAAA,IAAI,MAAM,sBAAsB;AAGxC,SAAOA,MAAK,OAAe,CAAC,QAAQ,SAAS,MAAM;AACjD,QAAI+D,MAAAA,eAAe,OAAO;AACjB,aAAA,GAAG,MAAM,IAAI,OAAO;AAGzB,QAAAC,mBAAa,OAAO,KAAK,QAAQ;AACnC,aAAO,GAAG,MAAM,WAAW,QAAQ,IAAI;AAGrC,QAAAC,MAAAA,aAAa,OAAO,GAAG;AACnB,YAAA,CAAC,MAAM,EAAE,IAAI;AACnB,aAAO,GAAG,MAAM,IAAI,IAAI,IAAI,EAAE;AAAA,IAChC;AAEA,QAAI,OAAO,WAAY;AAEd,aAAA,GAAG,MAAM,GADE,MAAM,IAAI,KAAK,GACL,GAAG,OAAO;AAGxC,UAAM,IAAI,MAAM,8BAA8B,KAAK,UAAU,OAAO,CAAC,IAAI;AAAA,KACxE,EAAE;AACP;AAgBa,MAAA,eAAe,CAAC,WAA2C,CAAA,GAAI,QAAQ,MAC3E,OAAO,QAAQ,QAAQ,EAC3B;AAAA,EAAI,CAAC,CAAC,KAAK,KAAK,MACf,KAAK,IAAI,IAAI,SAAS,QAAQ,GAAG,aAAa,MAAM,UAAU,QAAQ,CAAC,CAAC;AAC1E,EACC,OAAO,CAAC,KAAK,SAAU,OAAO,MAAM,OAAO,KAAM,CAAC,GAc1C,aAAa,CAAwB;AAAA,EAChD,MAAAC,QAAO,CAAC;AAAA,EACR;AAAA,EACA,QAAAC,UAAS;AAAA,EACT,UAAU,YAAY,CAAC,EAAC,MAAW,MAAA;AAAA,EACnC;AACF,MAA6B;AACrB,QAAA,UAAU,OAAO,QAAQD,KAAI;AAEnC,SAAO,QACJ,IAAI,CAAC,CAAC,KAAK,KAAK,GAAG,UAAU;AAC5B,UAAM,SAAS,UAAU,QAAQ,SAAS,GACpC,aAAa,GAAGC,OAAM,GAAG,SAAS,OAAO,SAAI,IAC7C,SAAS,UAAU,KAAK,GAExB,SAAS,WAAW;AAAA,MACxB,MAAM,MAAM;AAAA,MACZ;AAAA,MACA,QAAQ;AAAA,MACR,UAAU;AAAA,MACV;AAAA,IAAA,CACD;AAED,QAAI,EAAC,UAAQ,QAAA,OAAA;AAEX,aAAO,CADS,GAAGA,OAAM,GAAG,SAAS,WAAM,QAAG,UAAK,GAAG,IACrC,MAAM,EAAE,OAAO,OAAO,EAAE,KAAK;AAAA,CAAI;AAG9C,UAAA,CAAC,OAAO,GAAG,IAAI,IAAI,QACnB,eAAe,IAAI,OAAO,gBAAgBA,QAAO,SAAS,IAAI,MAAM,GACpE,QAAQ,SAAS,WAAM,UACvB,oBAAoB,IAAI,OAAO,gBAAgBA,QAAO,SAAS,CAAC,GAEhE,eAAe,GAAGA,OAAM,GAAG,KAAK,UAAK,GAAG,IAAI,YAAY,IAAI,WAAW,KAAK,CAAC,IAC7E,qBAAqB,KACxB,IAAI,CAAC,WAAW,GAAG,UAAU,GAAG,iBAAiB,IAAI,WAAW,MAAM,CAAC,EAAE,EACzE,KAAK;AAAA,CAAI;AAGL,WAAA,CADS,CAAC,cAAc,kBAAkB,EAAE,OAAO,OAAO,EAAE,KAAK;AAAA,CAAI,GAC3D,MAAM,EAAE,OAAO,OAAO,EAAE,KAAK;AAAA,CAAI;AAAA,EAAA,CACnD,EACA,KAAK;AAAA,CAAI;AACd;AAMO,SAAS,cAA2C,OAA2B;AACpF,QAAM,OAAmB,CAAA;AAGhB,WAAA,QAAQD,OAAY,OAAmB,MAAM;AAEhD,QAAA,CAACA,MAAK,KAAK,QAAQ;AAChB,WAAK,UAAO,KAAK,QAAQ,CAAA,IAG9B,KAAK,MAAM,KAAKA,KAAI;AACpB;AAAA,IACF;AAEM,UAAA,CAAC,SAAS,GAAG,IAAI,IAAIA,MAAK,MAC1B,MAAM,aAAa,CAAC,OAAO,CAAC;AAG7B,SAAK,aAAU,KAAK,WAAW,KAC9B,OAAO,KAAK,aAAW,KAAK,SAAS,GAAG,IAAI,CAAA,IAElD,QAAQ,EAAC,GAAGA,OAAM,MAAM,KAAA,GAAO,KAAK,SAAS,GAAG,CAAC;AAAA,EACnD;AAEW,aAAAA,SAAQ,MAAO,SAAQA,KAAI;AAC/B,SAAA;AACT;AC/HA,MAAM,QAAQE,SAAAA,OAAO,CAAC;AASf,SAAS,aAAa;AAAA,EAC3B;AAAA,EACA;AAAA,EACA;AAAA,EACA,aAAa;AACf,GAAkF;AAChF,UAAQ,MAAM,QAAQ,OAAO,IAAI,UAAU,CAAC,OAAO,GAChD,IAAI,CAAC,iBACA,aAAa,SAAS,gBACjB;AAAA,IACL;AAAA,MACE,MAAM,eAAe,QAAQ,KAAK;AAAA,MAClC,OAAO,aAAa,KAAO,MAAc,OAAO,MAAM,UAAU,aAAa,EAAE;AAAA,IAE9E,EAAA,OAAO,OAAO,EACd,KAAK,GAAG;AAAA,IACX;AAAA,MACE,aAAa;AAAA,QACX;AAAA,QACA,SAAS,aAAa;AAAA,QACtB;AAAA,QACA;AAAA,MAAA,CACD;AAAA,IACH;AAAA,IACA,KAAK;AAAA;AAAA,CAAM,IAER,qBAAqB;AAAA,IAC1B;AAAA,IACA,SAAS;AAAA,IACT;AAAA,IACA;AAAA,EAAA,CACD,CACF,EACA,KAAK;AAAA;AAAA,CAAM;AAChB;AAEA,SAAS,cAAc,KAAqC;AAC1D,SAAO,OAAO,OAAQ,WAAW,MAAM,IAAI;AAC7C;AAEA,SAAS,WAAW,OAAc,SAAyB;AAClB,SAAA;AAAA,IACrC,MAAM,MAAM,QAAQ;AAAA,IACpB,aAAa,MAAM,QAAQ,MAAM;AAAA,IACjC,kBAAkB,MAAM,SAAS,MAAM;AAAA,IACvC,aAAa,MAAM,MAAM,MAAM;AAAA,IAGnB,OAAO;AACvB;AAEA,SAAS,MAAM,OAAe,SAAkB,OAAsB;AAC/D,SAAA,QAIE,WAAW,OAAO,OAAO,EAAE,IAAI,KAAK,GAAG,IAHrC,IAAI,KAAK;AAIpB;AAEA,MAAM,iBAAmD;AAAA,EACvD,QAAQ;AAAA,EACR,mBAAmB;AAAA,EACnB,iBAAiB;AAAA,EACjB,QAAQ;AAAA,EACR,OAAO;AACT;AAEA,SAAS,WAAW,UAAwC;AAC1D,MAAI,QAAQ;AACV,WAAO,SAAS;AAGlB,MAAI,cAAc;AAChB,WAAO,SAAS,SAAS;AAI7B;AAEA,MAAM,gBAAgB,IAAI,KAAK,WAAW,SAAS;AAAA,EACjD,MAAM;AACR,CAAC;AAED,SAAS,eAAe,OAAc,UAAoB,WAA8B;AAxGxF,MAAA;AAyGE,QAAM,eAAe,MAAM,SAAS,MAAM,eAAe,SAAS,IAAI,GAAG,KAAK,GAExE,eACJ,cAAc,YAAY,UAAU,gBAChC;AAAA,IACE,cAAc,WACV,SAAS,SAAS,QAClB,cAAc,QAAO,KAAU,UAAA,kBAAV,OAA2B,KAAA,CAAA,CAAE;AAAA,IACtD;AAAA,IACA;AAAA,EAEF,IAAA;AAGN,SAAO,CAAC,cAAc,cAAc,MAAM,UAAU,WAAW,QAAQ,CAAC,CAAC,EACtE,OAAO,OAAO,EACd,KAAK,GAAG;AACb;AAEO,SAAS,qBAAqB;AAAA,EACnC;AAAA,EACA;AAAA,EACA;AAAA,EACA,aAAa;AACf,GAAuC;AAjIvC,MAAA;AAkIE,QAAM,OACJ,aAAa,UAAU,MAAM,KAAK,kBAAiB,KAAQ,QAAA,YAAR,OAAiB,SAAA,GAAA,UAAU,GAAG,IAAI,IACjF,SAAS,CAAC,eAAe,OAAO,SAAS,SAAS,GAAG,IAAI,EAAE,KAAK,GAAG,GACnE,UAAU,IAAI,OAAO,UAAU;AAErC,MACE,QAAQ,SAAS,YACjB,QAAQ,SAAS,uBACjB,QAAQ,SAAS;AAEjB,WAAO,CAAC,QAAQ;AAAA,GAAM,OAAO,KAAK,UAAU,QAAQ,UAAU,MAAM,CAAC,GAAG,UAAU,CAAC,EAAE,KAAK,EAAE;AAG1F,MAAA,QAAQ,SAAS,SAAS;AAC5B,UAAM,OAAO,cAAyB,QAAQ,QAAQ,KAAM,CAAA,GACtD,gBAAgB,KAAK,IAAI,aAAa,KAAK,QAAQ,IAAI,GAAG,EAAE;AAE3D,WAAA;AAAA,MACL;AAAA,MACA;AAAA;AAAA,MACA,WAAsB;AAAA,QACpB,MAAM,KAAK;AAAA,QACX;AAAA,QACA,QAAQ;AAAA,QACR,YAAY,CAAC,UAAU,oBAAoB,OAAO,KAAK;AAAA,MAAA,CACxD;AAAA,IAAA,EACD,KAAK,EAAE;AAAA,EACX;AAEO,SAAA;AACT;AAEA,SAAS,oBAAoB,OAAc,OAA0B;AAC7D,QAAA,EAAC,GAAM,IAAA,OACP,gBAAgB,MAAM,KAAK,GAAG,IAAI;AACxC,MAAI,GAAG,SAAS;AACd,WAAO,GAAG,MAAM,IAAI,aAAa,CAAC;AAEpC,MAAI,GAAG,SAAS;AACd,WAAO,GAAG,MAAM,OAAO,aAAa,CAAC,IAAI,GAAG,KAAK;AAEnD,MAAI,GAAG,SAAS,SAAS,GAAG,SAAS;AACnC,WAAO,GAAG,MAAM,OAAO,aAAa,CAAC,IAAI,GAAG,MAAM;AAEpD,MAAI,GAAG,SAAS;AACP,WAAA,GAAG,MAAM,OAAO,aAAa,CAAC,IAAI,KAAK,UAAU,GAAG,KAAK,CAAC;AAEnE,MAAI,GAAG,SAAS;AACP,WAAA,GAAG,MAAM,MAAM,aAAa,CAAC,IAAI,KAAK,UAAU,GAAG,KAAK,CAAC;AAElE,MAAI,GAAG,SAAS;AACP,WAAA,GAAG,MAAM,MAAM,aAAa,CAAC,IAAI,GAAG,QAAQ,KAAK;AAAA,MACtD,GAAG;AAAA,IAAA,CACJ,KAAK,KAAK,UAAU,GAAG,KAAK,CAAC;AAEhC,MAAI,GAAG,SAAS;AACP,WAAA,GAAG,MAAM,OAAO,aAAa,CAAC,IAAI,cAAc,GAAG,aAAa,CAAC,KAAK,KAAK;AAAA,MAChF,GAAG;AAAA,IACJ,CAAA;AAEH,MAAI,GAAG,SAAS;AACP,WAAA,GAAG,MAAM,IAAI,aAAa,CAAC,IAAI,GAAG,UAAU,KAAK,GAAG,QAAQ;AAGrE,QAAM,IAAI,MAAM,2BAA2B,GAAG,IAAI,EAAE;AACtD;AAEA,SAAS,OAAO,SAAiBhE,QAAO,GAAW;AAC3C,QAAA,UAAU,IAAI,OAAOA,KAAI;AAE/B,SAAO,QACJ,MAAM;AAAA,CAAI,EACV,IAAI,CAAC,SAAS,UAAU,IAAI,EAC5B,KAAK;AAAA,CAAI;AACd;ACtLA,MAAMhB,aAAW;AAAA;AAAA;AAAA,oGAGmFiF,QAAwB,wBAAA,cAAcC,oCAA4B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA6BtK,SAAS,cAAc,MAAyB;AAC9C,SAAO/D,eAAM,QAAAC,QAAA,QAAQ,KAAK,QAAQ,QAAQ,IAAI,EAAE,MAAM,CAAC,CAAC,EACrD,QAAQ,WAAW,EAAC,MAAM,WAAW,SAAS,GAAK,CAAA,EACnD,QAAQ,eAAe,EAAC,MAAM,UAAU,SAAS8D,QAAAA,6BAA6B,CAAA,EAC9E,QAAQ,YAAY,EAAC,MAAM,WAAW,SAAS,GAAI,CAAC,EACpD,QAAQ,WAAW,EAAC,MAAM,SAAQ,CAAC,EACnC,QAAQ,eAAe,EAAC,MAAM,SAAS,CAAA,EACvC,QAAQ,WAAW,EAAC,MAAM,SAAS,CAAA,EACnC,QAAQ,WAAW,EAAC,MAAM,WAAW,SAAS,GAAK,CAAA,EAAE;AAC1D;AAEA,MAAM,sBAAyD;AAAA,EAC7D,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXlF;AAAAA,EACA,aAAa;AAAA;AAAA,EAEb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,QAAQ,QAAQ,OAAO,QAAO,IAAI,SAC9C,CAAC,EAAE,IAAI,KAAK,oBACZ,0BAA0BY,sBAAK,KAAK,SAAS,oBAAoB,GAEjE,QAAQ,MAAM,cAAc,IAAI,GAEhC,aAAa,MAAM,YACnB,MAAM,MAAM,QACZ,UAAU,MAAM,SAChB,UAAU,MAAM;AAEtB,QAAK,WAAW,CAAC,WAAa,WAAW,CAAC;AAClC,YAAA,IAAI,MAAM,qEAAqE;AAGvF,QAAI,CAAC,IAAI;AACP,aAAO,MAAM,MAAM,IAAI,sCAAsC,CAAC;AAC9D,YAAM,aAAa,MAAM,kBAAkB,OAAO,GAC5C,QAAQ,IAAIkB,0BAAM;AAAA,QACtB,OAAO;AAAA,QACP,SAAS;AAAA,UACP,EAAC,MAAM,MAAM,OAAO,MAAM,WAAW,OAAM;AAAA,UAC3C,EAAC,MAAM,SAAS,OAAO,SAAS,WAAW,OAAM;AAAA,QACnD;AAAA,MAAA,CACD;AAEU,iBAAA,QAAQ,CAAC,qBAAqB;AACjC,cAAA,OAAO,EAAC,IAAI,iBAAiB,IAAI,OAAO,iBAAiB,UAAU,MAAA,CAAM;AAAA,MAAA,CAChF,GACD,MAAM,cACN,OAAO,MAAM,sDAAsD;AAEnE;AAAA,IACF;AAGW2C,kBAAA;AAAA,MACP,QAAQ,OAAO,QAAQ,QAAQ,MAAM,CAAC,CAAC;AAAA,IAAA,CACxC;AAGG,UAAA,aAAa,uBAAuB,SAAS,EAAE,GAC/C,kBAAkB,WAAW,OAAO,yBAAyB;AAEnE,QAAI,gBAAgB,SAAS;AAE3B,YAAM,IAAI;AAAA,QACR,kCAAkC,EAAE,QAAQ,MAAM,KAAK,uBAAuB,CAAC;AAAA,KAAU,WACtF,IAAI,CAAC,cAAc7D,cAAAA,QAAK,SAAS,yBAAyB,UAAU,YAAY,CAAC,EACjF,KAAK;AAAA,IAAO,CAAC;AAAA,MAAA;AAId,UAAA,SAAS,gBAAgB,CAAC;AAChC,QAAI,CAAC;AACH,YAAM,IAAI;AAAA,QACR,2BAA2B,EAAE,QAAQ,MAAM,KAAK,MAAM,KAAK,uBAAuB,CAAC,CAAC;AAAA;AAAA;AAAA,KAC1D,WAC9B,IAAI,CAAC,cAAcA,cAAAA,QAAK,SAAS,yBAAyB,UAAU,YAAY,CAAC,EACjF,KAAK;AAAA,IAAO,CAAC;AAAA,MAAA;AAIb,UAAM,MAAM,OAAO;AACf,QAAA,QAAQ,OAAO,UAAU;AAG3B,YAAM,IAAI;AAAA,QACR;AAAA,MAAA;AAIJ,UAAM,YAAuB,IAAI;AAEjC,QAAI,cAAc,CAAC;AACX,YAAA,IAAI,MAAM,wDAAwD;AAG1E,UAAM,cAAc,MAAM;AAC1B,QAAI,gBAAgB,QAAW;AAC7B,UAAI,cAAcqE,QAAA;AAChB,cAAM,IAAI;AAAA,UACR,oDAAoDA,QAAAA,wBAAwB;AAAA,QAAA;AAIhF,UAAI,gBAAgB;AAClB,cAAM,IAAI,MAAM,8CAA8C,WAAW,EAAE;AAAA,IAE/E;AAEA,UAAM,gBAAgB,UAAU;AAAA,MAC9B,aAAa;AAAA,MACb,gBAAgB;AAAA,IAAA,CACjB,EAAE,OAAO,GAEJ,YAAY;AAAA,MAChB,SAAS,4BAAW,cAAc;AAAA,MAClC,WAAW,4BAAW,cAAc;AAAA,MACpC,SAAS,cAAc;AAAA,MACvB,OAAO,cAAc;AAAA,MACrB,YAAY;AAAA,IAAA;AAEd,QAAI,KAAK;AACO;AACd;AAAA,IACF;AAkBA,QAhBA,OAAO;AAAA,MACL;AAAA,EAAK,MAAM,OAAO,MAAM,KAAK,qDAAqD,CAAC,CAAC;AAAA,OAEtF,OAAO;AAAA,MACL,wDAAwD,MAAM,KAAK,eAAe,CAAC;AAAA;AAAA,IAInF,IAAA,MAAM,WACL,MAAM,OAAO,OAAgB;AAAA,MAC5B,SAAS,kCAAkC,MAAM;AAAA,QAC/C,MAAM,KAAK,UAAU,OAAO;AAAA,MAAA,CAC7B,eAAe,MAAM,OAAO,MAAM,KAAK,UAAU,SAAS,CAAC,CAAC;AAAA,MAC7D,MAAM;AAAA,IAAA,CACP,OAEc,IAAO;AACtBnF,cAAM,wBAAwB;AAC9B;AAAA,IACF;AAEA,UAAM,UAAU,OAAO,QAAQ,sBAAsB,EAAE,GAAG,EAAE;AAC5D,UAAMqF,QAAI,IAAA,EAAC,KAAK,WAAW,aAAa,YAAY,eAAe,OAAO,EAAC,GAAG,SAAS,GACvF,QAAQ,KAAK;AAEb,aAAS,eAAe,iBAAoD;AAC1E,aAAO,SAAoBhF,WAA6B;AAClD,YAAA,CAAC,MAAM,UAAU;AACnB,0BAAgB,KAAK;AACrB;AAAA,QACF;AACA,YAAIA,UAAS,MAAM;AACD,0BAAA,OAAO,cAAc,EAAE;AAAA;AAAA,iBAEhC,MAAM,KAAK,UAAU,SAAS,CAAC;AAAA,iBAC/B,MAAM,KAAK,UAAU,OAAO,CAAC;AAAA;AAAA,IAE1CA,UAAS,SAAS;AAAA,IAClBA,UAAS,SAAS;AAAA,IAClB,MAAM,MAAMA,UAAS,sBAAsB,MAAM,CAAC,4BAC5C,gBAAgB,eAAe,EAAC,QAAQ,MAAM,MAAM,QAAG,GAAE;AACzD;AAAA,QACF;AAEC,SAAC,MAAM,GAAGA,UAAS,mBAAmB,EAAE,QAAQ,CAAC,gBAAgB;AAjO1E,cAAA;AAkOU,0BAAgB,OAAO,sBAAsB,EAAE,KAAK,MAAM,mBAAmB,KAAK;AAAA;AAAA,oBAExE,MAAM,KAAK,UAAU,SAAS,CAAC;AAAA,oBAC/B,MAAM,KAAK,UAAU,OAAO,CAAC;AAAA,oBAC7B,MAAM,MAAK,KAAA,UAAU,kBAAV,OAAyB,SAAA,GAAA,KAAK,IAAI,CAAC;AAAA;AAAA,IAE9DA,UAAS,SAAS;AAAA,IAClBA,UAAS,SAAS;AAAA,IAClB,MAAM,KAAKA,UAAS,OAAO,CAAC;AAAA,IAC5B,MAAM,MAAMA,UAAS,sBAAsB,MAAM,CAAC;AAAA;AAAA,IAGlD,eAAe,CAACA,UAAS,OACrB,QAAK,aAAa,EAAC,OAAO,SAAS,aAAa,WAAW,YAAY,EAAE,CAAA,CAAC,KAC1E,EACN;AAAA,QAAA,CACO;AAAA,MAAA;AAAA,IAEL;AAEA,mBAAe,gBAAgB;AAC7B,aAAO,MAAM,sBAAsB,EAAE,eAAe,GAEhD,cACF,OAAO,MAAM,gBAAgB,MAAM,KAAK,UAAU,CAAC,EAAE,GAGvD,OAAO,MAAM,GACb,OAAO,MAAM,gBAAgB,MAAM,KAAK,UAAU,SAAS,CAAC,EAAE,GAC9D,OAAO,MAAM,gBAAgB,MAAM,KAAK,UAAU,OAAO,CAAC,EAAE;AAE3C,uBAAA,YAAYiF,QAAAA,OAAO,EAAC,KAAK,WAAW,YAAY,cAAa,SAAS;AAChF,qBACL,OAAO,MAAM,GACb,OAAO;AAAA,UACL,aAAa;AAAA,YACX;AAAA,YACA,SAAS;AAAA,YACT;AAAA,UAAA,CACD;AAAA,QAAA;AAAA,IAGP;AAAA,EACF;AACF,GCtQMpF,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcX,iBAAuC;AAAA,EAC3C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OACN,MACA,aAEsB,MAAMqF,mBAAiB,GAExB,MAAM,OAAO;AAAA,EAAA,UAEpCrF;AACF;AAEA,eAAeqF,qBAAmB;AAUpB,UAAA,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,oBAAqC;AAAA,EAEnD,CAAA,GAAA;AACb;AChDA,MAAMrB,gBAAc,8EAEdhE,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcX,uBAA6C;AAAA,EACjD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,aACXgE;AAAAA,EAAA,UACAhE;AAAAA,EACA,QAAQ,OAAO,MAAM,aACP,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,oBAAoC;AAAA,MAElD,QAAQ,MAAM,OAAO;AAEpC;AC7BA,IAAe,cAAA;AAAA,EACb,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf;ACHA,MAAM,cAAc,wDAEdA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAiBX,2BAAiD;AAAA,EACrD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX;AAAA,EAAA,UACAA;AAAAA,EACA,QAAQ,OAAO,MAAM,aACP,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,qBAAqC;AAAA,MAEnD,QAAQ,MAAM,OAAO;AAEpC,GC/Ba,gBACX,QAAQ,OAAO,SAAS,QAAQ,IAAI,SAAS,UAAU,EAAE,QAAQ,QAAQ,MCQrEA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcX,eAAqC;AAAA,EACzC,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,QAAQ,OACN,MACA,YACG;AACH,UAAM,EAAC,QAAQ,OAAO,OAAA,IAAU,SAC1B,gBAAgB,MAAM,iBAAiB,GAEvC,OAAO,CAAC,QAAgB,OAAO,KAAK,MAAM,OAAO,QAAQ,GAAG,CAAC,GAC7D,QAAQ,CAAC,QAAgB,OAAO,KAAK,MAAM,IAAI,QAAQ,GAAG,CAAC;AACjE,SAAK,gXAA+D,GACpE,KAAK,yEAA+D,GACpE,KAAK,yEAA+D,GACpE,KAAK,oEAA+D,GACpE,KAAK,yEAA+D,GACpE,KAAK,oEAA+D,GACpE,KAAK,yEAA+D,GACpE,KAAK,yEAA+D,GACpE,KAAK,yEAA+D,GACpE,KAAK,gXAA+D,GACpE,KAAK,EAAE;AAEH,QAAA;AACI,YAAA,cAAc,MAAM,OAAO;AAAA,aAC1B,KAAK;AACZ,UAAI,IAAI,SAAS;AACT,cAAA;AAGF,YAAA,IAAI,OAAO,GACjB,MAAM;AAAA,CAAI,GAGR,iBACC,MAAM,OAAO,OAAO;AAAA,QACnB,SAAS;AAAA,QACT,MAAM;AAAA,MAAA,CACP,IAID,OADkB,MAAM,gBACR,MAAM,OAAO,IAI7B,QAAQ,KAAK,CAAC;AAAA,IAElB;AAAA,EACF;AAAA,EAAA,UACAA;AACF;AAEA,eAAe,mBAAmB;AAUpB,UAAA,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,oBAAqC;AAAA,EAEnD,CAAA,GAAA;AACb;AC1FA,MAAM,mBAAyC;AAAA,EAC7C,MAAM;AAAA,EACN,WAAW;AAAA,EACX,UAAU;AAAA,EACV,aAAa;AAAA,EACb,cAAc;AAAA,EACd,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,QAAQ,OAAO,MAAM,0DAA0D;AAAA,EACvF;AACF;ACXO,SAAS,mBAAmB,SAAiB;AAClD,SAAO,CAAC,QAAsE;AAC5E,UAAI,IAAI,eAAe,QACrB,IAAI,UAAU,UACR;AAAA,EAAA;AAKZ;ACJA,MAAMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAmBX,oBAAuD;AAAA,EAC3D,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EAAA,UACXA;AAAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AAC/B,UAAM,EAAC,WAAW,QAAQ,WAAU,SAC9B,CAAC,aAAa,IAAI,KAAK,oBACvB,QAAQ,KAAK,YAEb,SAAS,UAAY,EAAA,QAAQ,OAAO,EAAC,oBAAoB,IAAO,YAAY,cAAa,GACzF,EAAC,UAAS,IAAI,OAAO,OAAO,GAC5B,SAAS,MAAM,OAAO,QAAgB,EAAC,KAAK,aAAa,SAAS,SAAS,CAAA,GAAG;AAAA,MAClF,CAACsF,UAASA,MAAK;AAAA,IACjB,GACM,QAAQ,iBAAkB,MAAM,eAAe,MAAM,GACrD,eAAe,MAAM,QAAS,MAAM,cAAc,QAAQ,KAAK,GAC/D,OAAO,MAAM,KAAK,CAAC,EAAC,KAAA,MAAU,KAAK,YAAY,MAAM,aAAa,YAAa,CAAA;AACrF,QAAI,CAAC;AACH,YAAM,IAAI,MAAM,cAAc,YAAY,aAAa;AAGnD,UAAA,OACH,MAAM,EACN,QAAQ;AAAA,MACP,QAAQ;AAAA,MACR,KAAK,wBAAwB,SAAS;AAAA,MACtC,MAAM,EAAC,OAAO,MAAM,KAAK,KAAI;AAAA,MAC7B,cAAc;AAAA,MACd,cAAc;AAAA,IACf,CAAA,EACA;AAAA,MACC;AAAA,QACE;AAAA,MACF;AAAA,IAAA,GAGJ,OAAO,MAAM,sBAAsB,KAAK,EAAE;AAAA,EAC5C;AACF;AAIA,SAAS,eAAe,QAAsC;AAC5D,SAAO,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAAS;AAAA,IACT,QAAQ,CAAC,QAAQ,IAAI,KAAK;AAAA,IAC1B,UAAU,CAAC,SACL,CAAC,QAAQ,CAAC,KAAK,SAAS,GAAG,IACtB,kBAGF;AAAA,EAAA,CAEV;AACH;AAEA,SAAS,cAAc,QAAqB,OAAgC;AAC1E,SAAO,OAAO,OAAO;AAAA,IACnB,MAAM;AAAA,IACN,SAAS;AAAA,IACT,SAAS,MAAM,IAAI,CAAC,UAAU;AAAA,MAC5B,OAAO,KAAK;AAAA,MACZ,MAAM,GAAG,KAAK,KAAK,KAAK,KAAK,WAAW;AAAA,IAAA,EACxC;AAAA,EAAA,CACH;AACH;ACvFA,MAAM,aAAa,CAAC,MAAM,QAAQ,QAAQ,MAAM,GAE1C,WAAW;AAAA;AAAA;AAAA;AAAA,mDAIkC,WAAW,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAclE,mBAAyC;AAAA,EAC7C,MAAM;AAAA,EACN,OAAO;AAAA,EACP,WAAW;AAAA,EACX;AAAA,EACA,aAAa;AAAA,EACb,QAAQ,OAAO,MAAM,YAAY;AACzB,UAAA,EAAC,WAAW,QAAQ,UAAS,SAC7B,EAAC,MAAM,OAAO,QAAQ,gBAAe;AAAA,MACzC,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,GAAG,KAAK;AAAA,IAAA;AAGN,QAAA,CAAC,WAAW,SAAS,IAAI;AACrB,YAAA,IAAI,MAAM,wBAAwB,IAAI,qBAAqB,WAAW,KAAK,IAAI,CAAC,EAAE;AAGtF,QAAA,UAAU,SAAS,UAAU;AAC/B,YAAM,IAAI,MAAM,uBAAuB,KAAK,mCAAmC;AAG3E,UAAA,SAAS,aACT,eAAe,OAAO,MAAM,EAAE,OAAO,EAAC,oBAAoB,GAAA,CAAM,GAChE,EAAC,UAAA,IAAa,OAAO,OAAO,GAE5B,eAAe,IACf,CAAC,oBAAoB,OAAO,IAAI,MAAM,QAAQ,IAAI;AAAA,MACtD,cACI,aACG,QAAkB,EAAC,KAAK,wBAAwB,SAAS,IAAI,aAAa,CAAA,EAC1E,KAAK,qBAAqB,IAC7B,CAAC;AAAA,MACL,aAAa,QAAgC,EAAC,KAAK,aAAa,SAAS,IAAI,cAAa;AAAA,IAAA,CAC3F,GAEK,YAAY,QAAQ,QAAQ,IAAI,CAAC,WAAW,OAAO,EAAE,GACrD,QAAQ,MAAM,aACjB,QAAuB,EAAC,KAAK,UAAU,UAAU,KAAK,GAAG,CAAC,IAAI,aAAY,CAAC,EAC3E,KAAK,CAAC,SAAU,MAAM,QAAQ,IAAI,IAAI,OAAO,CAAC,IAAI,CAAE,GASjD,UAAU,CAAC,GAPM,QAAQ,QAC5B,IAAI,CAAC,YAAY;AAAA,MAChB,GAAG;AAAA,MACH,GAAG,aAAa,MAAM,KAAK,CAAC,cAAc,UAAU,OAAO,OAAO,EAAE,CAAC;AAAA,IACrE,EAAA,EACD,OAAO,CAAC,WAAW,CAAC,OAAO,WAAW,MAAM,GAEX,GAAG,kBAAkB,GAEnD,UAAUC,gBAAA;AAAA,MACd,QAAQ,IAAI,CAAC,EAAC,IAAI,MAAM,MAAM,KAAI,MAAM,CAAC,IAAI,MAAM,MAAM,IAAI,CAAC;AAAA,MAC9D,CAAC,WAAW,QAAQ,IAAI,CAAC;AAAA,IAAA,GAGrB,OAAO,UAAU,QAAQ,UAAU,QAAQ,QAE3C,GAAA,YAAY,KAAK;AAAA,MACrB,CAAC,KAAK,QAAQ,IAAI,IAAI,CAAC,SAAS,UAAU,KAAK,IAAIvE,sBAAK,OAAO,GAAG,IAAI,KAAK,CAAC,CAAC;AAAA,MAC7E,WAAW,IAAI,CAAC,QAAQA,cAAA,QAAK,GAAG,CAAC;AAAA,IAAA,GAG7B,WAAW,CAAC,QAAkB;AAC5B,YAAA,WAAW,IAAI,CAAC,MAAM,aACtB,UAAU,IAAI,IAAI,CAAC,KAAK,MAAM,GAAG,GAAG,GAAG,OAAO,UAAU,CAAC,CAAC,CAAC,EAAE,KAAK,KAAK;AAC7E,aAAO,WAAW,MAAM,IAAI,OAAO,IAAI;AAAA,IAAA;AAGzC,WAAO,MAAM,MAAM,KAAK,SAAS,UAAU,CAAC,CAAC,GAC7C,KAAK,QAAQ,CAAC,QAAQ,OAAO,MAAM,SAAS,GAAG,CAAC,CAAC;AAAA,EACnD;AACF;AAEA,SAAS,aAAa,MAAwB;AAC5C,QAAM,EAAC,aAAa,MAAM,WAAW,KAAI,IAAI,QAAQ;AACrD,SAAO,EAAC,MAAM,QAAQ,IAAI,MAAM,QAAQ;AAC1C;AAEA,SAAS,sBAAsB,aAAuB;AACpD,SAAO,YACJ,OAAO,CAAC,WAAW,CAAC,OAAO,cAAc,CAAC,OAAO,aAAa,CAAC,OAAO,gBAAgB,EACtF,IAAI,CAAC,YAAY;AAAA,IAChB,IAAI;AAAA,IACJ,MAAM,OAAO;AAAA,IACb,MAAM,OAAO;AAAA,IACb,MAAM,OAAO;AAAA,EACb,EAAA;AACN;AChHO,MAAM,aAAwC;AAAA,EACnD,MAAM;AAAA,EACN,WAAW;AAAA,EACX,aAAa;AAAA,EACb,aAAa;AACf,GCkDM,WAAiE;AAAA,EACrE;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACAwE;AAAAA,EACAC;AAAAA,EACAC;AAAAA,EACA;AAAA,EACAC;AAAAA,EACAC;AAAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACAC;AAAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA5B;AAAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA6B;AAAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,GAMa,qBAAqB;AAAA,EAChC,yBAAyB;AAAA,EACzB;AACF;;;;;;;"}