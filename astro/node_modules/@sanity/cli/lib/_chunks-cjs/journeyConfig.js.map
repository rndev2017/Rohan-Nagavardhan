{"version":3,"file":"journeyConfig.js","sources":["../../src/util/journeyConfig.ts"],"sourcesContent":["import fs from 'node:fs/promises'\nimport path from 'node:path'\nimport {Worker} from 'node:worker_threads'\n\nimport {\n  type BaseSchemaDefinition,\n  type DocumentDefinition,\n  type ObjectDefinition,\n} from '@sanity/types'\nimport {format} from 'prettier'\n\nimport {type CliApiClient} from '../types'\nimport {getCliWorkerPath} from './cliWorker'\n\n/**\n * A Journey schema is a server schema that is saved in the Journey API\n */\n\ninterface JourneySchemaWorkerData {\n  schemasPath: string\n  useTypeScript: boolean\n  schemaUrl: string\n}\n\ntype JourneySchemaWorkerResult = {type: 'success'} | {type: 'error'; error: Error}\n\ninterface JourneyConfigResponse {\n  projectId: string\n  datasetName: string\n  displayName: string\n  schemaUrl: string\n  isFirstProject: boolean // Always true for now, making it compatible with the existing getOrCreateProject\n}\n\ntype DocumentOrObject = DocumentDefinition | ObjectDefinition\ntype SchemaObject = BaseSchemaDefinition & {\n  type: string\n  fields?: SchemaObject[]\n  of?: SchemaObject[]\n  preview?: object\n}\n\n/**\n * Fetch a Journey schema from the Sanity schema club API and write it to disk\n */\nexport async function getAndWriteJourneySchema(data: JourneySchemaWorkerData): Promise<void> {\n  const {schemasPath, useTypeScript, schemaUrl} = data\n  try {\n    const documentTypes = await fetchJourneySchema(schemaUrl)\n    const fileExtension = useTypeScript ? 'ts' : 'js'\n\n    // Write a file for each schema\n    for (const documentType of documentTypes) {\n      const filePath = path.join(schemasPath, `${documentType.name}.${fileExtension}`)\n      await fs.writeFile(filePath, await assembleJourneySchemaTypeFileContent(documentType))\n    }\n    // Write an index file that exports all the schemas\n    const indexContent = await assembleJourneyIndexContent(documentTypes)\n    await fs.writeFile(path.join(schemasPath, `index.${fileExtension}`), indexContent)\n  } catch (error) {\n    throw new Error(`Failed to fetch remote schema: ${error.message}`)\n  }\n}\n\n/**\n * Executes the `getAndWriteJourneySchema` operation within a worker thread.\n *\n * This method is designed to safely import network resources by leveraging the `--experimental-network-imports` flag.\n * Due to the experimental nature of this flag, its use is not recommended in the main process. Consequently,\n * the task is delegated to a worker thread to ensure both safety and compliance with best practices.\n *\n * The core functionality involves fetching schema definitions from our own trusted API and writing them to disk.\n * This includes handling both predefined and custom schemas. For custom schemas, a process ensures\n * that they undergo JSON parsing to remove any JavaScript code and are validated before being saved.\n *\n * Depending on the configuration, the schemas are saved as either TypeScript or JavaScript files, dictated by the `useTypeScript` flag within the `workerData`.\n *\n * @param workerData - An object containing the necessary data and flags for the worker thread, including the path to save schemas, flags indicating whether to use TypeScript, and any other relevant configuration details.\n * @returns A promise that resolves upon successful execution of the schema fetching and writing process or rejects if an error occurs during the operation.\n */\nexport async function getAndWriteJourneySchemaWorker(\n  workerData: JourneySchemaWorkerData,\n): Promise<void> {\n  const workerPath = await getCliWorkerPath('getAndWriteJourneySchema')\n  return new Promise((resolve, reject) => {\n    const worker = new Worker(workerPath, {\n      workerData,\n      env: {\n        // eslint-disable-next-line no-process-env\n        ...process.env,\n        // Dynamic HTTPS imports are currently behind a Node flag\n        NODE_OPTIONS: '--experimental-network-imports',\n        NODE_NO_WARNINGS: '1',\n      },\n    })\n    worker.on('message', (message: JourneySchemaWorkerResult) => {\n      if (message.type === 'success') {\n        resolve()\n      } else {\n        message.error.message = `Import schema worker failed: ${message.error.message}`\n        reject(message.error)\n      }\n    })\n    worker.on('error', (error) => {\n      error.message = `Import schema worker failed: ${error.message}`\n      reject(error)\n    })\n    worker.on('exit', (code) => {\n      if (code !== 0) {\n        reject(new Error(`Worker stopped with exit code ${code}`))\n      }\n    })\n  })\n}\n\n/**\n * Fetch a Journey config from the Sanity schema club API\n *\n * @param projectId - The slug of the Journey schema to fetch\n * @returns The Journey schema as an array of Sanity document or object definitions\n */\nexport async function fetchJourneyConfig(\n  apiClient: CliApiClient,\n  projectId: string,\n): Promise<JourneyConfigResponse> {\n  if (!projectId) {\n    throw new Error('ProjectId is required')\n  }\n  if (!/^[a-zA-Z0-9-]+$/.test(projectId)) {\n    throw new Error('Invalid projectId')\n  }\n  try {\n    const response: {\n      projectId: string\n      dataset: string\n      displayName?: string\n      schemaUrl: string\n    } = await apiClient({\n      requireUser: true,\n      requireProject: true,\n      api: {projectId},\n    })\n      .config({apiVersion: 'v2024-02-23'})\n      .request({\n        method: 'GET',\n        uri: `/journey/projects/${projectId}`,\n      })\n\n    return {\n      projectId: response.projectId,\n      datasetName: response.dataset,\n      displayName: response.displayName || 'Sanity Project',\n      // The endpoint returns a signed URL that can be used to fetch the schema as ESM\n      schemaUrl: response.schemaUrl,\n      isFirstProject: true,\n    }\n  } catch (err) {\n    throw new Error(`Failed to fetch remote schema config: ${projectId}`)\n  }\n}\n\n/**\n * Fetch a Journey schema from the Sanity schema club API\n *\n * @param projectId - The slug of the Journey schema to fetch\n * @returns The Journey schema as an array of Sanity document or object definitions\n */\nasync function fetchJourneySchema(schemaUrl: string): Promise<DocumentOrObject[]> {\n  try {\n    const response = await import(schemaUrl)\n    return response.default\n  } catch (err) {\n    throw new Error(`Failed to fetch remote schema: ${schemaUrl}`)\n  }\n}\n\n/**\n * Assemble a Journey schema type into a module export\n * Include the necessary imports and export the schema type as a named export\n *\n * @param schema - The Journey schema to export\n * @returns The Journey schema as a module export\n */\nasync function assembleJourneySchemaTypeFileContent(schemaType: DocumentOrObject): Promise<string> {\n  const serialised = wrapSchemaTypeInHelpers(schemaType)\n  const imports = getImports(serialised)\n  const prettifiedSchemaType = await format(serialised, {\n    parser: 'typescript',\n    printWidth: 40,\n  })\n  // Start file with import, then export the schema type as a named export\n  return `${imports}\\n\\nexport const ${schemaType.name} = ${prettifiedSchemaType}\\n`\n}\n\n/**\n * Assemble a list of Journey schema module exports into a single index file\n *\n * @param schemas - The Journey schemas to assemble into an index file\n * @returns The index file as a string\n */\nfunction assembleJourneyIndexContent(schemas: DocumentOrObject[]): Promise<string> {\n  const sortedSchema = schemas.slice().sort((a, b) => (a.name > b.name ? 1 : -1))\n  const imports = sortedSchema.map((schema) => `import { ${schema.name} } from './${schema.name}'`)\n  const exports = sortedSchema.map((schema) => schema.name).join(',')\n  const fileContents = `${imports.join('\\n')}\\n\\nexport const schemaTypes = [${exports}]`\n  return format(fileContents, {parser: 'typescript'})\n}\n\n/**\n * Get the import statements for a schema type\n *\n * @param schemaType - The schema type to get the imports for\n * @returns The import statements for the schema type\n */\nfunction getImports(schemaType: string): string {\n  const defaultImports = ['defineType', 'defineField']\n  if (schemaType.includes('defineArrayMember')) {\n    defaultImports.push('defineArrayMember')\n  }\n  return `import { ${defaultImports.join(', ')} } from 'sanity'`\n}\n\n/**\n * Serialize a singleSanity schema type (signular) into a string.\n * Wraps the schema object in the appropriate helper function.\n *\n * @param schemaType - The schema type to serialize\n * @returns The schema type as a string\n */\n/**\n * Serializes a single Sanity schema type into a string.\n * Wraps the schema object in the appropriate helper function.\n *\n * @param schemaType - The schema type to serialize\n * @param root - Whether the schemaType is the root object\n * @returns The serialized schema type as a string\n */\nexport function wrapSchemaTypeInHelpers(schemaType: SchemaObject, root: boolean = true): string {\n  if (root) {\n    return generateSchemaDefinition(schemaType, 'defineType')\n  } else if (schemaType.type === 'array') {\n    return `${generateSchemaDefinition(schemaType, 'defineField')},`\n  }\n  return `${generateSchemaDefinition(schemaType, 'defineField')},`\n\n  function generateSchemaDefinition(\n    object: SchemaObject,\n    definitionType: 'defineType' | 'defineField',\n  ): string {\n    const {fields, preview, of, ...otherProperties} = object\n\n    const serializedProps = serialize(otherProperties)\n    const fieldsDef =\n      fields && `fields: [${fields.map((f) => wrapSchemaTypeInHelpers(f, false)).join('')}],`\n    const ofDef = of && `of: [${of.map((f) => `defineArrayMember({${serialize(f)}})`).join(',')}],`\n    const previewDef = preview && `preview: {${serialize(preview)}}`\n\n    const combinedDefinitions = [serializedProps, fieldsDef, ofDef, previewDef]\n      .filter(Boolean)\n      .join(',')\n    return `${definitionType}({ ${combinedDefinitions} })`\n  }\n\n  function serialize(obj: object) {\n    return Object.entries(obj)\n      .map(([key, value]) => {\n        if (key === 'prepare') {\n          return `${value.toString()}`\n        }\n        if (typeof value === 'string') {\n          return `${key}: \"${value}\"`\n        }\n        if (typeof value === 'object') {\n          return `${key}: ${JSON.stringify(value)}`\n        }\n        return `${key}: ${value}`\n      })\n      .join(',')\n  }\n}\n"],"names":["path","fs","getCliWorkerPath","Worker","format","exports"],"mappings":";;;;;;AA6CA,eAAsB,yBAAyB,MAA8C;AAC3F,QAAM,EAAC,aAAa,eAAe,UAAA,IAAa;AAC5C,MAAA;AACF,UAAM,gBAAgB,MAAM,mBAAmB,SAAS,GAClD,gBAAgB,gBAAgB,OAAO;AAG7C,eAAW,gBAAgB,eAAe;AAClC,YAAA,WAAWA,cAAAA,QAAK,KAAK,aAAa,GAAG,aAAa,IAAI,IAAI,aAAa,EAAE;AAC/E,YAAMC,YAAAA,QAAG,UAAU,UAAU,MAAM,qCAAqC,YAAY,CAAC;AAAA,IACvF;AAEM,UAAA,eAAe,MAAM,4BAA4B,aAAa;AAC9D,UAAAA,oBAAG,UAAUD,cAAK,QAAA,KAAK,aAAa,SAAS,aAAa,EAAE,GAAG,YAAY;AAAA,WAC1E,OAAO;AACd,UAAM,IAAI,MAAM,kCAAkC,MAAM,OAAO,EAAE;AAAA,EACnE;AACF;AAkBA,eAAsB,+BACpB,YACe;AACT,QAAA,aAAa,MAAME,2BAAiB,0BAA0B;AACpE,SAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AAChC,UAAA,SAAS,IAAIC,oBAAA,OAAO,YAAY;AAAA,MACpC;AAAA,MACA,KAAK;AAAA;AAAA,QAEH,GAAG,QAAQ;AAAA;AAAA,QAEX,cAAc;AAAA,QACd,kBAAkB;AAAA,MACpB;AAAA,IAAA,CACD;AACM,WAAA,GAAG,WAAW,CAAC,YAAuC;AACvD,cAAQ,SAAS,YACnB,aAEA,QAAQ,MAAM,UAAU,gCAAgC,QAAQ,MAAM,OAAO,IAC7E,OAAO,QAAQ,KAAK;AAAA,IAEvB,CAAA,GACD,OAAO,GAAG,SAAS,CAAC,UAAU;AAC5B,YAAM,UAAU,gCAAgC,MAAM,OAAO,IAC7D,OAAO,KAAK;AAAA,IACb,CAAA,GACD,OAAO,GAAG,QAAQ,CAAC,SAAS;AACtB,eAAS,KACX,OAAO,IAAI,MAAM,iCAAiC,IAAI,EAAE,CAAC;AAAA,IAAA,CAE5D;AAAA,EAAA,CACF;AACH;AAQsB,eAAA,mBACpB,WACA,WACgC;AAChC,MAAI,CAAC;AACG,UAAA,IAAI,MAAM,uBAAuB;AAErC,MAAA,CAAC,kBAAkB,KAAK,SAAS;AAC7B,UAAA,IAAI,MAAM,mBAAmB;AAEjC,MAAA;AACI,UAAA,WAKF,MAAM,UAAU;AAAA,MAClB,aAAa;AAAA,MACb,gBAAgB;AAAA,MAChB,KAAK,EAAC,UAAS;AAAA,IAAA,CAChB,EACE,OAAO,EAAC,YAAY,cAAc,CAAA,EAClC,QAAQ;AAAA,MACP,QAAQ;AAAA,MACR,KAAK,qBAAqB,SAAS;AAAA,IAAA,CACpC;AAEI,WAAA;AAAA,MACL,WAAW,SAAS;AAAA,MACpB,aAAa,SAAS;AAAA,MACtB,aAAa,SAAS,eAAe;AAAA;AAAA,MAErC,WAAW,SAAS;AAAA,MACpB,gBAAgB;AAAA,IAAA;AAAA,EAClB,QACY;AACZ,UAAM,IAAI,MAAM,yCAAyC,SAAS,EAAE;AAAA,EACtE;AACF;AAQA,eAAe,mBAAmB,WAAgD;AAC5E,MAAA;AACe,YAAA,MAAM,OAAO,YACd;AAAA,EAAA,QACJ;AACZ,UAAM,IAAI,MAAM,kCAAkC,SAAS,EAAE;AAAA,EAC/D;AACF;AASA,eAAe,qCAAqC,YAA+C;AAC3F,QAAA,aAAa,wBAAwB,UAAU,GAC/C,UAAU,WAAW,UAAU,GAC/B,uBAAuB,MAAMC,SAAAA,OAAO,YAAY;AAAA,IACpD,QAAQ;AAAA,IACR,YAAY;AAAA,EAAA,CACb;AAED,SAAO,GAAG,OAAO;AAAA;AAAA,eAAoB,WAAW,IAAI,MAAM,oBAAoB;AAAA;AAChF;AAQA,SAAS,4BAA4B,SAA8C;AACjF,QAAM,eAAe,QAAQ,QAAQ,KAAK,CAAC,GAAG,MAAO,EAAE,OAAO,EAAE,OAAO,IAAI,EAAG,GACxE,UAAU,aAAa,IAAI,CAAC,WAAW,YAAY,OAAO,IAAI,cAAc,OAAO,IAAI,GAAG,GAC1FC,WAAU,aAAa,IAAI,CAAC,WAAW,OAAO,IAAI,EAAE,KAAK,GAAG,GAC5D,eAAe,GAAG,QAAQ,KAAK;AAAA,CAAI,CAAC;AAAA;AAAA,8BAAmCA,QAAO;AACpF,SAAOD,SAAO,OAAA,cAAc,EAAC,QAAQ,aAAa,CAAA;AACpD;AAQA,SAAS,WAAW,YAA4B;AACxC,QAAA,iBAAiB,CAAC,cAAc,aAAa;AACnD,SAAI,WAAW,SAAS,mBAAmB,KACzC,eAAe,KAAK,mBAAmB,GAElC,YAAY,eAAe,KAAK,IAAI,CAAC;AAC9C;AAiBgB,SAAA,wBAAwB,YAA0B,OAAgB,IAAc;AAC1F,MAAA;AACK,WAAA,yBAAyB,YAAY,YAAY;AACnD,MAAI,WAAW,SAAS;AAC7B,WAAO,GAAG,yBAAyB,YAAY,aAAa,CAAC;AAE/D,SAAO,GAAG,yBAAyB,YAAY,aAAa,CAAC;AAEpD,WAAA,yBACP,QACA,gBACQ;AACR,UAAM,EAAC,QAAQ,SAAS,IAAI,GAAG,gBAAA,IAAmB,QAE5C,kBAAkB,UAAU,eAAe,GAC3C,YACJ,UAAU,YAAY,OAAO,IAAI,CAAC,MAAM,wBAAwB,GAAG,EAAK,CAAC,EAAE,KAAK,EAAE,CAAC,MAC/E,QAAQ,MAAM,QAAQ,GAAG,IAAI,CAAC,MAAM,sBAAsB,UAAU,CAAC,CAAC,IAAI,EAAE,KAAK,GAAG,CAAC,MACrF,aAAa,WAAW,aAAa,UAAU,OAAO,CAAC,KAEvD,sBAAsB,CAAC,iBAAiB,WAAW,OAAO,UAAU,EACvE,OAAO,OAAO,EACd,KAAK,GAAG;AACJ,WAAA,GAAG,cAAc,MAAM,mBAAmB;AAAA,EACnD;AAEA,WAAS,UAAU,KAAa;AAC9B,WAAO,OAAO,QAAQ,GAAG,EACtB,IAAI,CAAC,CAAC,KAAK,KAAK,MACX,QAAQ,YACH,GAAG,MAAM,UAAU,KAExB,OAAO,SAAU,WACZ,GAAG,GAAG,MAAM,KAAK,MAEtB,OAAO,SAAU,WACZ,GAAG,GAAG,KAAK,KAAK,UAAU,KAAK,CAAC,KAElC,GAAG,GAAG,KAAK,KAAK,EACxB,EACA,KAAK,GAAG;AAAA,EACb;AACF;;;;"}